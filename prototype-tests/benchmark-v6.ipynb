{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d598de90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import networkx.algorithms.community as nx_comm\n",
    "from networkx.generators.community import LFR_benchmark_graph\n",
    "from networkx.algorithms import bipartite\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy.sparse import coo_array\n",
    "from scipy import sparse\n",
    "from cdlib import algorithms\n",
    "from cdlib import evaluation\n",
    "import sklearn\n",
    "from utils import *\n",
    "from distances import *\n",
    "from consensus import *\n",
    "from mcl import *\n",
    "import math\n",
    "import itertools\n",
    "import random\n",
    "import time\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "febf84a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cons_name = \"v6\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cdbd9239",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import coo_array\n",
    "from scipy.sparse import csr_array\n",
    "from mcl import *\n",
    "\n",
    "# Assumes the elements of the cluster are named as 0-based indices\n",
    "def v6_consensus(P_list, niter=10, starting_partition=None, verbose=False):\n",
    "    G = nx.Graph(P_list[0][\"graph\"])\n",
    "    n = len(list(G.nodes()))\n",
    "    k = len(P_list)\n",
    "    print(\"Number of edges in G:\", len(list(G.edges())))\n",
    "\n",
    "    t1 = time.time()\n",
    "    A = nx.to_scipy_sparse_array(G, format=\"coo\")\n",
    "    t2 = time.time()\n",
    "    print(\"Time to get sparse matrix of the graph:\", t2-t1)\n",
    "\n",
    "    nz_rows = A.row \n",
    "    nz_cols = A.col\n",
    "    \n",
    "    t1 = time.time()\n",
    "    P_list_asn = []\n",
    "    c = np.zeros((n,k))\n",
    "    for i in range(k):\n",
    "        clust_lst = P_list[i][\"partition\"]\n",
    "        clust_asn = clust_lst_to_asn(clust_lst)\n",
    "        c[:,i] = np.array(clust_asn)\n",
    "    t2 = time.time()\n",
    "    print(\"Time to generate cluster assignment matrix:\", t2-t1)\n",
    "    \n",
    "    Aw_rows = A.row\n",
    "    Aw_cols = A.col\n",
    "    Aw_vals = A.data\n",
    "    #nz_elems = []\n",
    "    t1 = time.time()\n",
    "    for i in range(len(nz_rows)):\n",
    "        Aw_vals[i] = np.sum( c[nz_rows[i],:] == c[nz_cols[i],:] )\n",
    "    Aw = csr_array((Aw_vals, (Aw_rows, Aw_cols)), shape=(n, n))\n",
    "    t2 = time.time()\n",
    "    print(\"Time to generate weighted consensus graph:\", t2-t1)\n",
    "    print(\"Number of non-zeroes in Aw:\", Aw.count_nonzero())\n",
    "    Gw = nx.from_numpy_array(Aw)\n",
    "    Aw_nnz = Aw.count_nonzero()\n",
    "    print(\"Aw_nnz\", Aw_nnz)\n",
    "    \n",
    "    \"\"\"\n",
    "    t1 = time.time()\n",
    "    bfs_rows = []\n",
    "    bfs_cols = []\n",
    "    bfs_vals = []\n",
    "    for x in range(n):\n",
    "        bfs_edges = list(nx.bfs_tree(Gw, source=x, depth_limit=2).edges())\n",
    "        for edge in bfs_edges:\n",
    "            y = edge[1]\n",
    "            bfs_rows.append(x)\n",
    "            bfs_cols.append(y)\n",
    "            bfs_vals.append(1)\n",
    "    bfs_neighbors = csr_array((bfs_vals, (bfs_rows, bfs_cols)), shape=(n, n))\n",
    "    t2 = time.time()\n",
    "    print(\"Time to generate bfs neighborhood graph:\", t2-t1)\n",
    "    bfs_neighbors_nnz = bfs_neighbors.count_nonzero()\n",
    "    print(\"bfs_neighbors_nnz\", bfs_neighbors_nnz)\n",
    "    \"\"\"\n",
    "    \n",
    "    t1 = time.time()\n",
    "    #temp = csr_array(Aw)\n",
    "    Aw = add_self_loops(Aw, 1)\n",
    "    Aw = normalize(Aw)\n",
    "    Aw = prune(Aw, 0.001)\n",
    "    Aw_nnz = Aw.count_nonzero()\n",
    "    for i in range(2):\n",
    "        Aw = iterate(Aw, 2, 2)\n",
    "        Aw = prune(Aw, 0.001)\n",
    "        Aw = normalize(Aw)\n",
    "        Aw_nnz = Aw.count_nonzero()\n",
    "        print(\"Iteration\", i, \"Aw_nnz\", Aw_nnz)\n",
    "    t2 = time.time()\n",
    "    print(\"Time to simulate MCL:\", t2-t1)\n",
    "    #markov_clusters = get_clusters(Aw)\n",
    "    #print(\"Number of Markov clusters:\", len(markov_clusters))\n",
    "    #print(markov_clusters)\n",
    "    \n",
    "    \n",
    "    #R = nx.to_scipy_sparse_array(G, format=\"csr\")\n",
    "    \n",
    "    \n",
    "    A = nx.to_scipy_sparse_array(G, format=\"csr\")\n",
    "    \n",
    "    R = A + Aw\n",
    "    RT = R.transpose()\n",
    "    R = R + RT\n",
    "    print(\"R nnz:\", R.count_nonzero())\n",
    "    for u in range(n):\n",
    "        row_start = R.indptr[u]\n",
    "        row_end = R.indptr[u+1]\n",
    "        for j in range(row_start, row_end):\n",
    "            v = R.indices[j]\n",
    "            R.data[j] = np.sum( (c[int(u),:] == c[int(v),:]) )\n",
    "    #print(\"R nnz:\", R.count_nonzero())\n",
    "    \n",
    "    t1 = time.time()\n",
    "    refined_partition = None\n",
    "    if starting_partition:\n",
    "        refined_partition = list(starting_partition)\n",
    "    else:\n",
    "        refined_partition = []\n",
    "        for i in range(n):\n",
    "            refined_partition.append([str(i)])\n",
    "    \n",
    "    refined_partition_map = clust_lst_to_map(refined_partition)\n",
    "    items = list(refined_partition_map.keys())\n",
    "    t2 = time.time()\n",
    "    print(\"Time to initialize:\", t2-t1)\n",
    "    \n",
    "    sparseMatrixMiss = 0\n",
    "    sparseMatrixHit = 0\n",
    "    \n",
    "    tSearch = 0\n",
    "    tUpdate = 0\n",
    "    tMovement = 0\n",
    "    tSparseMatLookup = 0\n",
    "    count = 0\n",
    "    it = 1\n",
    "    last_valid = np.zeros(n)\n",
    "    last_deltaS = np.zeros(n)\n",
    "    while(it <= niter):\n",
    "        print(\"Iteration:\", it)\n",
    "        potential_moves = {\n",
    "            \"from\": np.arange(n),\n",
    "            \"to\": np.arange(n),\n",
    "            \"attractor\": np.arange(n),\n",
    "            \"deltaS\": np.zeros(n),\n",
    "            \"valid\": np.zeros(n)\n",
    "        }\n",
    "        for u in range(n):\n",
    "            row_start = A.indptr[u]\n",
    "            row_end = A.indptr[u+1]\n",
    "            for j in range(row_start, row_end):\n",
    "                v = A.indices[j]\n",
    "                w = A.data[j]\n",
    "                \n",
    "                t1 = time.time()\n",
    "                \n",
    "                a = refined_partition_map[str(u)]\n",
    "                b = refined_partition_map[str(v)]\n",
    "                \n",
    "                Mua = 0\n",
    "                Mub = 0\n",
    "                for elem in refined_partition[a]:\n",
    "                    if str(elem) != str(u):\n",
    "                        t3 = time.time()\n",
    "                        \n",
    "                        r = 0\n",
    "                        \n",
    "                        #r = R[int(u),int(elem)]\n",
    "                        \n",
    "                        R_row_start = R.indptr[u]\n",
    "                        R_row_end = R.indptr[u+1]\n",
    "                        low = R_row_start\n",
    "                        hi = R_row_end - 1\n",
    "                        target = -1\n",
    "                        while low <= hi:\n",
    "                            mid = ( low + hi ) // 2\n",
    "                            if R.indices[mid] < int(elem):\n",
    "                                low = mid + 1\n",
    "                            elif R.indices[mid] > int(elem):\n",
    "                                hi = mid - 1\n",
    "                            else:\n",
    "                                target = mid\n",
    "                                break\n",
    "                        if target != -1:\n",
    "                            r = R.data[target]\n",
    "    \n",
    "                        t4 = time.time()\n",
    "                        tSparseMatLookup += t4-t3\n",
    "                        \n",
    "                        if (r == 0):\n",
    "                            Mua = Mua + (k - 2 * np.sum( (c[int(u),:] == c[int(elem),:]) ) )\n",
    "                            sparseMatrixMiss = sparseMatrixMiss + 1\n",
    "                            #print(\"Sparse matrix lookup miss:\", sparseMatrixMiss)\n",
    "                        else:\n",
    "                            Mua = Mua + (k - 2 * r )\n",
    "                            sparseMatrixHit = sparseMatrixHit + 1\n",
    "                            #print(\"Sparse matrix lookup hit:\", sparseMatrixHit)\n",
    "                for elem in refined_partition[b]:    \n",
    "                    if str(elem) != str(u):\n",
    "                        t3 = time.time()\n",
    "                        \n",
    "                        r = 0\n",
    "                        \n",
    "                        #r = R[int(u),int(elem)]\n",
    "                        \n",
    "                        R_row_start = R.indptr[u]\n",
    "                        R_row_end = R.indptr[u+1]\n",
    "                        low = R_row_start\n",
    "                        hi = R_row_end - 1\n",
    "                        target = -1\n",
    "                        while low <= hi:\n",
    "                            mid = ( low + hi ) // 2\n",
    "                            if R.indices[mid] < int(elem):\n",
    "                                low = mid + 1\n",
    "                            elif R.indices[mid] > int(elem):\n",
    "                                hi = mid - 1\n",
    "                            else:\n",
    "                                target = mid\n",
    "                                break\n",
    "                        if target != -1:\n",
    "                            r = R.data[target]\n",
    "                        \n",
    "                        t4 = time.time()\n",
    "                        tSparseMatLookup += t4-t3\n",
    "                              \n",
    "                        if (r == 0):\n",
    "                            Mub = Mub + (k - 2 * np.sum( (c[int(u),:] == c[int(elem),:]) ) )\n",
    "                            sparseMatrixMiss = sparseMatrixMiss + 1\n",
    "                            #print(\"Sparse matrix lookup miss:\", sparseMatrixMiss)\n",
    "                        else:\n",
    "                            Mub = Mub + (k - 2 * r )\n",
    "                            sparseMatrixHit = sparseMatrixHit + 1\n",
    "                            #print(\"Sparse matrix lookup hit:\", sparseMatrixHit)\n",
    "                            \n",
    "                deltaS = Mub - Mua\n",
    "                t2 = time.time()\n",
    "                tSearch = tSearch + t2-t1\n",
    "                \n",
    "                if (deltaS is not None) and (deltaS < 0) and (a != b):\n",
    "                    potential_moves[\"from\"][u] = a\n",
    "                    potential_moves[\"to\"][u] = b\n",
    "                    potential_moves[\"attractor\"][u] = v\n",
    "                    potential_moves[\"deltaS\"][u] = deltaS\n",
    "                    potential_moves[\"valid\"][u] = 1\n",
    "        \n",
    "        t1 = time.time()\n",
    "        for u in range(n):\n",
    "            v = potential_moves[\"attractor\"][u]\n",
    "            if (potential_moves[\"valid\"][u] == 1) and (potential_moves[\"attractor\"][v] == u) and (potential_moves[\"valid\"][v] == 1):\n",
    "                # Question mark\n",
    "                if potential_moves[\"deltaS\"][u] < potential_moves[\"deltaS\"][v]:\n",
    "                    potential_moves[\"valid\"][v] = 0\n",
    "                    potential_moves[\"deltaS\"][v] = 0\n",
    "                else:\n",
    "                    potential_moves[\"valid\"][u] = 0\n",
    "                    potential_moves[\"deltaS\"][u] = 0\n",
    "        t2 = time.time()\n",
    "        tSearch = tSearch + (t2 - t1)\n",
    "        \n",
    "        flag = False\n",
    "        if np.sum( (potential_moves[\"valid\"] != last_valid) ) == 0:\n",
    "            # Same set of elements are being moved\n",
    "            if np.sum(potential_moves[\"deltaS\"]) < np.sum(last_deltaS):\n",
    "                last_valid = potential_moves[\"valid\"]\n",
    "                last_deltaS = potential_moves[\"deltaS\"]\n",
    "                flag = True\n",
    "        else:\n",
    "            last_valid = potential_moves[\"valid\"]\n",
    "            last_deltaS = potential_moves[\"deltaS\"]\n",
    "            flag = True\n",
    "        \n",
    "        if flag == True:\n",
    "            for u in range(n):\n",
    "                if potential_moves[\"valid\"][u] == True:\n",
    "                    a = potential_moves[\"from\"][u]\n",
    "                    b = potential_moves[\"to\"][u]\n",
    "\n",
    "                    t1 = time.time()\n",
    "                    if verbose:\n",
    "                        print(\"---\")\n",
    "                        print(\"Iteration:\", it, \"Move Count:\", count+1, \">> results in deltaS\", potential_moves[\"deltaS\"][u])\n",
    "                        print(\"Move:\", u)\n",
    "                        print(\"From partition\", a, \":\", refined_partition[a])\n",
    "                        print(\"To partition\", b, \":\", refined_partition[b])\n",
    "                        print(\"---\")\n",
    "                    refined_partition[a].remove(str(u))\n",
    "                    refined_partition[b].append(str(u))\n",
    "                    refined_partition_map[str(u)] = b\n",
    "                    t2 = time.time()\n",
    "                    tUpdate = tUpdate + (t2-t1)\n",
    "\n",
    "                    count = count + 1\n",
    "        \n",
    "        print(\"Sparse matrix lookup miss:\", sparseMatrixMiss)\n",
    "        print(\"Sparse matrix lookup hit:\", sparseMatrixHit)\n",
    "        \n",
    "        if flag == False:\n",
    "            break\n",
    "        \n",
    "        it = it + 1\n",
    "    print(\"Time to lookup entries in sparse R:\", tSparseMatLookup)\n",
    "    print(\"Time to search moves:\", tSearch)\n",
    "    print(\"Time to update M:\", tUpdate)\n",
    "    \n",
    "    t1 = time.time()\n",
    "    empty_clusters = []\n",
    "    for i in range(len(refined_partition)):\n",
    "        if len(refined_partition[i]) == 0:\n",
    "            empty_clusters.append(i)\n",
    "            \n",
    "    empty_clusters.sort(reverse=True)\n",
    "    for e in empty_clusters:\n",
    "        del refined_partition[e]\n",
    "    t2 = time.time()\n",
    "    print(\"Time to delete empty partitions:\", t2-t1)\n",
    "    \n",
    "    Gw = nx.from_scipy_sparse_array(Aw)\n",
    "    return {\"graph\": nx.Graph(Gw), \"partition\": list(refined_partition)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074ddb46",
   "metadata": {},
   "source": [
    "# n=200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "03a41e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('algorithms.label_propagation(G)', 0), ('algorithms.leiden(G)', 1), ('algorithms.significance_communities(G)', 2), ('algorithms.surprise_communities(G)', 3), ('algorithms.greedy_modularity(G)', 4), ('algorithms.paris(G)', 5), ('algorithms.louvain(G,resolution=0.75,randomize=314159)', 6), ('algorithms.louvain(G,resolution=0.75,randomize=2718)', 7), ('algorithms.louvain(G,resolution=1.0,randomize=314159)', 8), ('algorithms.louvain(G,resolution=1.0,randomize=2718)', 9), ('algorithms.louvain(G,resolution=1.25,randomize=314159)', 10), ('algorithms.louvain(G,resolution=1.25,randomize=2718)', 11), ('algorithms.louvain(G,resolution=1.5,randomize=314159)', 12), ('algorithms.louvain(G,resolution=1.5,randomize=2718)', 13), ('algorithms.infomap(G)', 14), ('algorithms.walktrap(G)', 15), ('algorithms.markov_clustering(G,inflation=1.2,pruning_threshold=0.01,convergence_check_frequency=100)', 16), ('algorithms.markov_clustering(G,inflation=1.2,pruning_threshold=0.001,convergence_check_frequency=100)', 17), ('algorithms.markov_clustering(G,inflation=1.5,pruning_threshold=0.01,convergence_check_frequency=100)', 18), ('algorithms.markov_clustering(G,inflation=1.5,pruning_threshold=0.001,convergence_check_frequency=100)', 19), ('algorithms.markov_clustering(G,inflation=2,pruning_threshold=0.01,convergence_check_frequency=100)', 20), ('algorithms.markov_clustering(G,inflation=2,pruning_threshold=0.001,convergence_check_frequency=100)', 21), ('algorithms.markov_clustering(G,inflation=2.5,pruning_threshold=0.01,convergence_check_frequency=100)', 22), ('algorithms.markov_clustering(G,inflation=2.5,pruning_threshold=0.001,convergence_check_frequency=100)', 23), ('algorithms.em(G,k=10)', 24), ('algorithms.em(G,k=32)', 25), ('algorithms.em(G,k=20)', 26), ('algorithms.em(G,k=25)', 27), ('algorithms.sbm_dl(G)', 28), ('algorithms.spinglass(G,spins=10)', 29), ('algorithms.spinglass(G,spins=32)', 30), ('algorithms.spinglass(G,spins=20)', 31), ('algorithms.spinglass(G,spins=25)', 32), ('algorithms.ricci_community(G,alpha=0.3)', 33), ('algorithms.ricci_community(G,alpha=0.5)', 34), ('algorithms.ricci_community(G,alpha=0.6)', 35), ('algorithms.ricci_community(G,alpha=0.75)', 36)]\n"
     ]
    }
   ],
   "source": [
    "n = 200\n",
    "expected_clusters = []\n",
    "for i in range(4):\n",
    "    expected_clusters.append(random.randint(int(n ** (1. / 3)),3*int(n ** (1. / 2))))\n",
    "    \n",
    "alg_params = {\n",
    "    \"label_propagation\": None,\n",
    "    \"leiden\": None,\n",
    "    \"significance_communities\": None,\n",
    "    \"surprise_communities\": None,\n",
    "    \"greedy_modularity\": None,\n",
    "    \"paris\": None,\n",
    "    \"louvain\": {\n",
    "        \"resolution\": [0.75, 1.0, 1.25, 1.5],\n",
    "        \"randomize\": [314159, 2718]\n",
    "    },\n",
    "    \"infomap\": None,\n",
    "    \"walktrap\": None,\n",
    "    \"markov_clustering\": {\n",
    "        \"inflation\": [1.2, 1.5, 2, 2.5],\n",
    "        \"pruning_threshold\": [0.01, 0.001],\n",
    "        \"convergence_check_frequency\": [100]\n",
    "    },\n",
    "    \"em\": {\n",
    "        \"k\": list(expected_clusters)\n",
    "    },\n",
    "    \"sbm_dl\": None,\n",
    "    \"spinglass\": {\n",
    "        \"spins\": list(expected_clusters)\n",
    "    },\n",
    "    \"ricci_community\": {\n",
    "        \"alpha\": [0.3, 0.5, 0.6, 0.75]\n",
    "    }\n",
    "}\n",
    "\n",
    "clustering_enumeration = []\n",
    "count = 0\n",
    "for alg, params in alg_params.items():\n",
    "    param_combinations = []\n",
    "    param_names = []\n",
    "    if params is not None:\n",
    "        iterables = []\n",
    "        param_names = []\n",
    "        for param in params.keys():\n",
    "            iterables.append(list(params[param]))\n",
    "            param_names.append(param)\n",
    "        param_combinations = list(itertools.product(*iterables))\n",
    "    if len(param_combinations) > 0:\n",
    "        for param_combination in param_combinations:\n",
    "            expr = \"algorithms.\"+alg+\"(G\"\n",
    "            for i in range(len(param_names)):\n",
    "                expr = expr + \",\" + param_names[i] + \"=\" + str(param_combination[i])\n",
    "            expr = expr + \")\"\n",
    "            clustering_enumeration.append((expr,count))\n",
    "            count = count + 1      \n",
    "    else:\n",
    "        expr = \"algorithms.\"+alg+\"(G)\"\n",
    "        clustering_enumeration.append((expr,count))\n",
    "        count = count + 1\n",
    "        \n",
    "print(clustering_enumeration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ab36873c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LFR/n200/LFR_n200_mu01_gamma30_beta11.mtx\n",
      "Number of edges in G: 993\n",
      "Time to get sparse matrix of the graph: 0.0024111270904541016\n",
      "Time to generate cluster assignment matrix: 0.0029020309448242188\n",
      "Time to generate weighted consensus graph: 0.008874177932739258\n",
      "Number of non-zeroes in Aw: 1924\n",
      "Aw_nnz 1924\n",
      "Iteration 0 Aw_nnz 3740\n",
      "Iteration 1 Aw_nnz 3168\n",
      "Iteration 2 Aw_nnz 1725\n",
      "Time to simulate MCL: 0.01769089698791504\n",
      "R nnz: 2929\n",
      "Time to initialize: 5.698204040527344e-05\n",
      "Iteration: 1\n",
      "Sparse matrix lookup miss: 0\n",
      "Sparse matrix lookup hit: 1862\n",
      "Iteration: 2\n",
      "Sparse matrix lookup miss: 4089\n",
      "Sparse matrix lookup hit: 16493\n",
      "Iteration: 3\n",
      "Sparse matrix lookup miss: 18583\n",
      "Sparse matrix lookup hit: 57141\n",
      "Iteration: 4\n",
      "Sparse matrix lookup miss: 39281\n",
      "Sparse matrix lookup hit: 108021\n",
      "Iteration: 5\n",
      "Sparse matrix lookup miss: 61318\n",
      "Sparse matrix lookup hit: 160868\n",
      "Iteration: 6\n",
      "Sparse matrix lookup miss: 83355\n",
      "Sparse matrix lookup hit: 213715\n",
      "Time to lookup entries in sparse R: 3.1922576427459717\n",
      "Time to search moves: 3.841763496398926\n",
      "Time to update M: 0.00020694732666015625\n",
      "Time to delete empty partitions: 3.743171691894531e-05\n",
      "mu 1 , number of clusters 16\n",
      "Time: 3.9490954875946045\n",
      "LFR/n200/LFR_n200_mu02_gamma30_beta11.mtx\n",
      "Number of edges in G: 1008\n",
      "Time to get sparse matrix of the graph: 0.002153158187866211\n",
      "Time to generate cluster assignment matrix: 0.0026159286499023438\n",
      "Time to generate weighted consensus graph: 0.00898432731628418\n",
      "Number of non-zeroes in Aw: 1957\n",
      "Aw_nnz 1957\n",
      "Iteration 0 Aw_nnz 3710\n",
      "Iteration 1 Aw_nnz 3035\n",
      "Iteration 2 Aw_nnz 1472\n",
      "Time to simulate MCL: 0.018240690231323242\n",
      "R nnz: 2899\n",
      "Time to initialize: 5.555152893066406e-05\n",
      "Iteration: 1\n",
      "Sparse matrix lookup miss: 0\n",
      "Sparse matrix lookup hit: 1898\n",
      "Iteration: 2\n",
      "Sparse matrix lookup miss: 9755\n",
      "Sparse matrix lookup hit: 20301\n",
      "Iteration: 3\n",
      "Sparse matrix lookup miss: 29357\n",
      "Sparse matrix lookup hit: 55191\n",
      "Iteration: 4\n",
      "Sparse matrix lookup miss: 55321\n",
      "Sparse matrix lookup hit: 99749\n",
      "Iteration: 5\n",
      "Sparse matrix lookup miss: 81600\n",
      "Sparse matrix lookup hit: 145228\n",
      "Iteration: 6\n",
      "Sparse matrix lookup miss: 108666\n",
      "Sparse matrix lookup hit: 191970\n",
      "Iteration: 7\n",
      "Sparse matrix lookup miss: 136385\n",
      "Sparse matrix lookup hit: 239295\n",
      "Iteration: 8\n",
      "Sparse matrix lookup miss: 164104\n",
      "Sparse matrix lookup hit: 286620\n",
      "Time to lookup entries in sparse R: 4.92647385597229\n",
      "Time to search moves: 6.127751588821411\n",
      "Time to update M: 0.00020837783813476562\n",
      "Time to delete empty partitions: 3.6716461181640625e-05\n",
      "mu 2 , number of clusters 16\n",
      "Time: 6.238068103790283\n",
      "LFR/n200/LFR_n200_mu03_gamma30_beta11.mtx\n",
      "Number of edges in G: 1031\n",
      "Time to get sparse matrix of the graph: 0.002234220504760742\n",
      "Time to generate cluster assignment matrix: 0.0025911331176757812\n",
      "Time to generate weighted consensus graph: 0.009221315383911133\n",
      "Number of non-zeroes in Aw: 2012\n",
      "Aw_nnz 2012\n",
      "Iteration 0 Aw_nnz 6172\n",
      "Iteration 1 Aw_nnz 3076\n",
      "Iteration 2 Aw_nnz 1392\n",
      "Time to simulate MCL: 0.02205371856689453\n",
      "R nnz: 3093\n",
      "Time to initialize: 5.626678466796875e-05\n",
      "Iteration: 1\n",
      "Sparse matrix lookup miss: 0\n",
      "Sparse matrix lookup hit: 1962\n",
      "Iteration: 2\n",
      "Sparse matrix lookup miss: 5817\n",
      "Sparse matrix lookup hit: 12471\n",
      "Iteration: 3\n",
      "Sparse matrix lookup miss: 18069\n",
      "Sparse matrix lookup hit: 33237\n",
      "Iteration: 4\n",
      "Sparse matrix lookup miss: 44655\n",
      "Sparse matrix lookup hit: 67909\n",
      "Iteration: 5\n",
      "Sparse matrix lookup miss: 76582\n",
      "Sparse matrix lookup hit: 108956\n",
      "Iteration: 6\n",
      "Sparse matrix lookup miss: 109388\n",
      "Sparse matrix lookup hit: 150668\n",
      "Iteration: 7\n",
      "Sparse matrix lookup miss: 142194\n",
      "Sparse matrix lookup hit: 192380\n",
      "Time to lookup entries in sparse R: 3.701697587966919\n",
      "Time to search moves: 4.6875433921813965\n",
      "Time to update M: 0.00023174285888671875\n",
      "Time to delete empty partitions: 3.528594970703125e-05\n",
      "mu 3 , number of clusters 17\n",
      "Time: 4.800358772277832\n",
      "LFR/n200/LFR_n200_mu04_gamma30_beta11.mtx\n",
      "Number of edges in G: 1047\n",
      "Time to get sparse matrix of the graph: 0.0022573471069335938\n",
      "Time to generate cluster assignment matrix: 0.0029022693634033203\n",
      "Time to generate weighted consensus graph: 0.009470939636230469\n",
      "Number of non-zeroes in Aw: 2050\n",
      "Aw_nnz 2050\n",
      "Iteration 0 Aw_nnz 10889\n",
      "Iteration 1 Aw_nnz 4481\n",
      "Iteration 2 Aw_nnz 1573\n",
      "Time to simulate MCL: 0.026602506637573242\n",
      "R nnz: 3926\n",
      "Time to initialize: 5.841255187988281e-05\n",
      "Iteration: 1\n",
      "Sparse matrix lookup miss: 0\n",
      "Sparse matrix lookup hit: 2006\n",
      "Iteration: 2\n",
      "Sparse matrix lookup miss: 7378\n",
      "Sparse matrix lookup hit: 10764\n",
      "Iteration: 3\n",
      "Sparse matrix lookup miss: 20506\n",
      "Sparse matrix lookup hit: 27278\n",
      "Iteration: 4\n",
      "Sparse matrix lookup miss: 44250\n",
      "Sparse matrix lookup hit: 52268\n",
      "Iteration: 5\n",
      "Sparse matrix lookup miss: 76116\n",
      "Sparse matrix lookup hit: 82292\n",
      "Iteration: 6\n",
      "Sparse matrix lookup miss: 114823\n",
      "Sparse matrix lookup hit: 116067\n",
      "Iteration: 7\n",
      "Sparse matrix lookup miss: 154246\n",
      "Sparse matrix lookup hit: 150206\n",
      "Iteration: 8\n",
      "Sparse matrix lookup miss: 193100\n",
      "Sparse matrix lookup hit: 184244\n",
      "Iteration: 9\n",
      "Sparse matrix lookup miss: 231588\n",
      "Sparse matrix lookup hit: 218096\n",
      "Time to lookup entries in sparse R: 5.189624071121216\n",
      "Time to search moves: 6.714535236358643\n",
      "Time to update M: 0.0003218650817871094\n",
      "Time to delete empty partitions: 3.528594970703125e-05\n",
      "mu 4 , number of clusters 19\n",
      "Time: 6.842483043670654\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "n = 200\n",
    "fileprefix = \"LFR/\" + \"n\" + str(n) + \"/\"\n",
    "mus = [1, 2, 3, 4]\n",
    "#mus = [4]\n",
    "gammas = [30]\n",
    "betas = [11]\n",
    "for mu in mus:\n",
    "    for gamma in gammas:\n",
    "        for beta in betas:\n",
    "            P_list = []\n",
    "            fname = \"LFR_n\" + str(n) + \"_mu0\" + str(mu) + \"_gamma\" + str(gamma) + \"_beta\" + str(beta)\n",
    "            graph_file = fileprefix + fname + \".mtx\"\n",
    "            print(graph_file)\n",
    "            G = None\n",
    "            with open(graph_file) as f:\n",
    "                G = nx.from_scipy_sparse_array(spio.mmread(f), create_using=nx.Graph)\n",
    "                coms = None\n",
    "                for k in clustering_enumeration:\n",
    "                    clust_file = fileprefix + fname + \".\" + str(k[1])\n",
    "                    if Path(clust_file).is_file():\n",
    "                        partition = read_clust_lst(clust_file)\n",
    "                        P_list.append({\"graph\": nx.Graph(G), \"partition\": list(partition)})\n",
    "                t1 = time.time()\n",
    "                P_star = v6_consensus(P_list, niter=100, starting_partition=None, verbose=False)\n",
    "                t2 = time.time()\n",
    "                print(\"mu\", mu, \", number of clusters\", len(P_star[\"partition\"]))\n",
    "                print(\"Time:\", t2-t1)\n",
    "                #write_clust_lst(P_star[\"partition\"], fileprefix + fname + \".\" + cons_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b24c46",
   "metadata": {},
   "source": [
    "# n=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b7550c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('algorithms.label_propagation(G)', 0), ('algorithms.leiden(G)', 1), ('algorithms.significance_communities(G)', 2), ('algorithms.surprise_communities(G)', 3), ('algorithms.greedy_modularity(G)', 4), ('algorithms.paris(G)', 5), ('algorithms.louvain(G,resolution=0.75,randomize=314159)', 6), ('algorithms.louvain(G,resolution=0.75,randomize=2718)', 7), ('algorithms.louvain(G,resolution=1.0,randomize=314159)', 8), ('algorithms.louvain(G,resolution=1.0,randomize=2718)', 9), ('algorithms.louvain(G,resolution=1.25,randomize=314159)', 10), ('algorithms.louvain(G,resolution=1.25,randomize=2718)', 11), ('algorithms.louvain(G,resolution=1.5,randomize=314159)', 12), ('algorithms.louvain(G,resolution=1.5,randomize=2718)', 13), ('algorithms.infomap(G)', 14), ('algorithms.walktrap(G)', 15), ('algorithms.markov_clustering(G,inflation=1.2,pruning_threshold=0.01,convergence_check_frequency=100)', 16), ('algorithms.markov_clustering(G,inflation=1.2,pruning_threshold=0.001,convergence_check_frequency=100)', 17), ('algorithms.markov_clustering(G,inflation=1.5,pruning_threshold=0.01,convergence_check_frequency=100)', 18), ('algorithms.markov_clustering(G,inflation=1.5,pruning_threshold=0.001,convergence_check_frequency=100)', 19), ('algorithms.markov_clustering(G,inflation=2,pruning_threshold=0.01,convergence_check_frequency=100)', 20), ('algorithms.markov_clustering(G,inflation=2,pruning_threshold=0.001,convergence_check_frequency=100)', 21), ('algorithms.markov_clustering(G,inflation=2.5,pruning_threshold=0.01,convergence_check_frequency=100)', 22), ('algorithms.markov_clustering(G,inflation=2.5,pruning_threshold=0.001,convergence_check_frequency=100)', 23), ('algorithms.em(G,k=72)', 24), ('algorithms.em(G,k=91)', 25), ('algorithms.em(G,k=49)', 26), ('algorithms.em(G,k=80)', 27), ('algorithms.sbm_dl(G)', 28), ('algorithms.spinglass(G,spins=72)', 29), ('algorithms.spinglass(G,spins=91)', 30), ('algorithms.spinglass(G,spins=49)', 31), ('algorithms.spinglass(G,spins=80)', 32), ('algorithms.ricci_community(G,alpha=0.3)', 33), ('algorithms.ricci_community(G,alpha=0.5)', 34), ('algorithms.ricci_community(G,alpha=0.6)', 35), ('algorithms.ricci_community(G,alpha=0.75)', 36)]\n"
     ]
    }
   ],
   "source": [
    "n = 1000\n",
    "expected_clusters = []\n",
    "for i in range(4):\n",
    "    expected_clusters.append(random.randint(int(n ** (1. / 3)),3*int(n ** (1. / 2))))\n",
    "    \n",
    "alg_params = {\n",
    "    \"label_propagation\": None,\n",
    "    \"leiden\": None,\n",
    "    \"significance_communities\": None,\n",
    "    \"surprise_communities\": None,\n",
    "    \"greedy_modularity\": None,\n",
    "    \"paris\": None,\n",
    "    \"louvain\": {\n",
    "        \"resolution\": [0.75, 1.0, 1.25, 1.5],\n",
    "        \"randomize\": [314159, 2718]\n",
    "    },\n",
    "    \"infomap\": None,\n",
    "    \"walktrap\": None,\n",
    "    \"markov_clustering\": {\n",
    "        \"inflation\": [1.2, 1.5, 2, 2.5],\n",
    "        \"pruning_threshold\": [0.01, 0.001],\n",
    "        \"convergence_check_frequency\": [100]\n",
    "    },\n",
    "    \"em\": {\n",
    "        \"k\": list(expected_clusters)\n",
    "    },\n",
    "    \"sbm_dl\": None,\n",
    "    \"spinglass\": {\n",
    "        \"spins\": list(expected_clusters)\n",
    "    },\n",
    "    \"ricci_community\": {\n",
    "        \"alpha\": [0.3, 0.5, 0.6, 0.75]\n",
    "    }\n",
    "}\n",
    "\n",
    "clustering_enumeration = []\n",
    "count = 0\n",
    "for alg, params in alg_params.items():\n",
    "    param_combinations = []\n",
    "    param_names = []\n",
    "    if params is not None:\n",
    "        iterables = []\n",
    "        param_names = []\n",
    "        for param in params.keys():\n",
    "            iterables.append(list(params[param]))\n",
    "            param_names.append(param)\n",
    "        param_combinations = list(itertools.product(*iterables))\n",
    "    if len(param_combinations) > 0:\n",
    "        for param_combination in param_combinations:\n",
    "            expr = \"algorithms.\"+alg+\"(G\"\n",
    "            for i in range(len(param_names)):\n",
    "                expr = expr + \",\" + param_names[i] + \"=\" + str(param_combination[i])\n",
    "            expr = expr + \")\"\n",
    "            clustering_enumeration.append((expr,count))\n",
    "            count = count + 1      \n",
    "    else:\n",
    "        expr = \"algorithms.\"+alg+\"(G)\"\n",
    "        clustering_enumeration.append((expr,count))\n",
    "        count = count + 1\n",
    "        \n",
    "print(clustering_enumeration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad03a766",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LFR/n1000/LFR_n1000_mu01_gamma30_beta11.mtx\n",
      "Number of edges in G: 9609\n",
      "Time to get sparse matrix of the graph: 0.019747495651245117\n",
      "Time to generate cluster assignment matrix: 0.01180720329284668\n",
      "Time to generate weighted consensus graph: 0.08393669128417969\n",
      "Number of non-zeroes in Aw: 17503\n",
      "Aw_nnz 17503\n",
      "Iteration 0 Aw_nnz 15694\n",
      "Iteration 1 Aw_nnz 31425\n",
      "Iteration 2 Aw_nnz 29398\n",
      "Iteration 3 Aw_nnz 18943\n",
      "Iteration 4 Aw_nnz 10775\n",
      "Iteration 5 Aw_nnz 5725\n",
      "Iteration 6 Aw_nnz 3375\n",
      "Iteration 7 Aw_nnz 2151\n",
      "Iteration 8 Aw_nnz 1580\n",
      "Iteration 9 Aw_nnz 1184\n",
      "Time to simulate MCL: 0.14886713027954102\n",
      "Time to initialize: 0.0002689361572265625\n",
      "Time to search moves: 0.5758402347564697\n",
      "Time to update M: 0.0005061626434326172\n",
      "Time to delete empty partitions: 0.00016689300537109375\n",
      "mu 1 , number of clusters 44\n",
      "Time: 1.2675745487213135\n",
      "LFR/n1000/LFR_n1000_mu02_gamma30_beta11.mtx\n",
      "Number of edges in G: 9791\n",
      "Time to get sparse matrix of the graph: 0.12459754943847656\n",
      "Time to generate cluster assignment matrix: 0.011911869049072266\n",
      "Time to generate weighted consensus graph: 0.08531355857849121\n",
      "Number of non-zeroes in Aw: 17779\n",
      "Aw_nnz 17779\n",
      "Iteration 0 Aw_nnz 13101\n",
      "Iteration 1 Aw_nnz 30652\n",
      "Iteration 2 Aw_nnz 28071\n",
      "Iteration 3 Aw_nnz 17335\n",
      "Iteration 4 Aw_nnz 8533\n",
      "Iteration 5 Aw_nnz 4163\n",
      "Iteration 6 Aw_nnz 2539\n",
      "Iteration 7 Aw_nnz 1790\n",
      "Iteration 8 Aw_nnz 1410\n",
      "Iteration 9 Aw_nnz 1199\n",
      "Time to simulate MCL: 0.13981318473815918\n",
      "Time to initialize: 0.00026917457580566406\n",
      "Time to search moves: 0.5662343502044678\n",
      "Time to update M: 0.0005168914794921875\n",
      "Time to delete empty partitions: 0.000152587890625\n",
      "mu 2 , number of clusters 46\n",
      "Time: 1.273040533065796\n",
      "LFR/n1000/LFR_n1000_mu03_gamma30_beta11.mtx\n",
      "Number of edges in G: 10049\n",
      "Time to get sparse matrix of the graph: 0.019822120666503906\n",
      "Time to generate cluster assignment matrix: 0.01179814338684082\n",
      "Time to generate weighted consensus graph: 0.08615255355834961\n",
      "Number of non-zeroes in Aw: 19887\n",
      "Aw_nnz 19887\n",
      "Iteration 0 Aw_nnz 10758\n",
      "Iteration 1 Aw_nnz 28764\n",
      "Iteration 2 Aw_nnz 25631\n",
      "Iteration 3 Aw_nnz 14820\n",
      "Iteration 4 Aw_nnz 6365\n",
      "Iteration 5 Aw_nnz 2596\n",
      "Iteration 6 Aw_nnz 1669\n",
      "Iteration 7 Aw_nnz 1298\n",
      "Iteration 8 Aw_nnz 1222\n",
      "Iteration 9 Aw_nnz 1056\n",
      "Time to simulate MCL: 0.13311433792114258\n",
      "Time to initialize: 0.0002636909484863281\n",
      "Time to search moves: 0.8542816638946533\n",
      "Time to update M: 0.0005047321319580078\n",
      "Time to delete empty partitions: 0.000152587890625\n",
      "mu 3 , number of clusters 44\n",
      "Time: 1.4909658432006836\n",
      "LFR/n1000/LFR_n1000_mu04_gamma30_beta11.mtx\n",
      "Number of edges in G: 10220\n",
      "Time to get sparse matrix of the graph: 0.019743919372558594\n",
      "Time to generate cluster assignment matrix: 0.011155843734741211\n",
      "Time to generate weighted consensus graph: 0.08612585067749023\n",
      "Number of non-zeroes in Aw: 20265\n",
      "Aw_nnz 20265\n",
      "Iteration 0 Aw_nnz 12822\n",
      "Iteration 1 Aw_nnz 25972\n",
      "Iteration 2 Aw_nnz 23175\n",
      "Iteration 3 Aw_nnz 13322\n",
      "Iteration 4 Aw_nnz 5732\n",
      "Iteration 5 Aw_nnz 2466\n",
      "Iteration 6 Aw_nnz 1487\n",
      "Iteration 7 Aw_nnz 1288\n",
      "Iteration 8 Aw_nnz 1092\n",
      "Iteration 9 Aw_nnz 1048\n",
      "Time to simulate MCL: 0.13706183433532715\n",
      "Time to initialize: 0.000263214111328125\n",
      "Time to search moves: 0.7194907665252686\n",
      "Time to update M: 0.0005009174346923828\n",
      "Time to delete empty partitions: 0.000152587890625\n",
      "mu 4 , number of clusters 96\n",
      "Time: 1.492089033126831\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "n = 1000\n",
    "fileprefix = \"LFR/\" + \"n\" + str(n) + \"/\"\n",
    "mus = [1, 2, 3, 4]\n",
    "#mus = [4]\n",
    "gammas = [30]\n",
    "betas = [11]\n",
    "for mu in mus:\n",
    "    for gamma in gammas:\n",
    "        for beta in betas:\n",
    "            P_list = []\n",
    "            fname = \"LFR_n\" + str(n) + \"_mu0\" + str(mu) + \"_gamma\" + str(gamma) + \"_beta\" + str(beta)\n",
    "            graph_file = fileprefix + fname + \".mtx\"\n",
    "            print(graph_file)\n",
    "            G = None\n",
    "            with open(graph_file) as f:\n",
    "                G = nx.from_scipy_sparse_array(spio.mmread(f), create_using=nx.Graph)\n",
    "                coms = None\n",
    "                for k in clustering_enumeration:\n",
    "                    clust_file = fileprefix + fname + \".\" + str(k[1])\n",
    "                    if Path(clust_file).is_file():\n",
    "                        partition = read_clust_lst(clust_file)\n",
    "                        P_list.append({\"graph\": nx.Graph(G), \"partition\": list(partition)})\n",
    "                t1 = time.time()\n",
    "                P_star = v6_consensus(P_list, niter=1000, starting_partition=None, verbose=False)\n",
    "                t2 = time.time()\n",
    "                print(\"mu\", mu, \", number of clusters\", len(P_star[\"partition\"]))\n",
    "                print(\"Time:\", t2-t1)\n",
    "                #write_clust_lst(P_star[\"partition\"], fileprefix + fname + \".\" + cons_name)\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d9c52b",
   "metadata": {},
   "source": [
    "# n=5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "68555d8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('algorithms.label_propagation(G)', 0), ('algorithms.leiden(G)', 1), ('algorithms.significance_communities(G)', 2), ('algorithms.surprise_communities(G)', 3), ('algorithms.greedy_modularity(G)', 4), ('algorithms.paris(G)', 5), ('algorithms.louvain(G,resolution=0.75,randomize=314159)', 6), ('algorithms.louvain(G,resolution=0.75,randomize=2718)', 7), ('algorithms.louvain(G,resolution=1.0,randomize=314159)', 8), ('algorithms.louvain(G,resolution=1.0,randomize=2718)', 9), ('algorithms.louvain(G,resolution=1.25,randomize=314159)', 10), ('algorithms.louvain(G,resolution=1.25,randomize=2718)', 11), ('algorithms.louvain(G,resolution=1.5,randomize=314159)', 12), ('algorithms.louvain(G,resolution=1.5,randomize=2718)', 13), ('algorithms.infomap(G)', 14), ('algorithms.walktrap(G)', 15), ('algorithms.markov_clustering(G,inflation=1.2,pruning_threshold=0.01,convergence_check_frequency=100)', 16), ('algorithms.markov_clustering(G,inflation=1.2,pruning_threshold=0.001,convergence_check_frequency=100)', 17), ('algorithms.markov_clustering(G,inflation=1.5,pruning_threshold=0.01,convergence_check_frequency=100)', 18), ('algorithms.markov_clustering(G,inflation=1.5,pruning_threshold=0.001,convergence_check_frequency=100)', 19), ('algorithms.markov_clustering(G,inflation=2,pruning_threshold=0.01,convergence_check_frequency=100)', 20), ('algorithms.markov_clustering(G,inflation=2,pruning_threshold=0.001,convergence_check_frequency=100)', 21), ('algorithms.markov_clustering(G,inflation=2.5,pruning_threshold=0.01,convergence_check_frequency=100)', 22), ('algorithms.markov_clustering(G,inflation=2.5,pruning_threshold=0.001,convergence_check_frequency=100)', 23), ('algorithms.em(G,k=118)', 24), ('algorithms.em(G,k=67)', 25), ('algorithms.em(G,k=197)', 26), ('algorithms.em(G,k=117)', 27), ('algorithms.sbm_dl(G)', 28), ('algorithms.spinglass(G,spins=118)', 29), ('algorithms.spinglass(G,spins=67)', 30), ('algorithms.spinglass(G,spins=197)', 31), ('algorithms.spinglass(G,spins=117)', 32), ('algorithms.ricci_community(G,alpha=0.3)', 33), ('algorithms.ricci_community(G,alpha=0.5)', 34), ('algorithms.ricci_community(G,alpha=0.6)', 35), ('algorithms.ricci_community(G,alpha=0.75)', 36)]\n"
     ]
    }
   ],
   "source": [
    "n = 5000\n",
    "expected_clusters = []\n",
    "for i in range(4):\n",
    "    expected_clusters.append(random.randint(int(n ** (1. / 3)),3*int(n ** (1. / 2))))\n",
    "    \n",
    "alg_params = {\n",
    "    \"label_propagation\": None,\n",
    "    \"leiden\": None,\n",
    "    \"significance_communities\": None,\n",
    "    \"surprise_communities\": None,\n",
    "    \"greedy_modularity\": None,\n",
    "    \"paris\": None,\n",
    "    \"louvain\": {\n",
    "        \"resolution\": [0.75, 1.0, 1.25, 1.5],\n",
    "        \"randomize\": [314159, 2718]\n",
    "    },\n",
    "    \"infomap\": None,\n",
    "    \"walktrap\": None,\n",
    "    \"markov_clustering\": {\n",
    "        \"inflation\": [1.2, 1.5, 2, 2.5],\n",
    "        \"pruning_threshold\": [0.01, 0.001],\n",
    "        \"convergence_check_frequency\": [100]\n",
    "    },\n",
    "    \"em\": {\n",
    "        \"k\": list(expected_clusters)\n",
    "    },\n",
    "    \"sbm_dl\": None,\n",
    "    \"spinglass\": {\n",
    "        \"spins\": list(expected_clusters)\n",
    "    },\n",
    "    \"ricci_community\": {\n",
    "        \"alpha\": [0.3, 0.5, 0.6, 0.75]\n",
    "    }\n",
    "}\n",
    "\n",
    "clustering_enumeration = []\n",
    "count = 0\n",
    "for alg, params in alg_params.items():\n",
    "    param_combinations = []\n",
    "    param_names = []\n",
    "    if params is not None:\n",
    "        iterables = []\n",
    "        param_names = []\n",
    "        for param in params.keys():\n",
    "            iterables.append(list(params[param]))\n",
    "            param_names.append(param)\n",
    "        param_combinations = list(itertools.product(*iterables))\n",
    "    if len(param_combinations) > 0:\n",
    "        for param_combination in param_combinations:\n",
    "            expr = \"algorithms.\"+alg+\"(G\"\n",
    "            for i in range(len(param_names)):\n",
    "                expr = expr + \",\" + param_names[i] + \"=\" + str(param_combination[i])\n",
    "            expr = expr + \")\"\n",
    "            clustering_enumeration.append((expr,count))\n",
    "            count = count + 1      \n",
    "    else:\n",
    "        expr = \"algorithms.\"+alg+\"(G)\"\n",
    "        clustering_enumeration.append((expr,count))\n",
    "        count = count + 1\n",
    "        \n",
    "print(clustering_enumeration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f067cc96",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LFR/n5000/LFR_n5000_mu01_gamma30_beta11.mtx\n",
      "Number of edges in G: 48950\n",
      "Time to get sparse matrix of the graph: 0.37200188636779785\n",
      "Time to generate cluster assignment matrix: 0.0628213882446289\n",
      "Time to generate weighted consensus graph: 0.4245913028717041\n",
      "Number of non-zeroes in Aw: 88672\n",
      "Aw_nnz 88672\n",
      "Iteration 0 Aw_nnz 79927\n",
      "Iteration 1 Aw_nnz 149875\n",
      "Iteration 2 Aw_nnz 135620\n",
      "Iteration 3 Aw_nnz 94563\n",
      "Iteration 4 Aw_nnz 53845\n",
      "Iteration 5 Aw_nnz 30113\n",
      "Iteration 6 Aw_nnz 16682\n",
      "Iteration 7 Aw_nnz 10252\n",
      "Iteration 8 Aw_nnz 7831\n",
      "Iteration 9 Aw_nnz 6600\n",
      "Time to simulate MCL: 0.7736890316009521\n",
      "Time to initialize: 0.0013642311096191406\n",
      "Time to search moves: 4.242081642150879\n",
      "Time to update M: 0.002650737762451172\n",
      "Time to delete empty partitions: 0.0007393360137939453\n",
      "mu 1 , number of clusters 243\n",
      "Time: 7.749377727508545\n",
      "LFR/n5000/LFR_n5000_mu02_gamma30_beta11.mtx\n",
      "Number of edges in G: 50068\n",
      "Time to get sparse matrix of the graph: 0.3930835723876953\n",
      "Time to generate cluster assignment matrix: 0.0638430118560791\n",
      "Time to generate weighted consensus graph: 0.41480326652526855\n",
      "Number of non-zeroes in Aw: 84929\n",
      "Aw_nnz 84929\n",
      "Iteration 0 Aw_nnz 66782\n",
      "Iteration 1 Aw_nnz 147212\n",
      "Iteration 2 Aw_nnz 126550\n",
      "Iteration 3 Aw_nnz 77103\n",
      "Iteration 4 Aw_nnz 38942\n",
      "Iteration 5 Aw_nnz 20711\n",
      "Iteration 6 Aw_nnz 12164\n",
      "Iteration 7 Aw_nnz 7708\n",
      "Iteration 8 Aw_nnz 6458\n",
      "Iteration 9 Aw_nnz 5697\n",
      "Time to simulate MCL: 0.7256441116333008\n",
      "Time to initialize: 0.0014231204986572266\n",
      "Time to search moves: 4.18104887008667\n",
      "Time to update M: 0.0026695728302001953\n",
      "Time to delete empty partitions: 0.0007598400115966797\n",
      "mu 2 , number of clusters 227\n",
      "Time: 7.5968616008758545\n",
      "LFR/n5000/LFR_n5000_mu03_gamma30_beta11.mtx\n",
      "Number of edges in G: 51119\n",
      "Time to get sparse matrix of the graph: 0.3731057643890381\n",
      "Time to generate cluster assignment matrix: 0.06324052810668945\n",
      "Time to generate weighted consensus graph: 0.4404747486114502\n",
      "Number of non-zeroes in Aw: 86390\n",
      "Aw_nnz 86390\n",
      "Iteration 0 Aw_nnz 54298\n",
      "Iteration 1 Aw_nnz 139698\n",
      "Iteration 2 Aw_nnz 116367\n",
      "Iteration 3 Aw_nnz 63201\n",
      "Iteration 4 Aw_nnz 27157\n",
      "Iteration 5 Aw_nnz 13553\n",
      "Iteration 6 Aw_nnz 9089\n",
      "Iteration 7 Aw_nnz 6887\n",
      "Iteration 8 Aw_nnz 5810\n",
      "Iteration 9 Aw_nnz 5302\n",
      "Time to simulate MCL: 0.6639342308044434\n",
      "Time to initialize: 0.001382589340209961\n",
      "Time to search moves: 2.7024223804473877\n",
      "Time to update M: 0.0029430389404296875\n",
      "Time to delete empty partitions: 0.0007600784301757812\n",
      "mu 3 , number of clusters 230\n",
      "Time: 6.015172719955444\n",
      "LFR/n5000/LFR_n5000_mu04_gamma30_beta11.mtx\n",
      "Number of edges in G: 51757\n",
      "Time to get sparse matrix of the graph: 0.11705303192138672\n",
      "Time to generate cluster assignment matrix: 0.0632619857788086\n",
      "Time to generate weighted consensus graph: 0.43816614151000977\n",
      "Number of non-zeroes in Aw: 102571\n",
      "Aw_nnz 102571\n",
      "Iteration 0 Aw_nnz 43434\n",
      "Iteration 1 Aw_nnz 126132\n",
      "Iteration 2 Aw_nnz 100174\n",
      "Iteration 3 Aw_nnz 45192\n",
      "Iteration 4 Aw_nnz 20047\n",
      "Iteration 5 Aw_nnz 10668\n",
      "Iteration 6 Aw_nnz 7602\n",
      "Iteration 7 Aw_nnz 6313\n",
      "Iteration 8 Aw_nnz 5691\n",
      "Iteration 9 Aw_nnz 5374\n",
      "Time to simulate MCL: 0.6109495162963867\n",
      "Time to initialize: 0.0012776851654052734\n",
      "Time to search moves: 5.043804168701172\n",
      "Time to update M: 0.002526998519897461\n",
      "Time to delete empty partitions: 0.0007319450378417969\n",
      "mu 4 , number of clusters 435\n",
      "Time: 8.525465488433838\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "n = 5000\n",
    "fileprefix = \"LFR/\" + \"n\" + str(n) + \"/\"\n",
    "mus = [1, 2, 3, 4]\n",
    "#mus = [4]\n",
    "gammas = [30]\n",
    "betas = [11]\n",
    "for mu in mus:\n",
    "    for gamma in gammas:\n",
    "        for beta in betas:\n",
    "            P_list = []\n",
    "            fname = \"LFR_n\" + str(n) + \"_mu0\" + str(mu) + \"_gamma\" + str(gamma) + \"_beta\" + str(beta)\n",
    "            graph_file = fileprefix + fname + \".mtx\"\n",
    "            print(graph_file)\n",
    "            G = None\n",
    "            with open(graph_file) as f:\n",
    "                G = nx.from_scipy_sparse_array(spio.mmread(f), create_using=nx.Graph)\n",
    "                coms = None\n",
    "                for k in clustering_enumeration:\n",
    "                    clust_file = fileprefix + fname + \".\" + str(k[1])\n",
    "                    if Path(clust_file).is_file():\n",
    "                        partition = read_clust_lst(clust_file)\n",
    "                        P_list.append({\"graph\": nx.Graph(G), \"partition\": list(partition)})\n",
    "                t1 = time.time()\n",
    "                P_star = v6_consensus(P_list, niter=1000, starting_partition = None, verbose=False)\n",
    "                t2 = time.time()\n",
    "                print(\"mu\", mu, \", number of clusters\", len(P_star[\"partition\"]))\n",
    "                print(\"Time:\", t2-t1)\n",
    "                #write_clust_lst(P_star[\"partition\"], fileprefix + fname + \".\" + cons_name)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfde8eef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
