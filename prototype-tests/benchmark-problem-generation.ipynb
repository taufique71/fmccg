{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3b6a3b4",
   "metadata": {},
   "source": [
    "# Benchmark network analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e74a874c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import networkx.algorithms.community as nx_comm\n",
    "from networkx.generators.community import LFR_benchmark_graph\n",
    "from networkx.algorithms import bipartite\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy.sparse import coo_array\n",
    "from scipy import sparse\n",
    "from cdlib import algorithms\n",
    "from cdlib import evaluation\n",
    "import sklearn\n",
    "from utils import *\n",
    "from distances import *\n",
    "from consensus import *\n",
    "import math\n",
    "import itertools\n",
    "import random\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45fb6d70",
   "metadata": {},
   "source": [
    "# Generate benchmark graphs\n",
    "\n",
    "- https://arxiv.org/pdf/0805.4770.pdf\n",
    "- https://networkx.org/documentation/stable/reference/generated/networkx.generators.community.LFR_benchmark_graph.html\n",
    "- https://stackoverflow.com/questions/53608425/how-tune-lfr-benchmark-graph-method-in-networkx-for-generating-large-graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3fdc5f",
   "metadata": {},
   "source": [
    "## 200 node graph\n",
    "Parameters:\n",
    "- Number of nodes $n=200$\n",
    "- Inter-cluster edge probability $\\mu \\in \\{ 0.1, 0.2, 0.3, 0.4 \\}$\n",
    "- Degree distribution parameter (Power-law exponent) $\\gamma = 3.0$\n",
    "- Community size distribution parameter (Power-law exponent) $\\beta = 1.1$\n",
    "- Minimum degree: $5$\n",
    "- Maximum degree: $50$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc9912c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import networkx.algorithms.community as nx_comm\n",
    "from networkx.generators.community import LFR_benchmark_graph\n",
    "from networkx.algorithms import bipartite\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy import sparse\n",
    "n = 200\n",
    "fileprefix = \"LFR/\" + \"n\" + str(n) + \"/\"\n",
    "mus = [1, 2, 3, 4]\n",
    "gammas = [30]\n",
    "betas = [11]\n",
    "for mu in mus:\n",
    "    for gamma in gammas:\n",
    "        for beta in betas:\n",
    "            fname = \"LFR_n\" + str(n) + \"_mu0\" + str(mu) + \"_gamma\" + str(gamma) + \"_beta\" + str(beta)\n",
    "            G = LFR_benchmark_graph(n, (float(gamma) / 10), (float(beta) / 10), (float(mu) / 10), seed=10, min_degree=5, max_degree=50)\n",
    "            m = nx.to_scipy_sparse_array(G)\n",
    "            sp.io.mmwrite(fileprefix + fname + \".mtx\", m)\n",
    "            clust_lst = {frozenset(G.nodes[v][\"community\"]) for v in G}\n",
    "            #nx.write_edgelist(G, fileprefix + name + \".edgelist\", data=False)\n",
    "            write_clust_lst(clust_lst, fileprefix + fname + \".gt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11fd3efb",
   "metadata": {},
   "source": [
    "### Clustering algorithm parameter configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df2aa555",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 200\n",
    "expected_clusters = []\n",
    "for i in range(4):\n",
    "    expected_clusters.append(random.randint(int(n ** (1. / 3)),3*int(n ** (1. / 2))))\n",
    "    \n",
    "alg_params = {\n",
    "    \"label_propagation\": None,\n",
    "    \"leiden\": None,\n",
    "    \"significance_communities\": None,\n",
    "    \"surprise_communities\": None,\n",
    "    \"greedy_modularity\": None,\n",
    "    \"paris\": None,\n",
    "    \"louvain\": {\n",
    "        \"resolution\": [0.75, 1.0, 1.25, 1.5],\n",
    "        \"randomize\": [314159, 2718]\n",
    "    },\n",
    "    \"infomap\": None,\n",
    "    \"walktrap\": None,\n",
    "    \"markov_clustering\": {\n",
    "        \"inflation\": [1.2, 1.5, 2, 2.5],\n",
    "        \"pruning_threshold\": [0.01, 0.001],\n",
    "        \"convergence_check_frequency\": [100]\n",
    "    },\n",
    "    \"em\": {\n",
    "        \"k\": list(expected_clusters)\n",
    "    },\n",
    "    \"sbm_dl\": None,\n",
    "    \"spinglass\": {\n",
    "        \"spins\": list(expected_clusters)\n",
    "    },\n",
    "    \"ricci_community\": {\n",
    "        \"alpha\": [0.3, 0.5, 0.6, 0.75]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4decf1",
   "metadata": {},
   "source": [
    "### Run different algorithms on generated benchmark networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f451ef6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 algorithms.label_propagation(G) 20\n",
      "1 algorithms.leiden(G) 12\n",
      "2 algorithms.significance_communities(G) 26\n",
      "3 algorithms.surprise_communities(G) 199\n",
      "4 algorithms.greedy_modularity(G) 10\n",
      "5 algorithms.paris(G) 15\n",
      "6 algorithms.louvain(G,resolution=0.75,randomize=314159) 12\n",
      "7 algorithms.louvain(G,resolution=0.75,randomize=2718) 12\n",
      "8 algorithms.louvain(G,resolution=1.0,randomize=314159) 12\n",
      "9 algorithms.louvain(G,resolution=1.0,randomize=2718) 12\n",
      "10 algorithms.louvain(G,resolution=1.25,randomize=314159) 14\n",
      "11 algorithms.louvain(G,resolution=1.25,randomize=2718) 14\n",
      "12 algorithms.louvain(G,resolution=1.5,randomize=314159) 14\n",
      "13 algorithms.louvain(G,resolution=1.5,randomize=2718) 14\n",
      "14 algorithms.infomap(G) 16\n",
      "15 algorithms.walktrap(G) 15\n",
      "16 algorithms.markov_clustering(G,inflation=1.2,pruning_threshold=0.01,convergence_check_frequency=100) 12\n",
      "17 algorithms.markov_clustering(G,inflation=1.2,pruning_threshold=0.001,convergence_check_frequency=100) 1\n",
      "18 algorithms.markov_clustering(G,inflation=1.5,pruning_threshold=0.01,convergence_check_frequency=100) 16\n",
      "19 algorithms.markov_clustering(G,inflation=1.5,pruning_threshold=0.001,convergence_check_frequency=100) 15\n",
      "20 algorithms.markov_clustering(G,inflation=2,pruning_threshold=0.01,convergence_check_frequency=100) 19\n",
      "21 algorithms.markov_clustering(G,inflation=2,pruning_threshold=0.001,convergence_check_frequency=100) 19\n",
      "22 algorithms.markov_clustering(G,inflation=2.5,pruning_threshold=0.01,convergence_check_frequency=100) 31\n",
      "23 algorithms.markov_clustering(G,inflation=2.5,pruning_threshold=0.001,convergence_check_frequency=100) 31\n",
      "24 algorithms.em(G,k=21) 12\n",
      "25 algorithms.em(G,k=13) 9\n",
      "26 algorithms.em(G,k=41) 16\n",
      "27 algorithms.em(G,k=15) 8\n",
      "28 algorithms.sbm_dl(G) 13\n",
      "29 algorithms.spinglass(G,spins=21) 14\n",
      "30 algorithms.spinglass(G,spins=13) 12\n",
      "31 algorithms.spinglass(G,spins=41) 15\n",
      "32 algorithms.spinglass(G,spins=15) 12\n",
      "33 algorithms.ricci_community(G,alpha=0.3) 14\n",
      "34 algorithms.ricci_community(G,alpha=0.5) 15\n",
      "35 algorithms.ricci_community(G,alpha=0.6) 13\n",
      "36 algorithms.ricci_community(G,alpha=0.75) 14\n",
      "0 algorithms.label_propagation(G) 13\n",
      "1 algorithms.leiden(G) 12\n",
      "2 algorithms.significance_communities(G) 33\n",
      "3 algorithms.surprise_communities(G) 199\n",
      "4 algorithms.greedy_modularity(G) 9\n",
      "5 algorithms.paris(G) 13\n",
      "6 algorithms.louvain(G,resolution=0.75,randomize=314159) 16\n",
      "7 algorithms.louvain(G,resolution=0.75,randomize=2718) 16\n",
      "8 algorithms.louvain(G,resolution=1.0,randomize=314159) 12\n",
      "9 algorithms.louvain(G,resolution=1.0,randomize=2718) 12\n",
      "10 algorithms.louvain(G,resolution=1.25,randomize=314159) 14\n",
      "11 algorithms.louvain(G,resolution=1.25,randomize=2718) 14\n",
      "12 algorithms.louvain(G,resolution=1.5,randomize=314159) 14\n",
      "13 algorithms.louvain(G,resolution=1.5,randomize=2718) 14\n",
      "14 algorithms.infomap(G) 15\n",
      "15 algorithms.walktrap(G) 16\n",
      "16 algorithms.markov_clustering(G,inflation=1.2,pruning_threshold=0.01,convergence_check_frequency=100) 9\n",
      "17 algorithms.markov_clustering(G,inflation=1.2,pruning_threshold=0.001,convergence_check_frequency=100) 1\n",
      "18 algorithms.markov_clustering(G,inflation=1.5,pruning_threshold=0.01,convergence_check_frequency=100) 16\n",
      "19 algorithms.markov_clustering(G,inflation=1.5,pruning_threshold=0.001,convergence_check_frequency=100) 14\n",
      "20 algorithms.markov_clustering(G,inflation=2,pruning_threshold=0.01,convergence_check_frequency=100) 18\n",
      "21 algorithms.markov_clustering(G,inflation=2,pruning_threshold=0.001,convergence_check_frequency=100) 18\n",
      "22 algorithms.markov_clustering(G,inflation=2.5,pruning_threshold=0.01,convergence_check_frequency=100) 45\n",
      "23 algorithms.markov_clustering(G,inflation=2.5,pruning_threshold=0.001,convergence_check_frequency=100) 43\n",
      "24 algorithms.em(G,k=21) 6\n",
      "25 algorithms.em(G,k=13) 10\n",
      "26 algorithms.em(G,k=41) 26\n",
      "27 algorithms.em(G,k=15) 5\n",
      "28 algorithms.sbm_dl(G) 16\n",
      "29 algorithms.spinglass(G,spins=21) 13\n",
      "30 algorithms.spinglass(G,spins=13) 11\n",
      "31 algorithms.spinglass(G,spins=41) 15\n",
      "32 algorithms.spinglass(G,spins=15) 13\n",
      "33 algorithms.ricci_community(G,alpha=0.3) 12\n",
      "34 algorithms.ricci_community(G,alpha=0.5) 15\n",
      "35 algorithms.ricci_community(G,alpha=0.6) 16\n",
      "36 algorithms.ricci_community(G,alpha=0.75) 16\n",
      "0 algorithms.label_propagation(G) 2\n",
      "1 algorithms.leiden(G) 12\n",
      "2 algorithms.significance_communities(G) 44\n",
      "3 algorithms.surprise_communities(G) 199\n",
      "4 algorithms.greedy_modularity(G) 7\n",
      "5 algorithms.paris(G) 2\n",
      "6 algorithms.louvain(G,resolution=0.75,randomize=314159) 23\n",
      "7 algorithms.louvain(G,resolution=0.75,randomize=2718) 10\n",
      "8 algorithms.louvain(G,resolution=1.0,randomize=314159) 11\n",
      "9 algorithms.louvain(G,resolution=1.0,randomize=2718) 11\n",
      "10 algorithms.louvain(G,resolution=1.25,randomize=314159) 14\n",
      "11 algorithms.louvain(G,resolution=1.25,randomize=2718) 12\n",
      "12 algorithms.louvain(G,resolution=1.5,randomize=314159) 13\n",
      "13 algorithms.louvain(G,resolution=1.5,randomize=2718) 13\n",
      "14 algorithms.infomap(G) 15\n",
      "15 algorithms.walktrap(G) 19\n",
      "16 algorithms.markov_clustering(G,inflation=1.2,pruning_threshold=0.01,convergence_check_frequency=100) 2\n",
      "17 algorithms.markov_clustering(G,inflation=1.2,pruning_threshold=0.001,convergence_check_frequency=100) 1\n",
      "18 algorithms.markov_clustering(G,inflation=1.5,pruning_threshold=0.01,convergence_check_frequency=100) 12\n",
      "19 algorithms.markov_clustering(G,inflation=1.5,pruning_threshold=0.001,convergence_check_frequency=100) 3\n",
      "20 algorithms.markov_clustering(G,inflation=2,pruning_threshold=0.01,convergence_check_frequency=100) 50\n",
      "21 algorithms.markov_clustering(G,inflation=2,pruning_threshold=0.001,convergence_check_frequency=100) 46\n",
      "22 algorithms.markov_clustering(G,inflation=2.5,pruning_threshold=0.01,convergence_check_frequency=100) 105\n",
      "23 algorithms.markov_clustering(G,inflation=2.5,pruning_threshold=0.001,convergence_check_frequency=100) 105\n",
      "24 algorithms.em(G,k=21) 7\n",
      "25 algorithms.em(G,k=13) 6\n",
      "26 algorithms.em(G,k=41) 7\n",
      "27 algorithms.em(G,k=15) 5\n",
      "28 algorithms.sbm_dl(G) 10\n",
      "29 algorithms.spinglass(G,spins=21) 13\n",
      "30 algorithms.spinglass(G,spins=13) 11\n",
      "31 algorithms.spinglass(G,spins=41) 12\n",
      "32 algorithms.spinglass(G,spins=15) 12\n",
      "33 algorithms.ricci_community(G,alpha=0.3) 17\n",
      "34 algorithms.ricci_community(G,alpha=0.5) 16\n",
      "35 algorithms.ricci_community(G,alpha=0.6) 13\n",
      "36 algorithms.ricci_community(G,alpha=0.75) 17\n",
      "0 algorithms.label_propagation(G) 1\n",
      "1 algorithms.leiden(G) 9\n",
      "2 algorithms.significance_communities(G) 58\n",
      "3 algorithms.surprise_communities(G) 199\n",
      "4 algorithms.greedy_modularity(G) 8\n",
      "5 algorithms.paris(G) 10\n",
      "6 algorithms.louvain(G,resolution=0.75,randomize=314159) 22\n",
      "7 algorithms.louvain(G,resolution=0.75,randomize=2718) 24\n",
      "8 algorithms.louvain(G,resolution=1.0,randomize=314159) 10\n",
      "9 algorithms.louvain(G,resolution=1.0,randomize=2718) 11\n",
      "10 algorithms.louvain(G,resolution=1.25,randomize=314159) 13\n",
      "11 algorithms.louvain(G,resolution=1.25,randomize=2718) 13\n",
      "12 algorithms.louvain(G,resolution=1.5,randomize=314159) 15\n",
      "13 algorithms.louvain(G,resolution=1.5,randomize=2718) 17\n",
      "14 algorithms.infomap(G) 11\n",
      "15 algorithms.walktrap(G) 12\n",
      "16 algorithms.markov_clustering(G,inflation=1.2,pruning_threshold=0.01,convergence_check_frequency=100) 1\n",
      "17 algorithms.markov_clustering(G,inflation=1.2,pruning_threshold=0.001,convergence_check_frequency=100) 1\n",
      "18 algorithms.markov_clustering(G,inflation=1.5,pruning_threshold=0.01,convergence_check_frequency=100) 3\n",
      "19 algorithms.markov_clustering(G,inflation=1.5,pruning_threshold=0.001,convergence_check_frequency=100) 1\n",
      "20 algorithms.markov_clustering(G,inflation=2,pruning_threshold=0.01,convergence_check_frequency=100) 83\n",
      "21 algorithms.markov_clustering(G,inflation=2,pruning_threshold=0.001,convergence_check_frequency=100) 74\n",
      "22 algorithms.markov_clustering(G,inflation=2.5,pruning_threshold=0.01,convergence_check_frequency=100) 174\n",
      "23 algorithms.markov_clustering(G,inflation=2.5,pruning_threshold=0.001,convergence_check_frequency=100) 174\n",
      "24 algorithms.em(G,k=21) 8\n",
      "25 algorithms.em(G,k=13) 8\n",
      "26 algorithms.em(G,k=41) 21\n",
      "27 algorithms.em(G,k=15) 7\n",
      "28 algorithms.sbm_dl(G) 1\n",
      "29 algorithms.spinglass(G,spins=21) 9\n",
      "30 algorithms.spinglass(G,spins=13) 9\n",
      "31 algorithms.spinglass(G,spins=41) 11\n",
      "32 algorithms.spinglass(G,spins=15) 8\n",
      "33 algorithms.ricci_community(G,alpha=0.3) 5\n",
      "34 algorithms.ricci_community(G,alpha=0.5) 4\n",
      "35 algorithms.ricci_community(G,alpha=0.6) 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36 algorithms.ricci_community(G,alpha=0.75) 5\n"
     ]
    }
   ],
   "source": [
    "n = 200\n",
    "fileprefix = \"LFR/\" + \"n\" + str(n) + \"/\"\n",
    "mus = [1, 2, 3, 4]\n",
    "#mus = [1]\n",
    "gammas = [30]\n",
    "betas = [11]\n",
    "for mu in mus:\n",
    "    for gamma in gammas:\n",
    "        for beta in betas:\n",
    "            fname = \"LFR_n\" + str(n) + \"_mu0\" + str(mu) + \"_gamma\" + str(gamma) + \"_beta\" + str(beta)\n",
    "            graph_file = fileprefix + fname + \".mtx\"\n",
    "            G = None\n",
    "            with open(graph_file) as f:\n",
    "                G = nx.from_scipy_sparse_array(spio.mmread(f), create_using=nx.Graph)\n",
    "                count = 0\n",
    "                comms = None\n",
    "                for alg, params in alg_params.items():\n",
    "                    param_combinations = []\n",
    "                    param_names = []\n",
    "                    if params is not None:\n",
    "                        iterables = []\n",
    "                        param_names = []\n",
    "                        for param in params.keys():\n",
    "                            iterables.append(list(params[param]))\n",
    "                            param_names.append(param)\n",
    "                        param_combinations = list(itertools.product(*iterables))\n",
    "                    if len(param_combinations) > 0:\n",
    "                        for param_combination in param_combinations:\n",
    "                            expr = \"algorithms.\"+alg+\"(G\"\n",
    "                            for i in range(len(param_names)):\n",
    "                                expr = expr + \",\" + param_names[i] + \"=\" + str(param_combination[i])\n",
    "                            expr = expr + \")\"\n",
    "                            try:\n",
    "                                coms = eval(expr)\n",
    "                                print(count, expr, len(coms.communities))\n",
    "                                write_clust_lst(coms.communities, fileprefix + fname + \".\" + str(count))\n",
    "                                count = count + 1\n",
    "                            except:\n",
    "                                print(\"UNSUCCESSFUL\", expr)       \n",
    "                    else:\n",
    "                        expr = \"algorithms.\"+alg+\"(G)\"\n",
    "                        try:\n",
    "                            coms = eval(expr)\n",
    "                            print(count, expr, len(coms.communities))\n",
    "                            write_clust_lst(coms.communities, fileprefix + fname + \".\" + str(count))\n",
    "                            count = count + 1\n",
    "                        except:\n",
    "                            print(\"UNSUCCESSFUL\", expr)\n",
    "\n",
    "                    #coms = eval()\n",
    "                #write_clust_lst(coms.communities, fileprefix + fname + \".\" + alg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84cda5fe",
   "metadata": {},
   "source": [
    "## 1000 node graph\n",
    "Parameters:\n",
    "- Number of nodes $n=1000$\n",
    "- Inter-cluster edge probability $\\mu \\in \\{ 0.1, 0.2, 0.3, 0.4 \\}$\n",
    "- Degree distribution parameter (Power-law exponent) $\\gamma = 3.0$\n",
    "- Community size distribution parameter (Power-law exponent) $\\beta = 1.1$\n",
    "- Minimum degree: $10$\n",
    "- Maximum degree: $50$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "63cad7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import networkx.algorithms.community as nx_comm\n",
    "from networkx.generators.community import LFR_benchmark_graph\n",
    "from networkx.algorithms import bipartite\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy import sparse\n",
    "n = 1000\n",
    "fileprefix = \"LFR/\" + \"n\" + str(n) + \"/\"\n",
    "mus = [1, 2, 3, 4]\n",
    "gammas = [30]\n",
    "betas = [11]\n",
    "for mu in mus:\n",
    "    for gamma in gammas:\n",
    "        for beta in betas:\n",
    "            fname = \"LFR_n\" + str(n) + \"_mu0\" + str(mu) + \"_gamma\" + str(gamma) + \"_beta\" + str(beta)\n",
    "            G = LFR_benchmark_graph(n, (float(gamma) / 10), (float(beta) / 10), (float(mu) / 10), seed=10, min_degree=10, max_degree=50)\n",
    "            m = nx.to_scipy_sparse_array(G)\n",
    "            sp.io.mmwrite(fileprefix + fname + \".mtx\", m)\n",
    "            clust_lst = {frozenset(G.nodes[v][\"community\"]) for v in G}\n",
    "            #nx.write_edgelist(G, fileprefix + name + \".edgelist\", data=False)\n",
    "            write_clust_lst(clust_lst, fileprefix + fname + \".gt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd02cf4",
   "metadata": {},
   "source": [
    "### Clustering algorithm parameter configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c8b980f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1000\n",
    "expected_clusters = []\n",
    "for i in range(4):\n",
    "    expected_clusters.append(random.randint(int(n ** (1. / 3)),3*int(n ** (1. / 2))))\n",
    "    \n",
    "alg_params = {\n",
    "    \"label_propagation\": None,\n",
    "    \"leiden\": None,\n",
    "    \"significance_communities\": None,\n",
    "    \"surprise_communities\": None,\n",
    "    \"greedy_modularity\": None,\n",
    "    \"paris\": None,\n",
    "    \"louvain\": {\n",
    "        \"resolution\": [0.75, 1.0, 1.25, 1.5],\n",
    "        \"randomize\": [314159, 2718]\n",
    "    },\n",
    "    \"infomap\": None,\n",
    "    \"walktrap\": None,\n",
    "    \"markov_clustering\": {\n",
    "        \"inflation\": [1.2, 1.5, 2, 2.5],\n",
    "        \"pruning_threshold\": [0.01, 0.001],\n",
    "        \"convergence_check_frequency\": [100]\n",
    "    },\n",
    "    \"em\": {\n",
    "        \"k\": list(expected_clusters)\n",
    "    },\n",
    "    \"sbm_dl\": None,\n",
    "    \"spinglass\": {\n",
    "        \"spins\": list(expected_clusters)\n",
    "    },\n",
    "    \"ricci_community\": {\n",
    "        \"alpha\": [0.3, 0.5, 0.6, 0.75]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11162f8d",
   "metadata": {},
   "source": [
    "### Run different algorithms on generated benchmark networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e7176582",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 algorithms.label_propagation(G) 32\n",
      "1 algorithms.leiden(G) 37\n",
      "2 algorithms.significance_communities(G) 38\n",
      "3 algorithms.surprise_communities(G) 999\n",
      "4 algorithms.greedy_modularity(G) 25\n",
      "5 algorithms.paris(G) 38\n",
      "6 algorithms.louvain(G,resolution=0.75,randomize=314159) 38\n",
      "7 algorithms.louvain(G,resolution=0.75,randomize=2718) 38\n",
      "8 algorithms.louvain(G,resolution=1.0,randomize=314159) 37\n",
      "9 algorithms.louvain(G,resolution=1.0,randomize=2718) 37\n",
      "10 algorithms.louvain(G,resolution=1.25,randomize=314159) 38\n",
      "11 algorithms.louvain(G,resolution=1.25,randomize=2718) 38\n",
      "12 algorithms.louvain(G,resolution=1.5,randomize=314159) 38\n",
      "13 algorithms.louvain(G,resolution=1.5,randomize=2718) 38\n",
      "14 algorithms.infomap(G) 38\n",
      "15 algorithms.walktrap(G) 38\n",
      "16 algorithms.markov_clustering(G,inflation=1.2,pruning_threshold=0.01,convergence_check_frequency=100) 38\n",
      "17 algorithms.markov_clustering(G,inflation=1.2,pruning_threshold=0.001,convergence_check_frequency=100) 37\n",
      "18 algorithms.markov_clustering(G,inflation=1.5,pruning_threshold=0.01,convergence_check_frequency=100) 38\n",
      "19 algorithms.markov_clustering(G,inflation=1.5,pruning_threshold=0.001,convergence_check_frequency=100) 38\n",
      "20 algorithms.markov_clustering(G,inflation=2,pruning_threshold=0.01,convergence_check_frequency=100) 38\n",
      "21 algorithms.markov_clustering(G,inflation=2,pruning_threshold=0.001,convergence_check_frequency=100) 38\n",
      "22 algorithms.markov_clustering(G,inflation=2.5,pruning_threshold=0.01,convergence_check_frequency=100) 38\n",
      "23 algorithms.markov_clustering(G,inflation=2.5,pruning_threshold=0.001,convergence_check_frequency=100) 38\n",
      "24 algorithms.em(G,k=13) 13\n",
      "25 algorithms.em(G,k=93) 45\n",
      "26 algorithms.em(G,k=75) 33\n",
      "27 algorithms.em(G,k=32) 18\n",
      "28 algorithms.sbm_dl(G) 37\n",
      "29 algorithms.spinglass(G,spins=13) 13\n",
      "30 algorithms.spinglass(G,spins=93) 45\n",
      "31 algorithms.spinglass(G,spins=75) 37\n",
      "32 algorithms.spinglass(G,spins=32) 31\n",
      "33 algorithms.ricci_community(G,alpha=0.3) 28\n",
      "34 algorithms.ricci_community(G,alpha=0.5) 28\n",
      "35 algorithms.ricci_community(G,alpha=0.6) 26\n",
      "36 algorithms.ricci_community(G,alpha=0.75) 35\n",
      "---\n",
      "0 algorithms.label_propagation(G) 30\n",
      "1 algorithms.leiden(G) 29\n",
      "2 algorithms.significance_communities(G) 41\n",
      "3 algorithms.surprise_communities(G) 999\n",
      "4 algorithms.greedy_modularity(G) 12\n",
      "5 algorithms.paris(G) 38\n",
      "6 algorithms.louvain(G,resolution=0.75,randomize=314159) 39\n",
      "7 algorithms.louvain(G,resolution=0.75,randomize=2718) 38\n",
      "8 algorithms.louvain(G,resolution=1.0,randomize=314159) 29\n",
      "9 algorithms.louvain(G,resolution=1.0,randomize=2718) 30\n",
      "10 algorithms.louvain(G,resolution=1.25,randomize=314159) 33\n",
      "11 algorithms.louvain(G,resolution=1.25,randomize=2718) 32\n",
      "12 algorithms.louvain(G,resolution=1.5,randomize=314159) 34\n",
      "13 algorithms.louvain(G,resolution=1.5,randomize=2718) 34\n",
      "14 algorithms.infomap(G) 38\n",
      "15 algorithms.walktrap(G) 36\n",
      "16 algorithms.markov_clustering(G,inflation=1.2,pruning_threshold=0.01,convergence_check_frequency=100) 38\n",
      "17 algorithms.markov_clustering(G,inflation=1.2,pruning_threshold=0.001,convergence_check_frequency=100) 17\n",
      "18 algorithms.markov_clustering(G,inflation=1.5,pruning_threshold=0.01,convergence_check_frequency=100) 38\n",
      "19 algorithms.markov_clustering(G,inflation=1.5,pruning_threshold=0.001,convergence_check_frequency=100) 38\n",
      "20 algorithms.markov_clustering(G,inflation=2,pruning_threshold=0.01,convergence_check_frequency=100) 42\n",
      "21 algorithms.markov_clustering(G,inflation=2,pruning_threshold=0.001,convergence_check_frequency=100) 42\n",
      "22 algorithms.markov_clustering(G,inflation=2.5,pruning_threshold=0.01,convergence_check_frequency=100) 190\n",
      "23 algorithms.markov_clustering(G,inflation=2.5,pruning_threshold=0.001,convergence_check_frequency=100) 164\n",
      "24 algorithms.em(G,k=13) 9\n",
      "25 algorithms.em(G,k=93) 18\n",
      "26 algorithms.em(G,k=75) 23\n",
      "27 algorithms.em(G,k=32) 13\n",
      "28 algorithms.sbm_dl(G) 36\n",
      "29 algorithms.spinglass(G,spins=13) 13\n",
      "30 algorithms.spinglass(G,spins=93) 39\n",
      "31 algorithms.spinglass(G,spins=75) 37\n",
      "32 algorithms.spinglass(G,spins=32) 29\n",
      "33 algorithms.ricci_community(G,alpha=0.3) 33\n",
      "34 algorithms.ricci_community(G,alpha=0.5) 31\n",
      "35 algorithms.ricci_community(G,alpha=0.6) 33\n",
      "36 algorithms.ricci_community(G,alpha=0.75) 37\n",
      "---\n",
      "0 algorithms.label_propagation(G) 20\n",
      "1 algorithms.leiden(G) 30\n",
      "2 algorithms.significance_communities(G) 54\n",
      "3 algorithms.surprise_communities(G) 999\n",
      "4 algorithms.greedy_modularity(G) 8\n",
      "5 algorithms.paris(G) 22\n",
      "6 algorithms.louvain(G,resolution=0.75,randomize=314159) 39\n",
      "7 algorithms.louvain(G,resolution=0.75,randomize=2718) 39\n",
      "8 algorithms.louvain(G,resolution=1.0,randomize=314159) 29\n",
      "9 algorithms.louvain(G,resolution=1.0,randomize=2718) 29\n",
      "10 algorithms.louvain(G,resolution=1.25,randomize=314159) 32\n",
      "11 algorithms.louvain(G,resolution=1.25,randomize=2718) 33\n",
      "12 algorithms.louvain(G,resolution=1.5,randomize=314159) 34\n",
      "13 algorithms.louvain(G,resolution=1.5,randomize=2718) 36\n",
      "14 algorithms.infomap(G) 38\n",
      "15 algorithms.walktrap(G) 36\n",
      "16 algorithms.markov_clustering(G,inflation=1.2,pruning_threshold=0.01,convergence_check_frequency=100) 38\n",
      "17 algorithms.markov_clustering(G,inflation=1.2,pruning_threshold=0.001,convergence_check_frequency=100) 1\n",
      "18 algorithms.markov_clustering(G,inflation=1.5,pruning_threshold=0.01,convergence_check_frequency=100) 42\n",
      "19 algorithms.markov_clustering(G,inflation=1.5,pruning_threshold=0.001,convergence_check_frequency=100) 36\n",
      "20 algorithms.markov_clustering(G,inflation=2,pruning_threshold=0.01,convergence_check_frequency=100) 250\n",
      "21 algorithms.markov_clustering(G,inflation=2,pruning_threshold=0.001,convergence_check_frequency=100) 204\n",
      "22 algorithms.markov_clustering(G,inflation=2.5,pruning_threshold=0.01,convergence_check_frequency=100) 726\n",
      "23 algorithms.markov_clustering(G,inflation=2.5,pruning_threshold=0.001,convergence_check_frequency=100) 706\n",
      "24 algorithms.em(G,k=13) 6\n",
      "25 algorithms.em(G,k=93) 27\n",
      "26 algorithms.em(G,k=75) 21\n",
      "27 algorithms.em(G,k=32) 13\n",
      "28 algorithms.sbm_dl(G) 34\n",
      "29 algorithms.spinglass(G,spins=13) 13\n",
      "30 algorithms.spinglass(G,spins=93) 38\n",
      "31 algorithms.spinglass(G,spins=75) 33\n",
      "32 algorithms.spinglass(G,spins=32) 29\n",
      "33 algorithms.ricci_community(G,alpha=0.3) 33\n",
      "34 algorithms.ricci_community(G,alpha=0.5) 34\n",
      "35 algorithms.ricci_community(G,alpha=0.6) 36\n",
      "36 algorithms.ricci_community(G,alpha=0.75) 38\n",
      "---\n",
      "0 algorithms.label_propagation(G) 1\n",
      "1 algorithms.leiden(G) 22\n",
      "2 algorithms.significance_communities(G) 112\n",
      "3 algorithms.surprise_communities(G) 999\n",
      "4 algorithms.greedy_modularity(G) 6\n",
      "5 algorithms.paris(G) 33\n",
      "6 algorithms.louvain(G,resolution=0.75,randomize=314159) 40\n",
      "7 algorithms.louvain(G,resolution=0.75,randomize=2718) 39\n",
      "8 algorithms.louvain(G,resolution=1.0,randomize=314159) 24\n",
      "9 algorithms.louvain(G,resolution=1.0,randomize=2718) 23\n",
      "10 algorithms.louvain(G,resolution=1.25,randomize=314159) 28\n",
      "11 algorithms.louvain(G,resolution=1.25,randomize=2718) 28\n",
      "12 algorithms.louvain(G,resolution=1.5,randomize=314159) 30\n",
      "13 algorithms.louvain(G,resolution=1.5,randomize=2718) 33\n",
      "14 algorithms.infomap(G) 35\n",
      "15 algorithms.walktrap(G) 29\n",
      "16 algorithms.markov_clustering(G,inflation=1.2,pruning_threshold=0.01,convergence_check_frequency=100) 40\n",
      "17 algorithms.markov_clustering(G,inflation=1.2,pruning_threshold=0.001,convergence_check_frequency=100) 1\n",
      "18 algorithms.markov_clustering(G,inflation=1.5,pruning_threshold=0.01,convergence_check_frequency=100) 78\n",
      "19 algorithms.markov_clustering(G,inflation=1.5,pruning_threshold=0.001,convergence_check_frequency=100) 32\n",
      "20 algorithms.markov_clustering(G,inflation=2,pruning_threshold=0.01,convergence_check_frequency=100) 766\n",
      "21 algorithms.markov_clustering(G,inflation=2,pruning_threshold=0.001,convergence_check_frequency=100) 725\n",
      "22 algorithms.markov_clustering(G,inflation=2.5,pruning_threshold=0.01,convergence_check_frequency=100) 975\n",
      "23 algorithms.markov_clustering(G,inflation=2.5,pruning_threshold=0.001,convergence_check_frequency=100) 975\n",
      "24 algorithms.em(G,k=13) 8\n",
      "25 algorithms.em(G,k=93) 23\n",
      "26 algorithms.em(G,k=75) 18\n",
      "27 algorithms.em(G,k=32) 17\n",
      "28 algorithms.sbm_dl(G) 29\n",
      "29 algorithms.spinglass(G,spins=13) 13\n",
      "30 algorithms.spinglass(G,spins=93) 30\n",
      "31 algorithms.spinglass(G,spins=75) 28\n",
      "32 algorithms.spinglass(G,spins=32) 25\n",
      "33 algorithms.ricci_community(G,alpha=0.3) 20\n",
      "34 algorithms.ricci_community(G,alpha=0.5) 19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35 algorithms.ricci_community(G,alpha=0.6) 17\n",
      "UNSUCCESSFUL algorithms.ricci_community(G,alpha=0.75)\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "n = 1000\n",
    "fileprefix = \"LFR/\" + \"n\" + str(n) + \"/\"\n",
    "mus = [1, 2, 3, 4]\n",
    "#mus = [1]\n",
    "gammas = [30]\n",
    "betas = [11]\n",
    "for mu in mus:\n",
    "    for gamma in gammas:\n",
    "        for beta in betas:\n",
    "            fname = \"LFR_n\" + str(n) + \"_mu0\" + str(mu) + \"_gamma\" + str(gamma) + \"_beta\" + str(beta)\n",
    "            graph_file = fileprefix + fname + \".mtx\"\n",
    "            G = None\n",
    "            with open(graph_file) as f:\n",
    "                G = nx.from_scipy_sparse_array(spio.mmread(f), create_using=nx.Graph)\n",
    "                count = 0\n",
    "                comms = None\n",
    "                for alg, params in alg_params.items():\n",
    "                    param_combinations = []\n",
    "                    param_names = []\n",
    "                    if params is not None:\n",
    "                        iterables = []\n",
    "                        param_names = []\n",
    "                        for param in params.keys():\n",
    "                            iterables.append(list(params[param]))\n",
    "                            param_names.append(param)\n",
    "                        param_combinations = list(itertools.product(*iterables))\n",
    "                    if len(param_combinations) > 0:\n",
    "                        for param_combination in param_combinations:\n",
    "                            expr = \"algorithms.\"+alg+\"(G\"\n",
    "                            for i in range(len(param_names)):\n",
    "                                expr = expr + \",\" + param_names[i] + \"=\" + str(param_combination[i])\n",
    "                            expr = expr + \")\"\n",
    "                            try:\n",
    "                                coms = eval(expr)\n",
    "                                print(count, expr, len(coms.communities))\n",
    "                                write_clust_lst(coms.communities, fileprefix + fname + \".\" + str(count))\n",
    "                                count = count + 1\n",
    "                            except:\n",
    "                                print(\"UNSUCCESSFUL\", expr)       \n",
    "                    else:\n",
    "                        expr = \"algorithms.\"+alg+\"(G)\"\n",
    "                        try:\n",
    "                            coms = eval(expr)\n",
    "                            print(count, expr, len(coms.communities))\n",
    "                            write_clust_lst(coms.communities, fileprefix + fname + \".\" + str(count))\n",
    "                            count = count + 1\n",
    "                        except:\n",
    "                            print(\"UNSUCCESSFUL\", expr)\n",
    "\n",
    "                    #coms = eval()\n",
    "                #write_clust_lst(coms.communities, fileprefix + fname + \".\" + alg)\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefa635f",
   "metadata": {},
   "source": [
    "## 5000 node graph\n",
    "Parameters:\n",
    "- Number of nodes $n=5000$\n",
    "- Inter-cluster edge probability $\\mu \\in \\{ 0.1, 0.2, 0.3, 0.4 \\}$\n",
    "- Degree distribution parameter (Power-law exponent) $\\gamma = 3.0$\n",
    "- Community size distribution parameter (Power-law exponent) $\\beta = 1.1$\n",
    "- Minimum degree: $10$\n",
    "- Maximum degree: $50$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "17dcedcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import networkx.algorithms.community as nx_comm\n",
    "from networkx.generators.community import LFR_benchmark_graph\n",
    "from networkx.algorithms import bipartite\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy import sparse\n",
    "n = 5000\n",
    "fileprefix = \"LFR/\" + \"n\" + str(n) + \"/\"\n",
    "mus = [1, 2, 3, 4]\n",
    "gammas = [30]\n",
    "betas = [11]\n",
    "for mu in mus:\n",
    "    for gamma in gammas:\n",
    "        for beta in betas:\n",
    "            fname = \"LFR_n\" + str(n) + \"_mu0\" + str(mu) + \"_gamma\" + str(gamma) + \"_beta\" + str(beta)\n",
    "            G = LFR_benchmark_graph(n, (float(gamma) / 10), (float(beta) / 10), (float(mu) / 10), seed=10, min_degree=10, max_degree=50)\n",
    "            m = nx.to_scipy_sparse_array(G)\n",
    "            sp.io.mmwrite(fileprefix + fname + \".mtx\", m)\n",
    "            clust_lst = {frozenset(G.nodes[v][\"community\"]) for v in G}\n",
    "            #nx.write_edgelist(G, fileprefix + name + \".edgelist\", data=False)\n",
    "            write_clust_lst(clust_lst, fileprefix + fname + \".gt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc958196",
   "metadata": {},
   "source": [
    "## Clustering algorithm parameter configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7160d428",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5000\n",
    "expected_clusters = []\n",
    "for i in range(4):\n",
    "    expected_clusters.append(random.randint(int(n ** (1. / 3)),3*int(n ** (1. / 2))))\n",
    "    \n",
    "alg_params = {\n",
    "    \"label_propagation\": None,\n",
    "    \"leiden\": None,\n",
    "    \"significance_communities\": None,\n",
    "    \"surprise_communities\": None,\n",
    "    \"greedy_modularity\": None,\n",
    "    \"paris\": None,\n",
    "    \"louvain\": {\n",
    "        \"resolution\": [0.75, 1.0, 1.25, 1.5],\n",
    "        \"randomize\": [314159, 2718]\n",
    "    },\n",
    "    \"infomap\": None,\n",
    "    \"walktrap\": None,\n",
    "    \"markov_clustering\": {\n",
    "        \"inflation\": [1.2, 1.5, 2, 2.5],\n",
    "        \"pruning_threshold\": [0.01, 0.001],\n",
    "        \"convergence_check_frequency\": [100]\n",
    "    },\n",
    "    \"em\": {\n",
    "        \"k\": list(expected_clusters)\n",
    "    },\n",
    "    \"sbm_dl\": None,\n",
    "    \"spinglass\": {\n",
    "        \"spins\": list(expected_clusters)\n",
    "    },\n",
    "    \"ricci_community\": {\n",
    "        \"alpha\": [0.3, 0.5, 0.6, 0.75]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1495477f",
   "metadata": {},
   "source": [
    "## Run different algorithms on generated benchmark networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bb2c9788",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 algorithms.label_propagation(G) 201\n",
      "1 algorithms.leiden(G) 113\n",
      "2 algorithms.significance_communities(G) 201\n",
      "3 algorithms.surprise_communities(G) 4999\n",
      "4 algorithms.greedy_modularity(G) 66\n",
      "5 algorithms.paris(G) 197\n",
      "6 algorithms.louvain(G,resolution=0.75,randomize=314159) 97\n",
      "7 algorithms.louvain(G,resolution=0.75,randomize=2718) 98\n",
      "8 algorithms.louvain(G,resolution=1.0,randomize=314159) 114\n",
      "9 algorithms.louvain(G,resolution=1.0,randomize=2718) 112\n",
      "10 algorithms.louvain(G,resolution=1.25,randomize=314159) 127\n",
      "11 algorithms.louvain(G,resolution=1.25,randomize=2718) 129\n",
      "12 algorithms.louvain(G,resolution=1.5,randomize=314159) 134\n",
      "13 algorithms.louvain(G,resolution=1.5,randomize=2718) 134\n",
      "14 algorithms.infomap(G) 201\n",
      "15 algorithms.walktrap(G) 200\n",
      "16 algorithms.markov_clustering(G,inflation=1.2,pruning_threshold=0.01,convergence_check_frequency=100) 201\n",
      "17 algorithms.markov_clustering(G,inflation=1.2,pruning_threshold=0.001,convergence_check_frequency=100) 200\n",
      "18 algorithms.markov_clustering(G,inflation=1.5,pruning_threshold=0.01,convergence_check_frequency=100) 201\n",
      "19 algorithms.markov_clustering(G,inflation=1.5,pruning_threshold=0.001,convergence_check_frequency=100) 201\n",
      "20 algorithms.markov_clustering(G,inflation=2,pruning_threshold=0.01,convergence_check_frequency=100) 201\n",
      "21 algorithms.markov_clustering(G,inflation=2,pruning_threshold=0.001,convergence_check_frequency=100) 201\n",
      "22 algorithms.markov_clustering(G,inflation=2.5,pruning_threshold=0.01,convergence_check_frequency=100) 202\n",
      "23 algorithms.markov_clustering(G,inflation=2.5,pruning_threshold=0.001,convergence_check_frequency=100) 201\n",
      "24 algorithms.em(G,k=182) 163\n",
      "25 algorithms.em(G,k=95) 93\n",
      "26 algorithms.em(G,k=169) 155\n",
      "27 algorithms.em(G,k=34) 34\n",
      "28 algorithms.sbm_dl(G) 140\n",
      "29 algorithms.spinglass(G,spins=182) 147\n",
      "30 algorithms.spinglass(G,spins=95) 91\n",
      "31 algorithms.spinglass(G,spins=169) 141\n",
      "32 algorithms.spinglass(G,spins=34) 34\n",
      "33 algorithms.ricci_community(G,alpha=0.3) 116\n",
      "34 algorithms.ricci_community(G,alpha=0.5) 123\n",
      "35 algorithms.ricci_community(G,alpha=0.6) 130\n",
      "36 algorithms.ricci_community(G,alpha=0.75) 147\n",
      "---\n",
      "0 algorithms.label_propagation(G) 158\n",
      "1 algorithms.leiden(G) 89\n",
      "2 algorithms.significance_communities(G) 201\n",
      "3 algorithms.surprise_communities(G) 4999\n",
      "4 algorithms.greedy_modularity(G) 22\n",
      "5 algorithms.paris(G) 183\n",
      "6 algorithms.louvain(G,resolution=0.75,randomize=314159) 74\n",
      "7 algorithms.louvain(G,resolution=0.75,randomize=2718) 72\n",
      "8 algorithms.louvain(G,resolution=1.0,randomize=314159) 89\n",
      "9 algorithms.louvain(G,resolution=1.0,randomize=2718) 90\n",
      "10 algorithms.louvain(G,resolution=1.25,randomize=314159) 109\n",
      "11 algorithms.louvain(G,resolution=1.25,randomize=2718) 109\n",
      "12 algorithms.louvain(G,resolution=1.5,randomize=314159) 121\n",
      "13 algorithms.louvain(G,resolution=1.5,randomize=2718) 121\n",
      "14 algorithms.infomap(G) 201\n",
      "15 algorithms.walktrap(G) 190\n",
      "16 algorithms.markov_clustering(G,inflation=1.2,pruning_threshold=0.01,convergence_check_frequency=100) 201\n",
      "17 algorithms.markov_clustering(G,inflation=1.2,pruning_threshold=0.001,convergence_check_frequency=100) 188\n",
      "18 algorithms.markov_clustering(G,inflation=1.5,pruning_threshold=0.01,convergence_check_frequency=100) 201\n",
      "19 algorithms.markov_clustering(G,inflation=1.5,pruning_threshold=0.001,convergence_check_frequency=100) 201\n",
      "20 algorithms.markov_clustering(G,inflation=2,pruning_threshold=0.01,convergence_check_frequency=100) 224\n",
      "21 algorithms.markov_clustering(G,inflation=2,pruning_threshold=0.001,convergence_check_frequency=100) 217\n",
      "22 algorithms.markov_clustering(G,inflation=2.5,pruning_threshold=0.01,convergence_check_frequency=100) 831\n",
      "23 algorithms.markov_clustering(G,inflation=2.5,pruning_threshold=0.001,convergence_check_frequency=100) 743\n",
      "24 algorithms.em(G,k=182) 125\n",
      "25 algorithms.em(G,k=95) 76\n",
      "26 algorithms.em(G,k=169) 107\n",
      "27 algorithms.em(G,k=34) 34\n",
      "28 algorithms.sbm_dl(G) 143\n",
      "29 algorithms.spinglass(G,spins=182) 141\n",
      "30 algorithms.spinglass(G,spins=95) 92\n",
      "31 algorithms.spinglass(G,spins=169) 133\n",
      "32 algorithms.spinglass(G,spins=34) 34\n",
      "33 algorithms.ricci_community(G,alpha=0.3) 127\n",
      "34 algorithms.ricci_community(G,alpha=0.5) 145\n",
      "35 algorithms.ricci_community(G,alpha=0.6) 148\n",
      "36 algorithms.ricci_community(G,alpha=0.75) 128\n",
      "---\n",
      "0 algorithms.label_propagation(G) 141\n",
      "1 algorithms.leiden(G) 72\n",
      "2 algorithms.significance_communities(G) 216\n",
      "3 algorithms.surprise_communities(G) 4999\n",
      "4 algorithms.greedy_modularity(G) 13\n",
      "5 algorithms.paris(G) 183\n",
      "6 algorithms.louvain(G,resolution=0.75,randomize=314159) 60\n",
      "7 algorithms.louvain(G,resolution=0.75,randomize=2718) 62\n",
      "8 algorithms.louvain(G,resolution=1.0,randomize=314159) 73\n",
      "9 algorithms.louvain(G,resolution=1.0,randomize=2718) 77\n",
      "10 algorithms.louvain(G,resolution=1.25,randomize=314159) 90\n",
      "11 algorithms.louvain(G,resolution=1.25,randomize=2718) 92\n",
      "12 algorithms.louvain(G,resolution=1.5,randomize=314159) 105\n",
      "13 algorithms.louvain(G,resolution=1.5,randomize=2718) 108\n",
      "14 algorithms.infomap(G) 199\n",
      "15 algorithms.walktrap(G) 197\n",
      "16 algorithms.markov_clustering(G,inflation=1.2,pruning_threshold=0.01,convergence_check_frequency=100) 205\n",
      "17 algorithms.markov_clustering(G,inflation=1.2,pruning_threshold=0.001,convergence_check_frequency=100) 137\n",
      "18 algorithms.markov_clustering(G,inflation=1.5,pruning_threshold=0.01,convergence_check_frequency=100) 217\n",
      "19 algorithms.markov_clustering(G,inflation=1.5,pruning_threshold=0.001,convergence_check_frequency=100) 201\n",
      "20 algorithms.markov_clustering(G,inflation=2,pruning_threshold=0.01,convergence_check_frequency=100) 1257\n",
      "21 algorithms.markov_clustering(G,inflation=2,pruning_threshold=0.001,convergence_check_frequency=100) 1089\n",
      "22 algorithms.markov_clustering(G,inflation=2.5,pruning_threshold=0.01,convergence_check_frequency=100) 3757\n",
      "23 algorithms.markov_clustering(G,inflation=2.5,pruning_threshold=0.001,convergence_check_frequency=100) 3675\n",
      "24 algorithms.em(G,k=182) 80\n",
      "25 algorithms.em(G,k=95) 55\n",
      "26 algorithms.em(G,k=169) 73\n",
      "27 algorithms.em(G,k=34) 29\n",
      "28 algorithms.sbm_dl(G) 139\n",
      "29 algorithms.spinglass(G,spins=182) 125\n",
      "30 algorithms.spinglass(G,spins=95) 89\n",
      "31 algorithms.spinglass(G,spins=169) 125\n",
      "32 algorithms.spinglass(G,spins=34) 34\n",
      "33 algorithms.ricci_community(G,alpha=0.3) 146\n",
      "34 algorithms.ricci_community(G,alpha=0.5) 151\n",
      "35 algorithms.ricci_community(G,alpha=0.6) 149\n",
      "36 algorithms.ricci_community(G,alpha=0.75) 169\n",
      "---\n",
      "0 algorithms.label_propagation(G) 1\n",
      "1 algorithms.leiden(G) 55\n",
      "2 algorithms.significance_communities(G) 309\n",
      "3 algorithms.surprise_communities(G) 4999\n",
      "4 algorithms.greedy_modularity(G) 10\n",
      "5 algorithms.paris(G) 87\n",
      "6 algorithms.louvain(G,resolution=0.75,randomize=314159) 49\n",
      "7 algorithms.louvain(G,resolution=0.75,randomize=2718) 61\n",
      "8 algorithms.louvain(G,resolution=1.0,randomize=314159) 52\n",
      "9 algorithms.louvain(G,resolution=1.0,randomize=2718) 56\n",
      "10 algorithms.louvain(G,resolution=1.25,randomize=314159) 75\n",
      "11 algorithms.louvain(G,resolution=1.25,randomize=2718) 71\n",
      "12 algorithms.louvain(G,resolution=1.5,randomize=314159) 94\n",
      "13 algorithms.louvain(G,resolution=1.5,randomize=2718) 95\n",
      "14 algorithms.infomap(G) 184\n",
      "15 algorithms.walktrap(G) 156\n",
      "16 algorithms.markov_clustering(G,inflation=1.2,pruning_threshold=0.01,convergence_check_frequency=100) 303\n",
      "17 algorithms.markov_clustering(G,inflation=1.2,pruning_threshold=0.001,convergence_check_frequency=100) 86\n",
      "18 algorithms.markov_clustering(G,inflation=1.5,pruning_threshold=0.01,convergence_check_frequency=100) 642\n",
      "19 algorithms.markov_clustering(G,inflation=1.5,pruning_threshold=0.001,convergence_check_frequency=100) 236\n",
      "20 algorithms.markov_clustering(G,inflation=2,pruning_threshold=0.01,convergence_check_frequency=100) 3866\n",
      "21 algorithms.markov_clustering(G,inflation=2,pruning_threshold=0.001,convergence_check_frequency=100) 3754\n",
      "22 algorithms.markov_clustering(G,inflation=2.5,pruning_threshold=0.01,convergence_check_frequency=100) 4892\n",
      "23 algorithms.markov_clustering(G,inflation=2.5,pruning_threshold=0.001,convergence_check_frequency=100) 4890\n",
      "24 algorithms.em(G,k=182) 179\n",
      "25 algorithms.em(G,k=95) 95\n",
      "26 algorithms.em(G,k=169) 167\n",
      "27 algorithms.em(G,k=34) 34\n",
      "28 algorithms.sbm_dl(G) 130\n",
      "29 algorithms.spinglass(G,spins=182) 108\n",
      "30 algorithms.spinglass(G,spins=95) 86\n",
      "31 algorithms.spinglass(G,spins=169) 103\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 algorithms.spinglass(G,spins=34) 34\n",
      "33 algorithms.ricci_community(G,alpha=0.3) 338\n",
      "34 algorithms.ricci_community(G,alpha=0.5) 410\n",
      "35 algorithms.ricci_community(G,alpha=0.6) 414\n",
      "36 algorithms.ricci_community(G,alpha=0.75) 420\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "n = 5000\n",
    "fileprefix = \"LFR/\" + \"n\" + str(n) + \"/\"\n",
    "mus = [1, 2, 3, 4]\n",
    "#mus = [1]\n",
    "gammas = [30]\n",
    "betas = [11]\n",
    "for mu in mus:\n",
    "    for gamma in gammas:\n",
    "        for beta in betas:\n",
    "            fname = \"LFR_n\" + str(n) + \"_mu0\" + str(mu) + \"_gamma\" + str(gamma) + \"_beta\" + str(beta)\n",
    "            graph_file = fileprefix + fname + \".mtx\"\n",
    "            G = None\n",
    "            with open(graph_file) as f:\n",
    "                G = nx.from_scipy_sparse_array(spio.mmread(f), create_using=nx.Graph)\n",
    "                count = 0\n",
    "                comms = None\n",
    "                for alg, params in alg_params.items():\n",
    "                    param_combinations = []\n",
    "                    param_names = []\n",
    "                    if params is not None:\n",
    "                        iterables = []\n",
    "                        param_names = []\n",
    "                        for param in params.keys():\n",
    "                            iterables.append(list(params[param]))\n",
    "                            param_names.append(param)\n",
    "                        param_combinations = list(itertools.product(*iterables))\n",
    "                    if len(param_combinations) > 0:\n",
    "                        for param_combination in param_combinations:\n",
    "                            expr = \"algorithms.\"+alg+\"(G\"\n",
    "                            for i in range(len(param_names)):\n",
    "                                expr = expr + \",\" + param_names[i] + \"=\" + str(param_combination[i])\n",
    "                            expr = expr + \")\"\n",
    "                            try:\n",
    "                                coms = eval(expr)\n",
    "                                print(count, expr, len(coms.communities))\n",
    "                                write_clust_lst(coms.communities, fileprefix + fname + \".\" + str(count))\n",
    "                                count = count + 1\n",
    "                            except:\n",
    "                                print(\"UNSUCCESSFUL\", expr)       \n",
    "                    else:\n",
    "                        expr = \"algorithms.\"+alg+\"(G)\"\n",
    "                        try:\n",
    "                            coms = eval(expr)\n",
    "                            print(count, expr, len(coms.communities))\n",
    "                            write_clust_lst(coms.communities, fileprefix + fname + \".\" + str(count))\n",
    "                            count = count + 1\n",
    "                        except:\n",
    "                            print(\"UNSUCCESSFUL\", expr)\n",
    "\n",
    "                    #coms = eval()\n",
    "                #write_clust_lst(coms.communities, fileprefix + fname + \".\" + alg)\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd21678",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
