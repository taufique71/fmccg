{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9ab0dfc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import networkx.algorithms.community as nx_comm\n",
    "from networkx.generators.community import LFR_benchmark_graph\n",
    "from networkx.algorithms import bipartite\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy.sparse import coo_array\n",
    "from scipy import sparse\n",
    "from cdlib import algorithms\n",
    "from cdlib import evaluation\n",
    "import sklearn\n",
    "from utils import *\n",
    "from distances import *\n",
    "from consensus import *\n",
    "import math\n",
    "import itertools\n",
    "import random\n",
    "import time\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "88c328d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('algorithms.label_propagation(G)', 0), ('algorithms.leiden(G)', 1), ('algorithms.significance_communities(G)', 2), ('algorithms.surprise_communities(G)', 3), ('algorithms.greedy_modularity(G)', 4), ('algorithms.paris(G)', 5), ('algorithms.louvain(G,resolution=0.75,randomize=314159)', 6), ('algorithms.louvain(G,resolution=0.75,randomize=2718)', 7), ('algorithms.louvain(G,resolution=1.0,randomize=314159)', 8), ('algorithms.louvain(G,resolution=1.0,randomize=2718)', 9), ('algorithms.louvain(G,resolution=1.25,randomize=314159)', 10), ('algorithms.louvain(G,resolution=1.25,randomize=2718)', 11), ('algorithms.louvain(G,resolution=1.5,randomize=314159)', 12), ('algorithms.louvain(G,resolution=1.5,randomize=2718)', 13), ('algorithms.infomap(G)', 14), ('algorithms.walktrap(G)', 15), ('algorithms.markov_clustering(G,inflation=1.2,pruning_threshold=0.01,convergence_check_frequency=100)', 16), ('algorithms.markov_clustering(G,inflation=1.2,pruning_threshold=0.001,convergence_check_frequency=100)', 17), ('algorithms.markov_clustering(G,inflation=1.5,pruning_threshold=0.01,convergence_check_frequency=100)', 18), ('algorithms.markov_clustering(G,inflation=1.5,pruning_threshold=0.001,convergence_check_frequency=100)', 19), ('algorithms.markov_clustering(G,inflation=2,pruning_threshold=0.01,convergence_check_frequency=100)', 20), ('algorithms.markov_clustering(G,inflation=2,pruning_threshold=0.001,convergence_check_frequency=100)', 21), ('algorithms.markov_clustering(G,inflation=2.5,pruning_threshold=0.01,convergence_check_frequency=100)', 22), ('algorithms.markov_clustering(G,inflation=2.5,pruning_threshold=0.001,convergence_check_frequency=100)', 23), ('algorithms.em(G,k=684)', 24), ('algorithms.em(G,k=599)', 25), ('algorithms.em(G,k=212)', 26), ('algorithms.em(G,k=682)', 27), ('algorithms.sbm_dl(G)', 28), ('algorithms.spinglass(G,spins=684)', 29), ('algorithms.spinglass(G,spins=599)', 30), ('algorithms.spinglass(G,spins=212)', 31), ('algorithms.spinglass(G,spins=682)', 32), ('algorithms.ricci_community(G,alpha=0.3)', 33), ('algorithms.ricci_community(G,alpha=0.5)', 34), ('algorithms.ricci_community(G,alpha=0.6)', 35), ('algorithms.ricci_community(G,alpha=0.75)', 36)]\n"
     ]
    }
   ],
   "source": [
    "n = 53173\n",
    "expected_clusters = []\n",
    "for i in range(4):\n",
    "    expected_clusters.append(random.randint(int(n ** (1. / 3)),3*int(n ** (1. / 2))))\n",
    "    \n",
    "alg_params = {\n",
    "    \"label_propagation\": None,\n",
    "    \"leiden\": None,\n",
    "    \"significance_communities\": None,\n",
    "    \"surprise_communities\": None,\n",
    "    \"greedy_modularity\": None,\n",
    "    \"paris\": None,\n",
    "    \"louvain\": {\n",
    "        \"resolution\": [0.75, 1.0, 1.25, 1.5],\n",
    "        \"randomize\": [314159, 2718]\n",
    "    },\n",
    "    \"infomap\": None,\n",
    "    \"walktrap\": None,\n",
    "    \"markov_clustering\": {\n",
    "        \"inflation\": [1.2, 1.5, 2, 2.5],\n",
    "        \"pruning_threshold\": [0.01, 0.001],\n",
    "        \"convergence_check_frequency\": [100]\n",
    "    },\n",
    "    \"em\": {\n",
    "        \"k\": list(expected_clusters)\n",
    "    },\n",
    "    \"sbm_dl\": None,\n",
    "    \"spinglass\": {\n",
    "        \"spins\": list(expected_clusters)\n",
    "    },\n",
    "    \"ricci_community\": {\n",
    "        \"alpha\": [0.3, 0.5, 0.6, 0.75]\n",
    "    }\n",
    "}\n",
    "clustering_enumeration = []\n",
    "count = 0\n",
    "for alg, params in alg_params.items():\n",
    "    param_combinations = []\n",
    "    param_names = []\n",
    "    if params is not None:\n",
    "        iterables = []\n",
    "        param_names = []\n",
    "        for param in params.keys():\n",
    "            iterables.append(list(params[param]))\n",
    "            param_names.append(param)\n",
    "        param_combinations = list(itertools.product(*iterables))\n",
    "    if len(param_combinations) > 0:\n",
    "        for param_combination in param_combinations:\n",
    "            expr = \"algorithms.\"+alg+\"(G\"\n",
    "            for i in range(len(param_names)):\n",
    "                expr = expr + \",\" + param_names[i] + \"=\" + str(param_combination[i])\n",
    "            expr = expr + \")\"\n",
    "            clustering_enumeration.append((expr,count))\n",
    "            count = count + 1      \n",
    "    else:\n",
    "        expr = \"algorithms.\"+alg+\"(G)\"\n",
    "        clustering_enumeration.append((expr,count))\n",
    "        count = count + 1\n",
    "        \n",
    "print(clustering_enumeration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0774cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mth/Data/UNC DATASET/Metis Format/Samusik_01NetworkMetis.mtx\n",
      "algorithms.label_propagation(G) 43 communities,  116.27263879776001 seconds\n",
      "---\n",
      "algorithms.leiden(G) 17 communities,  20.294886350631714 seconds\n",
      "---\n",
      "algorithms.significance_communities(G) 344 communities,  22.700498819351196 seconds\n",
      "---\n",
      "algorithms.surprise_communities(G) 135 communities,  24.670162200927734 seconds\n",
      "---\n",
      "algorithms.greedy_modularity(G) 7 communities,  3654.2147674560547 seconds\n",
      "---\n",
      "algorithms.paris(G) 6 communities,  69.38017106056213 seconds\n",
      "---\n",
      "algorithms.louvain(G,resolution=0.75,randomize=314159) 21 communities,  255.55172395706177 seconds\n",
      "---\n",
      "algorithms.louvain(G,resolution=0.75,randomize=2718) 21 communities,  343.7930133342743 seconds\n",
      "---\n",
      "algorithms.louvain(G,resolution=1.0,randomize=314159) 22 communities,  275.4744658470154 seconds\n",
      "---\n",
      "algorithms.louvain(G,resolution=1.0,randomize=2718) 22 communities,  282.3395140171051 seconds\n",
      "---\n",
      "algorithms.louvain(G,resolution=1.25,randomize=314159) 22 communities,  260.2861838340759 seconds\n",
      "---\n",
      "algorithms.louvain(G,resolution=1.25,randomize=2718) 24 communities,  402.64633655548096 seconds\n",
      "---\n",
      "algorithms.louvain(G,resolution=1.5,randomize=314159) 28 communities,  265.4258213043213 seconds\n",
      "---\n",
      "algorithms.louvain(G,resolution=1.5,randomize=2718) 27 communities,  278.8239619731903 seconds\n",
      "---\n",
      "algorithms.infomap(G) 4 communities,  27.237898349761963 seconds\n",
      "---\n",
      "algorithms.walktrap(G) 22 communities,  372.2165582180023 seconds\n",
      "---\n",
      "algorithms.markov_clustering(G,inflation=1.2,pruning_threshold=0.01,convergence_check_frequency=100) 48515 communities,  64.04991626739502 seconds\n",
      "---\n",
      "algorithms.markov_clustering(G,inflation=1.2,pruning_threshold=0.001,convergence_check_frequency=100) 47549 communities,  68.46284532546997 seconds\n",
      "---\n",
      "algorithms.markov_clustering(G,inflation=1.5,pruning_threshold=0.01,convergence_check_frequency=100) 53173 communities,  62.40435791015625 seconds\n",
      "---\n",
      "algorithms.markov_clustering(G,inflation=1.5,pruning_threshold=0.001,convergence_check_frequency=100) 53173 communities,  63.96893882751465 seconds\n",
      "---\n",
      "algorithms.markov_clustering(G,inflation=2,pruning_threshold=0.01,convergence_check_frequency=100) 53173 communities,  62.155921459198 seconds\n",
      "---\n",
      "algorithms.markov_clustering(G,inflation=2,pruning_threshold=0.001,convergence_check_frequency=100) 53173 communities,  63.01716947555542 seconds\n",
      "---\n",
      "algorithms.markov_clustering(G,inflation=2.5,pruning_threshold=0.01,convergence_check_frequency=100) 53173 communities,  63.738107442855835 seconds\n",
      "---\n",
      "algorithms.markov_clustering(G,inflation=2.5,pruning_threshold=0.001,convergence_check_frequency=100) 53173 communities,  61.08177042007446 seconds\n",
      "---\n",
      "algorithms.em(G,k=684) 8 communities,  2474.544456720352 seconds\n",
      "---\n",
      "algorithms.em(G,k=599) 8 communities,  2150.110697746277 seconds\n",
      "---\n",
      "algorithms.em(G,k=212) 7 communities,  744.152637720108 seconds\n",
      "---\n",
      "algorithms.em(G,k=682) 9 communities,  2470.023339509964 seconds\n",
      "---\n",
      "algorithms.sbm_dl(G) 310 communities,  477.90167236328125 seconds\n",
      "---\n",
      "algorithms.spinglass(G,spins=684) 30 communities,  778.1347231864929 seconds\n",
      "---\n",
      "algorithms.spinglass(G,spins=599) 33 communities,  421.6380178928375 seconds\n",
      "---\n",
      "algorithms.spinglass(G,spins=212) 63 communities,  3269.1396231651306 seconds\n",
      "---\n",
      "algorithms.spinglass(G,spins=682) 35 communities,  678.6206066608429 seconds\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "fileprefix = \"/home/mth/Data/UNC DATASET/Metis Format/\"\n",
    "fname = \"Samusik_01NetworkMetis\"\n",
    "graph_file = fileprefix + fname + \".mtx\"\n",
    "G = None\n",
    "print(graph_file)\n",
    "if Path(graph_file).is_file():\n",
    "    #print(\"File found\")\n",
    "    with open(graph_file) as f:\n",
    "        G = nx.from_scipy_sparse_array(spio.mmread(f), create_using=nx.Graph)\n",
    "        #G = nx.read_weighted_edgelist(f)\n",
    "        coms = None\n",
    "        count = 0\n",
    "        #print(G.edges())\n",
    "        for k in clustering_enumeration:\n",
    "            try:\n",
    "                t1 = time.time()\n",
    "                coms = eval(k[0])\n",
    "                t2 = time.time()\n",
    "                print(k[0], len(coms.communities), \"communities, \", t2-t1, \"seconds\")\n",
    "                nelem = 0\n",
    "                for l in coms.communities:\n",
    "                    nelem = nelem + len(l)\n",
    "                if nelem == len(G.nodes()):\n",
    "                    write_clust_lst(coms.communities, fileprefix + fname + \".\" + str(count))\n",
    "                    count = count + 1\n",
    "                    #print(\"VALID PARTITION\")\n",
    "                    print(\"---\")\n",
    "                else:\n",
    "                    print(\"INVALID PARTITION\")\n",
    "                    print(\"---\")\n",
    "            except Exception as e:\n",
    "                print(\"UNSUCCESSFUL\", k[0], e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a0088123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mth/Data/UNC DATASET/Metis Format/Samusik_01NetworkMetis\n",
      "File found\n",
      "53173 1256023\n"
     ]
    }
   ],
   "source": [
    "fileprefix = \"/home/mth/Data/UNC DATASET/Metis Format/\"\n",
    "fname = \"Samusik_01NetworkMetis\"\n",
    "#graph_file = fileprefix + fname + \".edgelist\"\n",
    "graph_file = fileprefix + fname\n",
    "G = None\n",
    "print(graph_file)\n",
    "if Path(graph_file).is_file():\n",
    "    print(\"File found\")\n",
    "    with open(graph_file, \"rU\") as f:\n",
    "        first_line = f.readline().strip('\\n')\n",
    "        tokens = first_line.split(\" \")\n",
    "        n = int(tokens[0])\n",
    "        m = int(tokens[1])\n",
    "        m = m - 1\n",
    "        print(n, m)\n",
    "        #nz_rows, nz_cols = np.nonzero(A)\n",
    "        row = [-1]*m\n",
    "        col = [-1]*m\n",
    "        val = [0]*m\n",
    "        for i in range(m):\n",
    "            line = f.readline().strip('\\n')\n",
    "            tokens = line.split(\" \")\n",
    "            #print(tokens)\n",
    "            row[i] = int(tokens[0])-1\n",
    "            col[i] = int(tokens[1])-1\n",
    "            val[i] = float(tokens[2])\n",
    "        r = coo_array((val, (row, col)), shape=(n, n))\n",
    "        spio.mmwrite(graph_file+\".mtx\", r)\n",
    "#         for line in f:\n",
    "#             nlines = nlines + 1\n",
    "#             #print(line)\n",
    "#         print(nlines)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "231fe548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mth/Data/UNC DATASET/Metis Format/Samusik_allNetworkMetis\n",
      "File found\n",
      "514386 11970593\n"
     ]
    }
   ],
   "source": [
    "fileprefix = \"/home/mth/Data/UNC DATASET/Metis Format/\"\n",
    "fname = \"Samusik_allNetworkMetis\"\n",
    "#graph_file = fileprefix + fname + \".edgelist\"\n",
    "graph_file = fileprefix + fname\n",
    "G = None\n",
    "print(graph_file)\n",
    "if Path(graph_file).is_file():\n",
    "    print(\"File found\")\n",
    "    with open(graph_file, \"rU\") as f:\n",
    "        first_line = f.readline().strip('\\n')\n",
    "        tokens = first_line.split(\" \")\n",
    "        n = int(tokens[0])\n",
    "        m = int(tokens[1])\n",
    "        m = m - 1\n",
    "        print(n, m)\n",
    "        #nz_rows, nz_cols = np.nonzero(A)\n",
    "        row = [-1]*m\n",
    "        col = [-1]*m\n",
    "        val = [0]*m\n",
    "        for i in range(m):\n",
    "            line = f.readline().strip('\\n')\n",
    "            tokens = line.split(\" \")\n",
    "            #print(tokens)\n",
    "            row[i] = int(tokens[0])-1\n",
    "            col[i] = int(tokens[1])-1\n",
    "            val[i] = float(tokens[2])\n",
    "        r = coo_array((val, (row, col)), shape=(n, n))\n",
    "        spio.mmwrite(graph_file+\".mtx\", r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "291a12b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mth/Data/UNC DATASET/Metis Format/Levine13_dimNetworkMetis\n",
      "File found\n",
      "81747 1830254\n"
     ]
    }
   ],
   "source": [
    "fileprefix = \"/home/mth/Data/UNC DATASET/Metis Format/\"\n",
    "fname = \"Levine13_dimNetworkMetis\"\n",
    "#graph_file = fileprefix + fname + \".edgelist\"\n",
    "graph_file = fileprefix + fname\n",
    "G = None\n",
    "print(graph_file)\n",
    "if Path(graph_file).is_file():\n",
    "    print(\"File found\")\n",
    "    with open(graph_file, \"rU\") as f:\n",
    "        first_line = f.readline().strip('\\n')\n",
    "        tokens = first_line.split(\" \")\n",
    "        n = int(tokens[0])\n",
    "        m = int(tokens[1])\n",
    "        m = m - 1\n",
    "        print(n, m)\n",
    "        #nz_rows, nz_cols = np.nonzero(A)\n",
    "        row = [-1]*m\n",
    "        col = [-1]*m\n",
    "        val = [0]*m\n",
    "        for i in range(m):\n",
    "            line = f.readline().strip('\\n')\n",
    "            tokens = line.split(\" \")\n",
    "            #print(tokens)\n",
    "            row[i] = int(tokens[0])-1\n",
    "            col[i] = int(tokens[1])-1\n",
    "            val[i] = float(tokens[2])\n",
    "        r = coo_array((val, (row, col)), shape=(n, n))\n",
    "        spio.mmwrite(graph_file+\".mtx\", r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "61cee5fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mth/Data/UNC DATASET/Metis Format/Levine32_dimNetworkMetis\n",
      "File found\n",
      "104184 2392991\n"
     ]
    }
   ],
   "source": [
    "fileprefix = \"/home/mth/Data/UNC DATASET/Metis Format/\"\n",
    "fname = \"Levine32_dimNetworkMetis\"\n",
    "#graph_file = fileprefix + fname + \".edgelist\"\n",
    "graph_file = fileprefix + fname\n",
    "G = None\n",
    "print(graph_file)\n",
    "if Path(graph_file).is_file():\n",
    "    print(\"File found\")\n",
    "    with open(graph_file, \"rU\") as f:\n",
    "        first_line = f.readline().strip('\\n')\n",
    "        tokens = first_line.split(\" \")\n",
    "        n = int(tokens[0])\n",
    "        m = int(tokens[1])\n",
    "        m = m - 1\n",
    "        print(n, m)\n",
    "        #nz_rows, nz_cols = np.nonzero(A)\n",
    "        row = [-1]*m\n",
    "        col = [-1]*m\n",
    "        val = [0]*m\n",
    "        for i in range(m):\n",
    "            line = f.readline().strip('\\n')\n",
    "            tokens = line.split(\" \")\n",
    "            #print(tokens)\n",
    "            row[i] = int(tokens[0])-1\n",
    "            col[i] = int(tokens[1])-1\n",
    "            val[i] = float(tokens[2])\n",
    "        r = coo_array((val, (row, col)), shape=(n, n))\n",
    "        spio.mmwrite(graph_file+\".mtx\", r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5692fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
