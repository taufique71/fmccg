{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7628bf70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "\t\t\t<script type=\"text/javascript\">\n",
       "\t\t\t<!--\n",
       "\t\t\t\t\n",
       "\t\t\t{\n",
       "\t\t\t\tvar element = document.getElementById('NetworKit_script');\n",
       "\t\t\t\tif (element) {\n",
       "\t\t\t\t\telement.parentNode.removeChild(element);\n",
       "\t\t\t\t}\n",
       "\t\t\t\telement = document.createElement('script');\n",
       "\t\t\t\telement.type = 'text/javascript';\n",
       "\t\t\t\telement.innerHTML = 'function NetworKit_pageEmbed(id) { var i, j; var elements; elements = document.getElementById(id).getElementsByClassName(\"Plot\"); for (i=0; i<elements.length; i++) { elements[i].id = id + \"_Plot_\" + i; var data = elements[i].getAttribute(\"data-image\").split(\"|\"); elements[i].removeAttribute(\"data-image\"); var content = \"<div class=\\\\\"Image\\\\\" id=\\\\\"\" + elements[i].id + \"_Image\\\\\" />\"; elements[i].innerHTML = content; elements[i].setAttribute(\"data-image-index\", 0); elements[i].setAttribute(\"data-image-length\", data.length); for (j=0; j<data.length; j++) { elements[i].setAttribute(\"data-image-\" + j, data[j]); } NetworKit_plotUpdate(elements[i]); elements[i].onclick = function (e) { NetworKit_overlayShow((e.target) ? e.target : e.srcElement); } } elements = document.getElementById(id).getElementsByClassName(\"HeatCell\"); for (i=0; i<elements.length; i++) { var data = parseFloat(elements[i].getAttribute(\"data-heat\")); var color = \"#00FF00\"; if (data <= 1 && data > 0) { color = \"hsla(0, 100%, 75%, \" + (data) + \")\"; } else if (data <= 0 && data >= -1) { color = \"hsla(240, 100%, 75%, \" + (-data) + \")\"; } elements[i].style.backgroundColor = color; } elements = document.getElementById(id).getElementsByClassName(\"Details\"); for (i=0; i<elements.length; i++) { elements[i].setAttribute(\"data-title\", \"-\"); NetworKit_toggleDetails(elements[i]); elements[i].onclick = function (e) { NetworKit_toggleDetails((e.target) ? e.target : e.srcElement); } } elements = document.getElementById(id).getElementsByClassName(\"MathValue\"); for (i=elements.length-1; i>=0; i--) { value = elements[i].innerHTML.trim(); if (value === \"nan\") { elements[i].parentNode.innerHTML = \"\" } } elements = document.getElementById(id).getElementsByClassName(\"SubCategory\"); for (i=elements.length-1; i>=0; i--) { value = elements[i].innerHTML.trim(); if (value === \"\") { elements[i].parentNode.removeChild(elements[i]) } } elements = document.getElementById(id).getElementsByClassName(\"Category\"); for (i=elements.length-1; i>=0; i--) { value = elements[i].innerHTML.trim(); if (value === \"\") { elements[i].parentNode.removeChild(elements[i]) } } var isFirefox = false; try { isFirefox = typeof InstallTrigger !== \"undefined\"; } catch (e) {} if (!isFirefox) { alert(\"Currently the function\\'s output is only fully supported by Firefox.\"); } } function NetworKit_plotUpdate(source) { var index = source.getAttribute(\"data-image-index\"); var data = source.getAttribute(\"data-image-\" + index); var image = document.getElementById(source.id + \"_Image\"); image.style.backgroundImage = \"url(\" + data + \")\"; } function NetworKit_showElement(id, show) { var element = document.getElementById(id); element.style.display = (show) ? \"block\" : \"none\"; } function NetworKit_overlayShow(source) { NetworKit_overlayUpdate(source); NetworKit_showElement(\"NetworKit_Overlay\", true); } function NetworKit_overlayUpdate(source) { document.getElementById(\"NetworKit_Overlay_Title\").innerHTML = source.title; var index = source.getAttribute(\"data-image-index\"); var data = source.getAttribute(\"data-image-\" + index); var image = document.getElementById(\"NetworKit_Overlay_Image\"); image.setAttribute(\"data-id\", source.id); image.style.backgroundImage = \"url(\" + data + \")\"; var link = document.getElementById(\"NetworKit_Overlay_Toolbar_Bottom_Save\"); link.href = data; link.download = source.title + \".svg\"; } function NetworKit_overlayImageShift(delta) { var image = document.getElementById(\"NetworKit_Overlay_Image\"); var source = document.getElementById(image.getAttribute(\"data-id\")); var index = parseInt(source.getAttribute(\"data-image-index\")); var length = parseInt(source.getAttribute(\"data-image-length\")); var index = (index+delta) % length; if (index < 0) { index = length + index; } source.setAttribute(\"data-image-index\", index); NetworKit_overlayUpdate(source); } function NetworKit_toggleDetails(source) { var childs = source.children; var show = false; if (source.getAttribute(\"data-title\") == \"-\") { source.setAttribute(\"data-title\", \"+\"); show = false; } else { source.setAttribute(\"data-title\", \"-\"); show = true; } for (i=0; i<childs.length; i++) { if (show) { childs[i].style.display = \"block\"; } else { childs[i].style.display = \"none\"; } } }';\n",
       "\t\t\t\telement.setAttribute('id', 'NetworKit_script');\n",
       "\t\t\t\tdocument.head.appendChild(element);\n",
       "\t\t\t}\n",
       "\t\t\n",
       "\t\t\t\t\n",
       "\t\t\t{\n",
       "\t\t\t\tvar element = document.getElementById('NetworKit_style');\n",
       "\t\t\t\tif (element) {\n",
       "\t\t\t\t\telement.parentNode.removeChild(element);\n",
       "\t\t\t\t}\n",
       "\t\t\t\telement = document.createElement('style');\n",
       "\t\t\t\telement.type = 'text/css';\n",
       "\t\t\t\telement.innerHTML = '.NetworKit_Page { font-family: Arial, Helvetica, sans-serif; font-size: 14px; } .NetworKit_Page .Value:before { font-family: Arial, Helvetica, sans-serif; font-size: 1.05em; content: attr(data-title) \":\"; margin-left: -2.5em; padding-right: 0.5em; } .NetworKit_Page .Details .Value:before { display: block; } .NetworKit_Page .Value { font-family: monospace; white-space: pre; padding-left: 2.5em; white-space: -moz-pre-wrap !important; white-space: -pre-wrap; white-space: -o-pre-wrap; white-space: pre-wrap; word-wrap: break-word; tab-size: 4; -moz-tab-size: 4; } .NetworKit_Page .Category { clear: both; padding-left: 1em; margin-bottom: 1.5em; } .NetworKit_Page .Category:before { content: attr(data-title); font-size: 1.75em; display: block; margin-left: -0.8em; margin-bottom: 0.5em; } .NetworKit_Page .SubCategory { margin-bottom: 1.5em; padding-left: 1em; } .NetworKit_Page .SubCategory:before { font-size: 1.6em; display: block; margin-left: -0.8em; margin-bottom: 0.5em; } .NetworKit_Page .SubCategory[data-title]:before { content: attr(data-title); } .NetworKit_Page .Block { display: block; } .NetworKit_Page .Block:after { content: \".\"; visibility: hidden; display: block; height: 0; clear: both; } .NetworKit_Page .Block .Thumbnail_Overview, .NetworKit_Page .Block .Thumbnail_ScatterPlot { width: 260px; float: left; } .NetworKit_Page .Block .Thumbnail_Overview img, .NetworKit_Page .Block .Thumbnail_ScatterPlot img { width: 260px; } .NetworKit_Page .Block .Thumbnail_Overview:before, .NetworKit_Page .Block .Thumbnail_ScatterPlot:before { display: block; text-align: center; font-weight: bold; } .NetworKit_Page .Block .Thumbnail_Overview:before { content: attr(data-title); } .NetworKit_Page .HeatCell { font-family: \"Courier New\", Courier, monospace; cursor: pointer; } .NetworKit_Page .HeatCell, .NetworKit_Page .HeatCellName { display: inline; padding: 0.1em; margin-right: 2px; background-color: #FFFFFF } .NetworKit_Page .HeatCellName { margin-left: 0.25em; } .NetworKit_Page .HeatCell:before { content: attr(data-heat); display: inline-block; color: #000000; width: 4em; text-align: center; } .NetworKit_Page .Measure { clear: both; } .NetworKit_Page .Measure .Details { cursor: pointer; } .NetworKit_Page .Measure .Details:before { content: \"[\" attr(data-title) \"]\"; display: block; } .NetworKit_Page .Measure .Details .Value { border-left: 1px dotted black; margin-left: 0.4em; padding-left: 3.5em; pointer-events: none; } .NetworKit_Page .Measure .Details .Spacer:before { content: \".\"; opacity: 0.0; pointer-events: none; } .NetworKit_Page .Measure .Plot { width: 440px; height: 440px; cursor: pointer; float: left; margin-left: -0.9em; margin-right: 20px; } .NetworKit_Page .Measure .Plot .Image { background-repeat: no-repeat; background-position: center center; background-size: contain; height: 100%; pointer-events: none; } .NetworKit_Page .Measure .Stat { width: 500px; float: left; } .NetworKit_Page .Measure .Stat .Group { padding-left: 1.25em; margin-bottom: 0.75em; } .NetworKit_Page .Measure .Stat .Group .Title { font-size: 1.1em; display: block; margin-bottom: 0.3em; margin-left: -0.75em; border-right-style: dotted; border-right-width: 1px; border-bottom-style: dotted; border-bottom-width: 1px; background-color: #D0D0D0; padding-left: 0.2em; } .NetworKit_Page .Measure .Stat .Group .List { -webkit-column-count: 3; -moz-column-count: 3; column-count: 3; } .NetworKit_Page .Measure .Stat .Group .List .Entry { position: relative; line-height: 1.75em; } .NetworKit_Page .Measure .Stat .Group .List .Entry[data-tooltip]:before { position: absolute; left: 0; top: -40px; background-color: #808080; color: #ffffff; height: 30px; line-height: 30px; border-radius: 5px; padding: 0 15px; content: attr(data-tooltip); white-space: nowrap; display: none; } .NetworKit_Page .Measure .Stat .Group .List .Entry[data-tooltip]:after { position: absolute; left: 15px; top: -10px; border-top: 7px solid #808080; border-left: 7px solid transparent; border-right: 7px solid transparent; content: \"\"; display: none; } .NetworKit_Page .Measure .Stat .Group .List .Entry[data-tooltip]:hover:after, .NetworKit_Page .Measure .Stat .Group .List .Entry[data-tooltip]:hover:before { display: block; } .NetworKit_Page .Measure .Stat .Group .List .Entry .MathValue { font-family: \"Courier New\", Courier, monospace; } .NetworKit_Page .Measure:after { content: \".\"; visibility: hidden; display: block; height: 0; clear: both; } .NetworKit_Page .PartitionPie { clear: both; } .NetworKit_Page .PartitionPie img { width: 600px; } #NetworKit_Overlay { left: 0px; top: 0px; display: none; position: absolute; width: 100%; height: 100%; background-color: rgba(0,0,0,0.6); z-index: 1000; } #NetworKit_Overlay_Title { position: absolute; color: white; transform: rotate(-90deg); width: 32em; height: 32em; padding-right: 0.5em; padding-top: 0.5em; text-align: right; font-size: 40px; } #NetworKit_Overlay .button { background: white; cursor: pointer; } #NetworKit_Overlay .button:before { size: 13px; display: inline-block; text-align: center; margin-top: 0.5em; margin-bottom: 0.5em; width: 1.5em; height: 1.5em; } #NetworKit_Overlay .icon-close:before { content: \"X\"; } #NetworKit_Overlay .icon-previous:before { content: \"P\"; } #NetworKit_Overlay .icon-next:before { content: \"N\"; } #NetworKit_Overlay .icon-save:before { content: \"S\"; } #NetworKit_Overlay_Toolbar_Top, #NetworKit_Overlay_Toolbar_Bottom { position: absolute; width: 40px; right: 13px; text-align: right; z-index: 1100; } #NetworKit_Overlay_Toolbar_Top { top: 0.5em; } #NetworKit_Overlay_Toolbar_Bottom { Bottom: 0.5em; } #NetworKit_Overlay_ImageContainer { position: absolute; top: 5%; left: 5%; height: 90%; width: 90%; background-repeat: no-repeat; background-position: center center; background-size: contain; } #NetworKit_Overlay_Image { height: 100%; width: 100%; background-repeat: no-repeat; background-position: center center; background-size: contain; }';\n",
       "\t\t\t\telement.setAttribute('id', 'NetworKit_style');\n",
       "\t\t\t\tdocument.head.appendChild(element);\n",
       "\t\t\t}\n",
       "\t\t\n",
       "\t\t\t\t\n",
       "\t\t\t{\n",
       "\t\t\t\tvar element = document.getElementById('NetworKit_Overlay');\n",
       "\t\t\t\tif (element) {\n",
       "\t\t\t\t\telement.parentNode.removeChild(element);\n",
       "\t\t\t\t}\n",
       "\t\t\t\telement = document.createElement('div');\n",
       "\t\t\t\telement.innerHTML = '<div id=\"NetworKit_Overlay_Toolbar_Top\"><div class=\"button icon-close\" id=\"NetworKit_Overlay_Close\" /></div><div id=\"NetworKit_Overlay_Title\" /> <div id=\"NetworKit_Overlay_ImageContainer\"> <div id=\"NetworKit_Overlay_Image\" /> </div> <div id=\"NetworKit_Overlay_Toolbar_Bottom\"> <div class=\"button icon-previous\" onclick=\"NetworKit_overlayImageShift(-1)\" /> <div class=\"button icon-next\" onclick=\"NetworKit_overlayImageShift(1)\" /> <a id=\"NetworKit_Overlay_Toolbar_Bottom_Save\"><div class=\"button icon-save\" /></a> </div>';\n",
       "\t\t\t\telement.setAttribute('id', 'NetworKit_Overlay');\n",
       "\t\t\t\tdocument.body.appendChild(element);\n",
       "\t\t\t\tdocument.getElementById('NetworKit_Overlay_Close').onclick = function (e) {\n",
       "\t\t\t\t\tdocument.getElementById('NetworKit_Overlay').style.display = 'none';\n",
       "\t\t\t\t}\n",
       "\t\t\t}\n",
       "\t\t\n",
       "\t\t\t-->\n",
       "\t\t\t</script>\n",
       "\t\t"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: to be able to use all crisp methods, you need to install some additional packages:  {'ASLPAw'}\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import networkx.algorithms.community as nx_comm\n",
    "from networkx.generators.community import LFR_benchmark_graph\n",
    "from networkx.algorithms import bipartite\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy.sparse import coo_array\n",
    "from scipy import sparse\n",
    "from cdlib import algorithms\n",
    "from cdlib import evaluation\n",
    "import sklearn\n",
    "from utils import *\n",
    "from distances import *\n",
    "from consensus import *\n",
    "import math\n",
    "import itertools\n",
    "import random\n",
    "import time\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4bce3087",
   "metadata": {},
   "outputs": [],
   "source": [
    "cons_name = \"v4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c74ce98c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True False  True  True]\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "a = np.array([1,2,3,4])\n",
    "b = np.array([1,3,3,4])\n",
    "c = np.equal(a, b)\n",
    "d = np.sum(c)\n",
    "print(c)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3b7e03f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DeltaSOD is calculated following the paper titled \"Integrating Microarray Data by Consensus Clustering\"\n",
    "# by Filkov and Skiena\n",
    "# Assumes the elements of the cluster are named as 0-based indices\n",
    "def v4_consensus(P_list, niter=10, starting_partition=None, verbose=False):\n",
    "    G = nx.Graph(P_list[0][\"graph\"])\n",
    "    n = len(list(G.nodes()))\n",
    "    k = len(P_list)\n",
    "    A = nx.to_numpy_array(G)\n",
    "    nz_rows, nz_cols = np.nonzero(A)\n",
    "    \n",
    "    t1 = time.time()\n",
    "    P_list_asn = []\n",
    "    c = np.zeros((n,k))\n",
    "    for i in range(k):\n",
    "        clust_lst = P_list[i][\"partition\"]\n",
    "        clust_asn = clust_lst_to_asn(clust_lst)\n",
    "        c[:,i] = np.array(clust_asn)\n",
    "    t2 = time.time()\n",
    "    print(\"Time to generate cluster assignment matrix:\", t2-t1)\n",
    "    \n",
    "    t1 = time.time()\n",
    "    Aw = np.array(A)\n",
    "    nz_elems = []\n",
    "    for i in range(len(nz_rows)):\n",
    "        Aw[nz_rows[i], nz_cols[i]] = np.sum( c[nz_rows[i],:] == c[nz_cols[i],:] )\n",
    "        Aw[nz_cols[i], nz_rows[i]] = Aw[nz_rows[i], nz_cols[i]]\n",
    "        nz_elems.append((nz_rows[i], nz_cols[i], Aw[nz_rows[i], nz_cols[i]]))\n",
    "    Gw = nx.from_numpy_array(Aw)\n",
    "    nz_elems = sorted(nz_elems, key=lambda x: x[2], reverse=True)\n",
    "    t2 = time.time()\n",
    "    print(\"Time to generate weighted consensus graph:\", t2-t1)\n",
    "    \n",
    "    \n",
    "    t1 = time.time()\n",
    "    nodes = list(Gw.nodes())\n",
    "    neighbors = {}\n",
    "    bfs_neighbors = {}\n",
    "    for node in nodes:\n",
    "        neighbors[node] = list(Gw.neighbors(node))\n",
    "        bfs_neighbors[node] = []\n",
    "        bfs_edges = list(nx.bfs_tree(Gw, source=node, depth_limit=3).edges())\n",
    "        for edge in bfs_edges:\n",
    "            y = edge[1]\n",
    "            bfs_neighbors[node].append(y)\n",
    "        #bfs_neighbors[node] = set(bfs_neighbors[node])\n",
    "    t2 = time.time()\n",
    "    print(\"Neighborhood list prep:\", t2-t1)\n",
    "    \n",
    "    \"\"\"\n",
    "    t1 = time.time()\n",
    "    row = []\n",
    "    col = []\n",
    "    val = []\n",
    "    for x in P_list:\n",
    "        graph = x[\"graph\"]\n",
    "        partition = x[\"partition\"]\n",
    "        for cluster in partition:\n",
    "            for i in range(len(cluster)):\n",
    "                for j in range(i+1, len(cluster)):\n",
    "                    item_1 = cluster[i]\n",
    "                    item_2 = cluster[j]\n",
    "                    row.append(min(int(item_1), int(item_2)))\n",
    "                    col.append(max(int(item_1), int(item_2)))\n",
    "                    val.append(int(1))\n",
    "                    \n",
    "    r = coo_array((val, (row, col)), shape=(n, n))\n",
    "    print(\"r.nnz:\", r.nnz)\n",
    "    t2 = time.time()\n",
    "    print(\"Time to prepare r:\", t2-t1)\n",
    "    \"\"\"\n",
    "    \n",
    "    t1 = time.time()\n",
    "    row = []\n",
    "    col = []\n",
    "    val = []\n",
    "    for x in P_list:\n",
    "        graph = x[\"graph\"]\n",
    "        partition_lst = x[\"partition\"]\n",
    "        partition_asn = clust_lst_to_asn(partition_lst)\n",
    "        for node in nodes:\n",
    "            for bfsn in bfs_neighbors[node]:\n",
    "                if partition_asn[node] == partition_asn[bfsn]:\n",
    "                    row.append(node)\n",
    "                    col.append(bfsn)\n",
    "                    val.append(1)\n",
    "                    \n",
    "                    #row.append(bfsn)\n",
    "                    #col.append(node)\n",
    "                    #val.append(1)\n",
    "    r = coo_array((val, (row, col)), shape=(n, n))\n",
    "    print(\"r.nnz:\", r.nnz)\n",
    "    t2 = time.time()\n",
    "    print(\"Time to prepare r:\", t2-t1)\n",
    "    \n",
    "    r = r.tocsr()\n",
    "    R = r.sum()\n",
    "    if verbose:\n",
    "        print(\"R:\", R)\n",
    "    \n",
    "    t1 = time.time()\n",
    "    rDense = r.toarray() # Should be upper triangular\n",
    "    rDense = rDense + rDense.T # Making symmetric\n",
    "    t2 = time.time()\n",
    "    print(\"Time to prepare rDense:\", t2-t1)\n",
    "    \n",
    "    K = k - 2 * rDense\n",
    "    np.fill_diagonal(K, -k) # Adding diagonal entries\n",
    "    \n",
    "    t1 = time.time()\n",
    "    refined_partition = None\n",
    "    if starting_partition:\n",
    "        refined_partition = list(starting_partition)\n",
    "    else:\n",
    "        refined_partition = []\n",
    "        for i in range(n):\n",
    "            refined_partition.append([str(i)])\n",
    "    \n",
    "    refined_partition_map = clust_lst_to_map(refined_partition)\n",
    "    t2 = time.time()\n",
    "    print(\"Time to initialize:\", t2-t1)\n",
    "    \n",
    "    t1 = time.time()\n",
    "    items = list(refined_partition_map.keys())\n",
    "    M = np.zeros((n, len(refined_partition)))\n",
    "    for item_1 in items:\n",
    "        for partition_id in range(len(refined_partition)):\n",
    "            for item_2 in refined_partition[partition_id]:\n",
    "                if(item_1 != item_2):\n",
    "                    M[int(item_1),partition_id] = M[int(item_1),partition_id] + K[int(item_1), int(item_2)]\n",
    "    \n",
    "    mv = np.min(M, axis=1)\n",
    "    mb = np.argmin(M, axis=1)\n",
    "    t2 = time.time()\n",
    "    print(\"Time to prepare M:\", t2-t1)\n",
    "    \n",
    "    tSearch = 0\n",
    "    tUpdate = 0\n",
    "    tMovement = 0\n",
    "    count = 0\n",
    "    it = 1\n",
    "    while(it <= niter):\n",
    "        opt_item = items[0]\n",
    "        opt_deltaS = 0\n",
    "        opt_a = refined_partition_map[items[0]]\n",
    "        opt_b = refined_partition_map[items[0]]\n",
    "        opt_x = int(opt_item)\n",
    "        flag = False\n",
    "        for i in range(len(nz_elems)):\n",
    "            if verbose:\n",
    "                print(\"nz_elems[\", i, \"]\", nz_elems[i])\n",
    "            t1 = time.time()\n",
    "            x1 = nz_elems[i][0]\n",
    "            x2 = nz_elems[i][1]\n",
    "            a1 = refined_partition_map[str(x1)]\n",
    "            a2 = refined_partition_map[str(x2)]\n",
    "            deltaS1 = M[x1,a2] - M[x1,a1]\n",
    "            deltaS2 = M[x2,a1] - M[x2,a2]\n",
    "            x = None\n",
    "            item = None\n",
    "            b = None\n",
    "            deltaS = None\n",
    "            if (deltaS1 < deltaS2):\n",
    "                x = x1\n",
    "                item = str(x1)\n",
    "                a = a1\n",
    "                b = a2\n",
    "                deltaS = deltaS1\n",
    "            else:\n",
    "                x = x2\n",
    "                item = str(x2)\n",
    "                a = a2\n",
    "                b = a1\n",
    "                deltaS = deltaS2\n",
    "            t2 = time.time()\n",
    "            tSearch = tSearch + t2-t1\n",
    "            if (deltaS is not None) and (deltaS < 0) and (a != b):\n",
    "                opt_item = item\n",
    "                opt_deltaS = deltaS\n",
    "                opt_a = a\n",
    "                opt_b = b\n",
    "                opt_x = x\n",
    "                \n",
    "                if verbose:\n",
    "                    print(\"---\")\n",
    "                    print(\"Move Count:\", count+1, \"Optimum move results in\", opt_deltaS)\n",
    "                    print(\"Move:\", opt_item)\n",
    "                    print(\"From\", opt_a, \":\", refined_partition[opt_a])\n",
    "                    print(\"To\", opt_b, \":\", refined_partition[opt_b])\n",
    "                    \n",
    "                t1 = time.time()\n",
    "                #print(len(items), len(list(nx.bfs_tree(Gw, source=opt_x, depth_limit=5).edges())))\n",
    "                #bfs_edges = list(nx.bfs_tree(Gw, source=opt_x, depth_limit=5).edges())\n",
    "                #for edge in bfs_edges:\n",
    "                    #y = edge[1]\n",
    "                for y_str in bfs_neighbors[opt_x]:\n",
    "                    y = int(y_str)\n",
    "                    if y != opt_x:\n",
    "                        M[y, opt_a] = M[y, opt_a] - K[y, opt_x]\n",
    "                        M[y, opt_b] = M[y, opt_b] + K[y, opt_x]\n",
    "                t2 = time.time()\n",
    "                tUpdate = tUpdate + (t2-t1)\n",
    "                \n",
    "                t1 = time.time()\n",
    "                refined_partition[opt_a].remove(opt_item)\n",
    "                refined_partition[opt_b].append(opt_item)\n",
    "                refined_partition_map[opt_item] = opt_b\n",
    "                t2 = time.time()\n",
    "                tMovement = tMovement + (t2-t1)\n",
    "                if verbose:\n",
    "                    print(\"---\")\n",
    "            \n",
    "                count = count + 1\n",
    "                flag = True\n",
    "        if flag == False:\n",
    "            break\n",
    "\n",
    "        it = it + 1\n",
    "    print(\"Time to search moves:\", tSearch)\n",
    "    print(\"Time to update M:\", tUpdate)\n",
    "    \n",
    "    t1 = time.time()\n",
    "    empty_clusters = []\n",
    "    for i in range(len(refined_partition)):\n",
    "        if len(refined_partition[i]) == 0:\n",
    "            empty_clusters.append(i)\n",
    "            \n",
    "    empty_clusters.sort(reverse=True)\n",
    "    for e in empty_clusters:\n",
    "        del refined_partition[e]\n",
    "    t2 = time.time()\n",
    "    print(\"Time to delete empty partitions:\", t2-t1)\n",
    "        \n",
    "    #G = nx.from_scipy_sparse_array(r)\n",
    "    \n",
    "    return {\"graph\": nx.Graph(Gw), \"partition\": list(refined_partition)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074ddb46",
   "metadata": {},
   "source": [
    "# n=200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "03a41e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('algorithms.label_propagation(G)', 0), ('algorithms.leiden(G)', 1), ('algorithms.significance_communities(G)', 2), ('algorithms.surprise_communities(G)', 3), ('algorithms.greedy_modularity(G)', 4), ('algorithms.paris(G)', 5), ('algorithms.louvain(G,resolution=0.75,randomize=314159)', 6), ('algorithms.louvain(G,resolution=0.75,randomize=2718)', 7), ('algorithms.louvain(G,resolution=1.0,randomize=314159)', 8), ('algorithms.louvain(G,resolution=1.0,randomize=2718)', 9), ('algorithms.louvain(G,resolution=1.25,randomize=314159)', 10), ('algorithms.louvain(G,resolution=1.25,randomize=2718)', 11), ('algorithms.louvain(G,resolution=1.5,randomize=314159)', 12), ('algorithms.louvain(G,resolution=1.5,randomize=2718)', 13), ('algorithms.infomap(G)', 14), ('algorithms.walktrap(G)', 15), ('algorithms.markov_clustering(G,inflation=1.2,pruning_threshold=0.01,convergence_check_frequency=100)', 16), ('algorithms.markov_clustering(G,inflation=1.2,pruning_threshold=0.001,convergence_check_frequency=100)', 17), ('algorithms.markov_clustering(G,inflation=1.5,pruning_threshold=0.01,convergence_check_frequency=100)', 18), ('algorithms.markov_clustering(G,inflation=1.5,pruning_threshold=0.001,convergence_check_frequency=100)', 19), ('algorithms.markov_clustering(G,inflation=2,pruning_threshold=0.01,convergence_check_frequency=100)', 20), ('algorithms.markov_clustering(G,inflation=2,pruning_threshold=0.001,convergence_check_frequency=100)', 21), ('algorithms.markov_clustering(G,inflation=2.5,pruning_threshold=0.01,convergence_check_frequency=100)', 22), ('algorithms.markov_clustering(G,inflation=2.5,pruning_threshold=0.001,convergence_check_frequency=100)', 23), ('algorithms.em(G,k=28)', 24), ('algorithms.em(G,k=5)', 25), ('algorithms.em(G,k=7)', 26), ('algorithms.em(G,k=42)', 27), ('algorithms.sbm_dl(G)', 28), ('algorithms.spinglass(G,spins=28)', 29), ('algorithms.spinglass(G,spins=5)', 30), ('algorithms.spinglass(G,spins=7)', 31), ('algorithms.spinglass(G,spins=42)', 32), ('algorithms.ricci_community(G,alpha=0.3)', 33), ('algorithms.ricci_community(G,alpha=0.5)', 34), ('algorithms.ricci_community(G,alpha=0.6)', 35), ('algorithms.ricci_community(G,alpha=0.75)', 36)]\n"
     ]
    }
   ],
   "source": [
    "n = 200\n",
    "expected_clusters = []\n",
    "for i in range(4):\n",
    "    expected_clusters.append(random.randint(int(n ** (1. / 3)),3*int(n ** (1. / 2))))\n",
    "    \n",
    "alg_params = {\n",
    "    \"label_propagation\": None,\n",
    "    \"leiden\": None,\n",
    "    \"significance_communities\": None,\n",
    "    \"surprise_communities\": None,\n",
    "    \"greedy_modularity\": None,\n",
    "    \"paris\": None,\n",
    "    \"louvain\": {\n",
    "        \"resolution\": [0.75, 1.0, 1.25, 1.5],\n",
    "        \"randomize\": [314159, 2718]\n",
    "    },\n",
    "    \"infomap\": None,\n",
    "    \"walktrap\": None,\n",
    "    \"markov_clustering\": {\n",
    "        \"inflation\": [1.2, 1.5, 2, 2.5],\n",
    "        \"pruning_threshold\": [0.01, 0.001],\n",
    "        \"convergence_check_frequency\": [100]\n",
    "    },\n",
    "    \"em\": {\n",
    "        \"k\": list(expected_clusters)\n",
    "    },\n",
    "    \"sbm_dl\": None,\n",
    "    \"spinglass\": {\n",
    "        \"spins\": list(expected_clusters)\n",
    "    },\n",
    "    \"ricci_community\": {\n",
    "        \"alpha\": [0.3, 0.5, 0.6, 0.75]\n",
    "    }\n",
    "}\n",
    "\n",
    "clustering_enumeration = []\n",
    "count = 0\n",
    "for alg, params in alg_params.items():\n",
    "    param_combinations = []\n",
    "    param_names = []\n",
    "    if params is not None:\n",
    "        iterables = []\n",
    "        param_names = []\n",
    "        for param in params.keys():\n",
    "            iterables.append(list(params[param]))\n",
    "            param_names.append(param)\n",
    "        param_combinations = list(itertools.product(*iterables))\n",
    "    if len(param_combinations) > 0:\n",
    "        for param_combination in param_combinations:\n",
    "            expr = \"algorithms.\"+alg+\"(G\"\n",
    "            for i in range(len(param_names)):\n",
    "                expr = expr + \",\" + param_names[i] + \"=\" + str(param_combination[i])\n",
    "            expr = expr + \")\"\n",
    "            clustering_enumeration.append((expr,count))\n",
    "            count = count + 1      \n",
    "    else:\n",
    "        expr = \"algorithms.\"+alg+\"(G)\"\n",
    "        clustering_enumeration.append((expr,count))\n",
    "        count = count + 1\n",
    "        \n",
    "print(clustering_enumeration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ab36873c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LFR/n200/LFR_n200_mu01_gamma30_beta11.mtx\n",
      "Time to generate cluster assignment matrix: 0.0024747848510742188\n",
      "Time to generate weighted consensus graph: 0.01470184326171875\n",
      "Neighborhood list prep: 0.062403202056884766\n",
      "r.nnz: 235796\n",
      "Time to prepare r: 0.09558224678039551\n",
      "Time to prepare rDense: 8.273124694824219e-05\n",
      "Time to initialize: 0.0022764205932617188\n",
      "Time to prepare M: 0.03168153762817383\n",
      "Time to search moves: 0.00482940673828125\n",
      "Time to update M: 0.024632930755615234\n",
      "Time to delete empty partitions: 6.151199340820312e-05\n",
      "mu 1 , number of clusters 16\n",
      "Time: 0.2635152339935303\n",
      "LFR/n200/LFR_n200_mu02_gamma30_beta11.mtx\n",
      "Time to generate cluster assignment matrix: 0.0030477046966552734\n",
      "Time to generate weighted consensus graph: 0.014647722244262695\n",
      "Neighborhood list prep: 0.07484197616577148\n",
      "r.nnz: 227548\n",
      "Time to prepare r: 0.10245895385742188\n",
      "Time to prepare rDense: 8.630752563476562e-05\n",
      "Time to initialize: 7.2479248046875e-05\n",
      "Time to prepare M: 0.030550241470336914\n",
      "Time to search moves: 0.0046234130859375\n",
      "Time to update M: 0.03162074089050293\n",
      "Time to delete empty partitions: 3.147125244140625e-05\n",
      "mu 2 , number of clusters 16\n",
      "Time: 0.289217472076416\n",
      "LFR/n200/LFR_n200_mu03_gamma30_beta11.mtx\n",
      "Time to generate cluster assignment matrix: 0.002709627151489258\n",
      "Time to generate weighted consensus graph: 0.014910459518432617\n",
      "Neighborhood list prep: 0.09186792373657227\n",
      "r.nnz: 391498\n",
      "Time to prepare r: 0.14320898056030273\n",
      "Time to prepare rDense: 9.250640869140625e-05\n",
      "Time to initialize: 7.343292236328125e-05\n",
      "Time to prepare M: 0.03242802619934082\n",
      "Time to search moves: 0.007456541061401367\n",
      "Time to update M: 0.03873300552368164\n",
      "Time to delete empty partitions: 3.123283386230469e-05\n",
      "mu 3 , number of clusters 17\n",
      "Time: 0.3774683475494385\n",
      "LFR/n200/LFR_n200_mu04_gamma30_beta11.mtx\n",
      "Time to generate cluster assignment matrix: 0.0024292469024658203\n",
      "Time to generate weighted consensus graph: 0.015694618225097656\n",
      "Neighborhood list prep: 0.09211421012878418\n",
      "r.nnz: 564416\n",
      "Time to prepare r: 0.17647361755371094\n",
      "Time to prepare rDense: 8.96453857421875e-05\n",
      "Time to initialize: 7.2479248046875e-05\n",
      "Time to prepare M: 0.032698869705200195\n",
      "Time to search moves: 0.007615327835083008\n",
      "Time to update M: 0.0713043212890625\n",
      "Time to delete empty partitions: 3.314018249511719e-05\n",
      "mu 4 , number of clusters 2\n",
      "Time: 0.45066165924072266\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "n = 200\n",
    "fileprefix = \"LFR/\" + \"n\" + str(n) + \"/\"\n",
    "mus = [1, 2, 3, 4]\n",
    "#mus = [4]\n",
    "gammas = [30]\n",
    "betas = [11]\n",
    "for mu in mus:\n",
    "    for gamma in gammas:\n",
    "        for beta in betas:\n",
    "            P_list = []\n",
    "            fname = \"LFR_n\" + str(n) + \"_mu0\" + str(mu) + \"_gamma\" + str(gamma) + \"_beta\" + str(beta)\n",
    "            graph_file = fileprefix + fname + \".mtx\"\n",
    "            print(graph_file)\n",
    "            G = None\n",
    "            with open(graph_file) as f:\n",
    "                G = nx.from_scipy_sparse_array(spio.mmread(f), create_using=nx.Graph)\n",
    "                coms = None\n",
    "                for k in clustering_enumeration:\n",
    "                    clust_file = fileprefix + fname + \".\" + str(k[1])\n",
    "                    if Path(clust_file).is_file():\n",
    "                        partition = read_clust_lst(clust_file)\n",
    "                        P_list.append({\"graph\": nx.Graph(G), \"partition\": list(partition)})\n",
    "                t1 = time.time()\n",
    "                P_star = v4_consensus(P_list, niter=1000, starting_partition = None, verbose=False)\n",
    "                t2 = time.time()\n",
    "                print(\"mu\", mu, \", number of clusters\", len(P_star[\"partition\"]))\n",
    "                print(\"Time:\", t2-t1)\n",
    "                write_clust_lst(P_star[\"partition\"], fileprefix + fname + \".\" + cons_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b24c46",
   "metadata": {},
   "source": [
    "# n=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1b7550c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('algorithms.label_propagation(G)', 0), ('algorithms.leiden(G)', 1), ('algorithms.significance_communities(G)', 2), ('algorithms.surprise_communities(G)', 3), ('algorithms.greedy_modularity(G)', 4), ('algorithms.paris(G)', 5), ('algorithms.louvain(G,resolution=0.75,randomize=314159)', 6), ('algorithms.louvain(G,resolution=0.75,randomize=2718)', 7), ('algorithms.louvain(G,resolution=1.0,randomize=314159)', 8), ('algorithms.louvain(G,resolution=1.0,randomize=2718)', 9), ('algorithms.louvain(G,resolution=1.25,randomize=314159)', 10), ('algorithms.louvain(G,resolution=1.25,randomize=2718)', 11), ('algorithms.louvain(G,resolution=1.5,randomize=314159)', 12), ('algorithms.louvain(G,resolution=1.5,randomize=2718)', 13), ('algorithms.infomap(G)', 14), ('algorithms.walktrap(G)', 15), ('algorithms.markov_clustering(G,inflation=1.2,pruning_threshold=0.01,convergence_check_frequency=100)', 16), ('algorithms.markov_clustering(G,inflation=1.2,pruning_threshold=0.001,convergence_check_frequency=100)', 17), ('algorithms.markov_clustering(G,inflation=1.5,pruning_threshold=0.01,convergence_check_frequency=100)', 18), ('algorithms.markov_clustering(G,inflation=1.5,pruning_threshold=0.001,convergence_check_frequency=100)', 19), ('algorithms.markov_clustering(G,inflation=2,pruning_threshold=0.01,convergence_check_frequency=100)', 20), ('algorithms.markov_clustering(G,inflation=2,pruning_threshold=0.001,convergence_check_frequency=100)', 21), ('algorithms.markov_clustering(G,inflation=2.5,pruning_threshold=0.01,convergence_check_frequency=100)', 22), ('algorithms.markov_clustering(G,inflation=2.5,pruning_threshold=0.001,convergence_check_frequency=100)', 23), ('algorithms.em(G,k=22)', 24), ('algorithms.em(G,k=79)', 25), ('algorithms.em(G,k=9)', 26), ('algorithms.em(G,k=46)', 27), ('algorithms.sbm_dl(G)', 28), ('algorithms.spinglass(G,spins=22)', 29), ('algorithms.spinglass(G,spins=79)', 30), ('algorithms.spinglass(G,spins=9)', 31), ('algorithms.spinglass(G,spins=46)', 32), ('algorithms.ricci_community(G,alpha=0.3)', 33), ('algorithms.ricci_community(G,alpha=0.5)', 34), ('algorithms.ricci_community(G,alpha=0.6)', 35), ('algorithms.ricci_community(G,alpha=0.75)', 36)]\n"
     ]
    }
   ],
   "source": [
    "n = 1000\n",
    "expected_clusters = []\n",
    "for i in range(4):\n",
    "    expected_clusters.append(random.randint(int(n ** (1. / 3)),3*int(n ** (1. / 2))))\n",
    "    \n",
    "alg_params = {\n",
    "    \"label_propagation\": None,\n",
    "    \"leiden\": None,\n",
    "    \"significance_communities\": None,\n",
    "    \"surprise_communities\": None,\n",
    "    \"greedy_modularity\": None,\n",
    "    \"paris\": None,\n",
    "    \"louvain\": {\n",
    "        \"resolution\": [0.75, 1.0, 1.25, 1.5],\n",
    "        \"randomize\": [314159, 2718]\n",
    "    },\n",
    "    \"infomap\": None,\n",
    "    \"walktrap\": None,\n",
    "    \"markov_clustering\": {\n",
    "        \"inflation\": [1.2, 1.5, 2, 2.5],\n",
    "        \"pruning_threshold\": [0.01, 0.001],\n",
    "        \"convergence_check_frequency\": [100]\n",
    "    },\n",
    "    \"em\": {\n",
    "        \"k\": list(expected_clusters)\n",
    "    },\n",
    "    \"sbm_dl\": None,\n",
    "    \"spinglass\": {\n",
    "        \"spins\": list(expected_clusters)\n",
    "    },\n",
    "    \"ricci_community\": {\n",
    "        \"alpha\": [0.3, 0.5, 0.6, 0.75]\n",
    "    }\n",
    "}\n",
    "\n",
    "clustering_enumeration = []\n",
    "count = 0\n",
    "for alg, params in alg_params.items():\n",
    "    param_combinations = []\n",
    "    param_names = []\n",
    "    if params is not None:\n",
    "        iterables = []\n",
    "        param_names = []\n",
    "        for param in params.keys():\n",
    "            iterables.append(list(params[param]))\n",
    "            param_names.append(param)\n",
    "        param_combinations = list(itertools.product(*iterables))\n",
    "    if len(param_combinations) > 0:\n",
    "        for param_combination in param_combinations:\n",
    "            expr = \"algorithms.\"+alg+\"(G\"\n",
    "            for i in range(len(param_names)):\n",
    "                expr = expr + \",\" + param_names[i] + \"=\" + str(param_combination[i])\n",
    "            expr = expr + \")\"\n",
    "            clustering_enumeration.append((expr,count))\n",
    "            count = count + 1      \n",
    "    else:\n",
    "        expr = \"algorithms.\"+alg+\"(G)\"\n",
    "        clustering_enumeration.append((expr,count))\n",
    "        count = count + 1\n",
    "        \n",
    "print(clustering_enumeration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ad03a766",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LFR/n1000/LFR_n1000_mu01_gamma30_beta11.mtx\n",
      "Time to generate cluster assignment matrix: 0.012668609619140625\n",
      "Time to generate weighted consensus graph: 0.14499902725219727\n",
      "Neighborhood list prep: 1.0340590476989746\n",
      "r.nnz: 1377994\n",
      "Time to prepare r: 1.0513384342193604\n",
      "Time to prepare rDense: 0.0022389888763427734\n",
      "Time to initialize: 0.012945413589477539\n",
      "Time to prepare M: 0.8441145420074463\n",
      "Time to search moves: 0.054007530212402344\n",
      "Time to update M: 0.5379209518432617\n",
      "Time to delete empty partitions: 0.0001800060272216797\n",
      "mu 1 , number of clusters 38\n",
      "Time: 3.8883891105651855\n",
      "LFR/n1000/LFR_n1000_mu02_gamma30_beta11.mtx\n",
      "Time to generate cluster assignment matrix: 0.012375593185424805\n",
      "Time to generate weighted consensus graph: 0.14670705795288086\n",
      "Neighborhood list prep: 2.285011053085327\n",
      "r.nnz: 2247534\n",
      "Time to prepare r: 1.8389804363250732\n",
      "Time to prepare rDense: 0.002635478973388672\n",
      "Time to initialize: 0.020925283432006836\n",
      "Time to prepare M: 0.857600212097168\n",
      "Time to search moves: 0.05246543884277344\n",
      "Time to update M: 0.9831314086914062\n",
      "Time to delete empty partitions: 0.0001850128173828125\n",
      "mu 2 , number of clusters 38\n",
      "Time: 6.485037565231323\n",
      "LFR/n1000/LFR_n1000_mu03_gamma30_beta11.mtx\n",
      "Time to generate cluster assignment matrix: 0.012279987335205078\n",
      "Time to generate weighted consensus graph: 0.15391969680786133\n",
      "Neighborhood list prep: 3.419072389602661\n",
      "r.nnz: 4265292\n",
      "Time to prepare r: 2.567868709564209\n",
      "Time to prepare rDense: 0.0028574466705322266\n",
      "Time to initialize: 0.04061174392700195\n",
      "Time to prepare M: 0.8097014427185059\n",
      "Time to search moves: 0.0783376693725586\n",
      "Time to update M: 1.127856969833374\n",
      "Time to delete empty partitions: 0.00038886070251464844\n",
      "mu 3 , number of clusters 37\n",
      "Time: 8.684626579284668\n",
      "LFR/n1000/LFR_n1000_mu04_gamma30_beta11.mtx\n",
      "Time to generate cluster assignment matrix: 0.011729955673217773\n",
      "Time to generate weighted consensus graph: 0.15866971015930176\n",
      "Neighborhood list prep: 3.531216859817505\n",
      "r.nnz: 7739118\n",
      "Time to prepare r: 3.2184150218963623\n",
      "Time to prepare rDense: 0.0031135082244873047\n",
      "Time to initialize: 0.07383084297180176\n",
      "Time to prepare M: 0.8052055835723877\n",
      "Time to search moves: 0.08240604400634766\n",
      "Time to update M: 1.230381727218628\n",
      "Time to delete empty partitions: 0.00020170211791992188\n",
      "mu 4 , number of clusters 32\n",
      "Time: 9.896045923233032\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "n = 1000\n",
    "fileprefix = \"LFR/\" + \"n\" + str(n) + \"/\"\n",
    "mus = [1, 2, 3, 4]\n",
    "#mus = [4]\n",
    "gammas = [30]\n",
    "betas = [11]\n",
    "for mu in mus:\n",
    "    for gamma in gammas:\n",
    "        for beta in betas:\n",
    "            P_list = []\n",
    "            fname = \"LFR_n\" + str(n) + \"_mu0\" + str(mu) + \"_gamma\" + str(gamma) + \"_beta\" + str(beta)\n",
    "            graph_file = fileprefix + fname + \".mtx\"\n",
    "            print(graph_file)\n",
    "            G = None\n",
    "            with open(graph_file) as f:\n",
    "                G = nx.from_scipy_sparse_array(spio.mmread(f), create_using=nx.Graph)\n",
    "                coms = None\n",
    "                for k in clustering_enumeration:\n",
    "                    clust_file = fileprefix + fname + \".\" + str(k[1])\n",
    "                    if Path(clust_file).is_file():\n",
    "                        partition = read_clust_lst(clust_file)\n",
    "                        P_list.append({\"graph\": nx.Graph(G), \"partition\": list(partition)})\n",
    "                t1 = time.time()\n",
    "                P_star = v4_consensus(P_list, niter=1000, starting_partition=None, verbose=False)\n",
    "                t2 = time.time()\n",
    "                print(\"mu\", mu, \", number of clusters\", len(P_star[\"partition\"]))\n",
    "                print(\"Time:\", t2-t1)\n",
    "                write_clust_lst(P_star[\"partition\"], fileprefix + fname + \".\" + cons_name)\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d9c52b",
   "metadata": {},
   "source": [
    "# n=5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "68555d8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('algorithms.label_propagation(G)', 0), ('algorithms.leiden(G)', 1), ('algorithms.significance_communities(G)', 2), ('algorithms.surprise_communities(G)', 3), ('algorithms.greedy_modularity(G)', 4), ('algorithms.paris(G)', 5), ('algorithms.louvain(G,resolution=0.75,randomize=314159)', 6), ('algorithms.louvain(G,resolution=0.75,randomize=2718)', 7), ('algorithms.louvain(G,resolution=1.0,randomize=314159)', 8), ('algorithms.louvain(G,resolution=1.0,randomize=2718)', 9), ('algorithms.louvain(G,resolution=1.25,randomize=314159)', 10), ('algorithms.louvain(G,resolution=1.25,randomize=2718)', 11), ('algorithms.louvain(G,resolution=1.5,randomize=314159)', 12), ('algorithms.louvain(G,resolution=1.5,randomize=2718)', 13), ('algorithms.infomap(G)', 14), ('algorithms.walktrap(G)', 15), ('algorithms.markov_clustering(G,inflation=1.2,pruning_threshold=0.01,convergence_check_frequency=100)', 16), ('algorithms.markov_clustering(G,inflation=1.2,pruning_threshold=0.001,convergence_check_frequency=100)', 17), ('algorithms.markov_clustering(G,inflation=1.5,pruning_threshold=0.01,convergence_check_frequency=100)', 18), ('algorithms.markov_clustering(G,inflation=1.5,pruning_threshold=0.001,convergence_check_frequency=100)', 19), ('algorithms.markov_clustering(G,inflation=2,pruning_threshold=0.01,convergence_check_frequency=100)', 20), ('algorithms.markov_clustering(G,inflation=2,pruning_threshold=0.001,convergence_check_frequency=100)', 21), ('algorithms.markov_clustering(G,inflation=2.5,pruning_threshold=0.01,convergence_check_frequency=100)', 22), ('algorithms.markov_clustering(G,inflation=2.5,pruning_threshold=0.001,convergence_check_frequency=100)', 23), ('algorithms.em(G,k=176)', 24), ('algorithms.em(G,k=204)', 25), ('algorithms.em(G,k=91)', 26), ('algorithms.em(G,k=45)', 27), ('algorithms.sbm_dl(G)', 28), ('algorithms.spinglass(G,spins=176)', 29), ('algorithms.spinglass(G,spins=204)', 30), ('algorithms.spinglass(G,spins=91)', 31), ('algorithms.spinglass(G,spins=45)', 32), ('algorithms.ricci_community(G,alpha=0.3)', 33), ('algorithms.ricci_community(G,alpha=0.5)', 34), ('algorithms.ricci_community(G,alpha=0.6)', 35), ('algorithms.ricci_community(G,alpha=0.75)', 36)]\n"
     ]
    }
   ],
   "source": [
    "n = 5000\n",
    "expected_clusters = []\n",
    "for i in range(4):\n",
    "    expected_clusters.append(random.randint(int(n ** (1. / 3)),3*int(n ** (1. / 2))))\n",
    "    \n",
    "alg_params = {\n",
    "    \"label_propagation\": None,\n",
    "    \"leiden\": None,\n",
    "    \"significance_communities\": None,\n",
    "    \"surprise_communities\": None,\n",
    "    \"greedy_modularity\": None,\n",
    "    \"paris\": None,\n",
    "    \"louvain\": {\n",
    "        \"resolution\": [0.75, 1.0, 1.25, 1.5],\n",
    "        \"randomize\": [314159, 2718]\n",
    "    },\n",
    "    \"infomap\": None,\n",
    "    \"walktrap\": None,\n",
    "    \"markov_clustering\": {\n",
    "        \"inflation\": [1.2, 1.5, 2, 2.5],\n",
    "        \"pruning_threshold\": [0.01, 0.001],\n",
    "        \"convergence_check_frequency\": [100]\n",
    "    },\n",
    "    \"em\": {\n",
    "        \"k\": list(expected_clusters)\n",
    "    },\n",
    "    \"sbm_dl\": None,\n",
    "    \"spinglass\": {\n",
    "        \"spins\": list(expected_clusters)\n",
    "    },\n",
    "    \"ricci_community\": {\n",
    "        \"alpha\": [0.3, 0.5, 0.6, 0.75]\n",
    "    }\n",
    "}\n",
    "\n",
    "clustering_enumeration = []\n",
    "count = 0\n",
    "for alg, params in alg_params.items():\n",
    "    param_combinations = []\n",
    "    param_names = []\n",
    "    if params is not None:\n",
    "        iterables = []\n",
    "        param_names = []\n",
    "        for param in params.keys():\n",
    "            iterables.append(list(params[param]))\n",
    "            param_names.append(param)\n",
    "        param_combinations = list(itertools.product(*iterables))\n",
    "    if len(param_combinations) > 0:\n",
    "        for param_combination in param_combinations:\n",
    "            expr = \"algorithms.\"+alg+\"(G\"\n",
    "            for i in range(len(param_names)):\n",
    "                expr = expr + \",\" + param_names[i] + \"=\" + str(param_combination[i])\n",
    "            expr = expr + \")\"\n",
    "            clustering_enumeration.append((expr,count))\n",
    "            count = count + 1      \n",
    "    else:\n",
    "        expr = \"algorithms.\"+alg+\"(G)\"\n",
    "        clustering_enumeration.append((expr,count))\n",
    "        count = count + 1\n",
    "        \n",
    "print(clustering_enumeration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f067cc96",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LFR/n5000/LFR_n5000_mu01_gamma30_beta11.mtx\n",
      "Time to generate cluster assignment matrix: 0.0655660629272461\n",
      "Time to generate weighted consensus graph: 0.8906497955322266\n",
      "Neighborhood list prep: 10.445287942886353\n",
      "r.nnz: 10863926\n",
      "Time to prepare r: 7.9341514110565186\n",
      "Time to prepare rDense: 0.29502129554748535\n",
      "Time to initialize: 0.0015158653259277344\n",
      "Time to prepare M: 21.08752703666687\n",
      "Time to search moves: 0.28795623779296875\n",
      "Time to update M: 4.060292482376099\n",
      "Time to delete empty partitions: 0.0008149147033691406\n",
      "mu 1 , number of clusters 201\n",
      "Time: 46.70052170753479\n",
      "LFR/n5000/LFR_n5000_mu02_gamma30_beta11.mtx\n",
      "Time to generate cluster assignment matrix: 0.06761717796325684\n",
      "Time to generate weighted consensus graph: 0.9039409160614014\n",
      "Neighborhood list prep: 23.66901135444641\n",
      "r.nnz: 13876954\n",
      "Time to prepare r: 14.251368761062622\n",
      "Time to prepare rDense: 0.3007338047027588\n",
      "Time to initialize: 0.14516496658325195\n",
      "Time to prepare M: 21.25161051750183\n",
      "Time to search moves: 0.43729305267333984\n",
      "Time to update M: 8.315298080444336\n",
      "Time to delete empty partitions: 0.0007963180541992188\n",
      "mu 2 , number of clusters 201\n",
      "Time: 71.33846354484558\n",
      "LFR/n5000/LFR_n5000_mu03_gamma30_beta11.mtx\n",
      "Time to generate cluster assignment matrix: 0.07598090171813965\n",
      "Time to generate weighted consensus graph: 1.0105006694793701\n",
      "Neighborhood list prep: 46.92447304725647\n",
      "r.nnz: 21568858\n",
      "Time to prepare r: 25.13228988647461\n",
      "Time to prepare rDense: 0.2973642349243164\n",
      "Time to initialize: 0.4555327892303467\n",
      "Time to prepare M: 20.29937243461609\n",
      "Time to search moves: 0.3073599338531494\n",
      "Time to update M: 13.979553699493408\n",
      "Time to delete empty partitions: 0.0008990764617919922\n",
      "mu 3 , number of clusters 201\n",
      "Time: 111.05105638504028\n",
      "LFR/n5000/LFR_n5000_mu04_gamma30_beta11.mtx\n",
      "Time to generate cluster assignment matrix: 0.06822037696838379\n",
      "Time to generate weighted consensus graph: 0.9766340255737305\n",
      "Neighborhood list prep: 100.9040036201477\n",
      "r.nnz: 37884286\n",
      "Time to prepare r: 44.612709522247314\n",
      "Time to prepare rDense: 0.3106396198272705\n",
      "Time to initialize: 0.4149906635284424\n",
      "Time to prepare M: 21.211472511291504\n",
      "Time to search moves: 0.4563732147216797\n",
      "Time to update M: 21.871071577072144\n",
      "Time to delete empty partitions: 0.0008435249328613281\n",
      "mu 4 , number of clusters 221\n",
      "Time: 195.30622696876526\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "n = 5000\n",
    "fileprefix = \"LFR/\" + \"n\" + str(n) + \"/\"\n",
    "mus = [1, 2, 3, 4]\n",
    "#mus = [4]\n",
    "gammas = [30]\n",
    "betas = [11]\n",
    "for mu in mus:\n",
    "    for gamma in gammas:\n",
    "        for beta in betas:\n",
    "            P_list = []\n",
    "            fname = \"LFR_n\" + str(n) + \"_mu0\" + str(mu) + \"_gamma\" + str(gamma) + \"_beta\" + str(beta)\n",
    "            graph_file = fileprefix + fname + \".mtx\"\n",
    "            print(graph_file)\n",
    "            G = None\n",
    "            with open(graph_file) as f:\n",
    "                G = nx.from_scipy_sparse_array(spio.mmread(f), create_using=nx.Graph)\n",
    "                coms = None\n",
    "                for k in clustering_enumeration:\n",
    "                    clust_file = fileprefix + fname + \".\" + str(k[1])\n",
    "                    if Path(clust_file).is_file():\n",
    "                        partition = read_clust_lst(clust_file)\n",
    "                        P_list.append({\"graph\": nx.Graph(G), \"partition\": list(partition)})\n",
    "                t1 = time.time()\n",
    "                P_star = v4_consensus(P_list, niter=1000, starting_partition = None, verbose=False)\n",
    "                t2 = time.time()\n",
    "                print(\"mu\", mu, \", number of clusters\", len(P_star[\"partition\"]))\n",
    "                print(\"Time:\", t2-t1)\n",
    "                write_clust_lst(P_star[\"partition\"], fileprefix + fname + \".\" + cons_name)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9cfa467",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
