{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "35eae32e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import networkx.algorithms.community as nx_comm\n",
    "from networkx.generators.community import LFR_benchmark_graph\n",
    "from networkx.algorithms import bipartite\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy.sparse import coo_array\n",
    "from scipy import sparse\n",
    "from cdlib import algorithms\n",
    "from cdlib import evaluation\n",
    "import sklearn\n",
    "from utils import *\n",
    "from distances import *\n",
    "from consensus import *\n",
    "import math\n",
    "import itertools\n",
    "import random\n",
    "import time\n",
    "from pathlib import Path\n",
    "from sklearn.metrics.cluster import normalized_mutual_info_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac0ea4b",
   "metadata": {},
   "source": [
    "## Parameter configurations for clustering generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e24da99",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1000\n",
    "expected_clusters = []\n",
    "for i in range(4):\n",
    "    expected_clusters.append(random.randint(int(n ** (1. / 3)),3*int(n ** (1. / 2))))\n",
    "    \n",
    "alg_params = {\n",
    "    \"label_propagation\": None,\n",
    "    \"leiden\": None,\n",
    "    \"significance_communities\": None,\n",
    "    \"surprise_communities\": None,\n",
    "    \"greedy_modularity\": None,\n",
    "    \"paris\": None,\n",
    "    \"louvain\": {\n",
    "        \"resolution\": [0.75, 1.0, 1.25, 1.5],\n",
    "        \"randomize\": [314159, 2718]\n",
    "    },\n",
    "    \"infomap\": None,\n",
    "    \"walktrap\": None,\n",
    "    \"markov_clustering\": {\n",
    "        \"inflation\": [1.2, 1.5, 2, 2.5],\n",
    "        \"pruning_threshold\": [0.01, 0.001],\n",
    "        \"convergence_check_frequency\": [100]\n",
    "    },\n",
    "    \"em\": {\n",
    "        \"k\": list(expected_clusters)\n",
    "    },\n",
    "    \"sbm_dl\": None,\n",
    "    \"spinglass\": {\n",
    "        \"spins\": list(expected_clusters)\n",
    "    },\n",
    "    \"ricci_community\": {\n",
    "        \"alpha\": [0.3, 0.5, 0.6, 0.75]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8558fa",
   "metadata": {},
   "source": [
    "## Enumerate clusterings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b4b22489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('algorithms.label_propagation(G)', 0), ('algorithms.leiden(G)', 1), ('algorithms.significance_communities(G)', 2), ('algorithms.surprise_communities(G)', 3), ('algorithms.greedy_modularity(G)', 4), ('algorithms.paris(G)', 5), ('algorithms.louvain(G,resolution=0.75,randomize=314159)', 6), ('algorithms.louvain(G,resolution=0.75,randomize=2718)', 7), ('algorithms.louvain(G,resolution=1.0,randomize=314159)', 8), ('algorithms.louvain(G,resolution=1.0,randomize=2718)', 9), ('algorithms.louvain(G,resolution=1.25,randomize=314159)', 10), ('algorithms.louvain(G,resolution=1.25,randomize=2718)', 11), ('algorithms.louvain(G,resolution=1.5,randomize=314159)', 12), ('algorithms.louvain(G,resolution=1.5,randomize=2718)', 13), ('algorithms.infomap(G)', 14), ('algorithms.walktrap(G)', 15), ('algorithms.markov_clustering(G,inflation=1.2,pruning_threshold=0.01,convergence_check_frequency=100)', 16), ('algorithms.markov_clustering(G,inflation=1.2,pruning_threshold=0.001,convergence_check_frequency=100)', 17), ('algorithms.markov_clustering(G,inflation=1.5,pruning_threshold=0.01,convergence_check_frequency=100)', 18), ('algorithms.markov_clustering(G,inflation=1.5,pruning_threshold=0.001,convergence_check_frequency=100)', 19), ('algorithms.markov_clustering(G,inflation=2,pruning_threshold=0.01,convergence_check_frequency=100)', 20), ('algorithms.markov_clustering(G,inflation=2,pruning_threshold=0.001,convergence_check_frequency=100)', 21), ('algorithms.markov_clustering(G,inflation=2.5,pruning_threshold=0.01,convergence_check_frequency=100)', 22), ('algorithms.markov_clustering(G,inflation=2.5,pruning_threshold=0.001,convergence_check_frequency=100)', 23), ('algorithms.em(G,k=86)', 24), ('algorithms.em(G,k=9)', 25), ('algorithms.em(G,k=71)', 26), ('algorithms.em(G,k=93)', 27), ('algorithms.sbm_dl(G)', 28), ('algorithms.spinglass(G,spins=86)', 29), ('algorithms.spinglass(G,spins=9)', 30), ('algorithms.spinglass(G,spins=71)', 31), ('algorithms.spinglass(G,spins=93)', 32), ('algorithms.ricci_community(G,alpha=0.3)', 33), ('algorithms.ricci_community(G,alpha=0.5)', 34), ('algorithms.ricci_community(G,alpha=0.6)', 35), ('algorithms.ricci_community(G,alpha=0.75)', 36)]\n"
     ]
    }
   ],
   "source": [
    "clustering_enumeration = []\n",
    "count = 0\n",
    "for alg, params in alg_params.items():\n",
    "    param_combinations = []\n",
    "    param_names = []\n",
    "    if params is not None:\n",
    "        iterables = []\n",
    "        param_names = []\n",
    "        for param in params.keys():\n",
    "            iterables.append(list(params[param]))\n",
    "            param_names.append(param)\n",
    "        param_combinations = list(itertools.product(*iterables))\n",
    "    if len(param_combinations) > 0:\n",
    "        for param_combination in param_combinations:\n",
    "            expr = \"algorithms.\"+alg+\"(G\"\n",
    "            for i in range(len(param_names)):\n",
    "                expr = expr + \",\" + param_names[i] + \"=\" + str(param_combination[i])\n",
    "            expr = expr + \")\"\n",
    "            clustering_enumeration.append((expr,count))\n",
    "            count = count + 1      \n",
    "    else:\n",
    "        expr = \"algorithms.\"+alg+\"(G)\"\n",
    "        clustering_enumeration.append((expr,count))\n",
    "        count = count + 1\n",
    "print(clustering_enumeration)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77c8dfb",
   "metadata": {},
   "source": [
    "### Distance distribution for all benchmark graphs, all conensus methods and all distance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "00489027",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LFR/n200/LFR_n200_mu01_gamma30_beta11.mtx\n",
      "LFR/n200/LFR_n200_mu02_gamma30_beta11.mtx\n",
      "LFR/n200/LFR_n200_mu03_gamma30_beta11.mtx\n",
      "LFR/n200/LFR_n200_mu04_gamma30_beta11.mtx\n",
      "LFR/n1000/LFR_n1000_mu01_gamma30_beta11.mtx\n",
      "LFR/n1000/LFR_n1000_mu02_gamma30_beta11.mtx\n",
      "LFR/n1000/LFR_n1000_mu03_gamma30_beta11.mtx\n",
      "LFR/n1000/LFR_n1000_mu04_gamma30_beta11.mtx\n",
      "LFR/n5000/LFR_n5000_mu01_gamma30_beta11.mtx\n",
      "LFR/n5000/LFR_n5000_mu02_gamma30_beta11.mtx\n",
      "LFR/n5000/LFR_n5000_mu03_gamma30_beta11.mtx\n",
      "LFR/n5000/LFR_n5000_mu04_gamma30_beta11.mtx\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "stats = []\n",
    "\n",
    "distance_metrics = [\"split_joint_distance\", \"mirkin_distance\", \"variation_of_info_distance\"]\n",
    "consensus_methods = [\"lf\", \"mcla\", \"hbgf\", \"nmf\", \"v1\", \"boem\", \"v2\", \"v3\", \"v4\", \"v5\"]\n",
    "#consensus_methods = [\"v4\"]\n",
    "ns = [200, 1000, 5000]\n",
    "mus = [1, 2, 3, 4]\n",
    "#mus = [2]\n",
    "gammas = [30]\n",
    "betas = [11]\n",
    "for n in ns:\n",
    "    for mu in mus:\n",
    "        for gamma in gammas:\n",
    "            for beta in betas:\n",
    "                P_list = []\n",
    "                fileprefix = \"LFR/\" + \"n\" + str(n) + \"/\"\n",
    "                fname = \"LFR_n\" + str(n) + \"_mu0\" + str(mu) + \"_gamma\" + str(gamma) + \"_beta\" + str(beta)\n",
    "                graph_file = fileprefix + fname + \".mtx\"\n",
    "                print(graph_file)\n",
    "                G = None\n",
    "                with open(graph_file) as f:\n",
    "                    G = nx.from_scipy_sparse_array(spio.mmread(f), create_using=nx.Graph)\n",
    "\n",
    "                    for k in clustering_enumeration:\n",
    "                        alg_clust_file = fileprefix + fname + \".\" + str(k[1])\n",
    "                        alg_partition = None\n",
    "                        if Path(alg_clust_file).is_file():\n",
    "                            alg_partition = read_clust_lst(alg_clust_file)\n",
    "\n",
    "                            for cons_method in consensus_methods:\n",
    "                                for distance_metric in distance_metrics:\n",
    "                                    cons_partition = None\n",
    "                                    optimized_distance = None\n",
    "                                    cons_clust_file = fileprefix + fname + \".\" + cons_method\n",
    "                                    common_stat = {}\n",
    "                                    common_stat[\"mu\"] = mu\n",
    "                                    common_stat[\"n\"] = n\n",
    "                                    common_stat[\"gamma\"] = gamma\n",
    "                                    common_stat[\"beta\"] = beta\n",
    "                                    common_stat[\"alg\"] = k[1]\n",
    "                                    common_stat[\"cons_method\"] = cons_method\n",
    "                                    common_stat[\"distance_metric\"] = distance_metric\n",
    "\n",
    "                                    if cons_method in [\"best_candidate\"]:\n",
    "                                        \"\"\"\n",
    "                                        for optimized_distance in distance_metrics:\n",
    "                                            cons_partition = read_clust_lst(clust_file_prefix + \".\" + optimized_distance)\n",
    "                                            #print(clust_file_prefix + \".\" + optimized_distance)\n",
    "                                            stat = dict(common_stat)\n",
    "                                            stat[\"optimized_distance\"] = optimized_distance\n",
    "                                            distance = eval(distance_metric)(alg_partition, cons_partition)\n",
    "                                            stat[\"distance\"] = distance\n",
    "\n",
    "                                            stats.append(stat)\n",
    "                                        \"\"\"\n",
    "                                        pass\n",
    "                                    else:\n",
    "                                         if Path(cons_clust_file).is_file():\n",
    "                                            # No need to append any extension\n",
    "                                            cons_partition = read_clust_lst(cons_clust_file)\n",
    "                                            stat = dict(common_stat)\n",
    "                                            stat[\"optimized_distance\"] = \"none\"\n",
    "                                            distance = eval(distance_metric)(alg_partition, cons_partition)\n",
    "                                            stat[\"distance\"] = distance\n",
    "\n",
    "                                            stats.append(stat)\n",
    "\n",
    "                \n",
    "df = pd.DataFrame(stats)\n",
    "filename = \"benchmark-consensus-distance-stats.csv\"\n",
    "df.to_csv(filename, index=False, mode='w', header=True)\n",
    "#df.to_csv(filename, index=False, mode='a', header=not os.path.exists(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "66707c3b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import networkx.algorithms.community as nx_comm\n",
    "from networkx.generators.community import LFR_benchmark_graph\n",
    "from networkx.algorithms import bipartite\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy import sparse\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from matplotlib import rc\n",
    "import matplotlib.colors as mcolors\n",
    "matplotlib.rcParams.update(matplotlib.rcParamsDefault)\n",
    "plt.rcParams.update({\n",
    "    \"text.usetex\": True,\n",
    "    #\"font.family\": \"Helvetica\"\n",
    "    \"font.family\": \"Arial\"\n",
    "})\n",
    "\n",
    "def plot_distance_distribution(data, ax, colors, distribution_labels, ylabel, title):\n",
    "    # https://stackoverflow.com/questions/26291479/changing-the-color-of-matplotlibs-violin-plots\n",
    "    violin_parts = ax.violinplot(data, showmeans=True, showmedians=True, points=20)\n",
    "\n",
    "    for k in range(len(data)):\n",
    "        violin_parts[\"bodies\"][k].set_facecolor(colors[k])\n",
    "        violin_parts[\"bodies\"][k].set_edgecolor(\"black\")\n",
    "    violin_parts[\"cmeans\"].set_color(\"magenta\")\n",
    "    violin_parts[\"cmedians\"].set_color(\"aqua\")\n",
    "    violin_parts[\"cbars\"].set_color(\"gray\")\n",
    "    violin_parts[\"cmaxes\"].set_color(\"lightgray\")\n",
    "    violin_parts[\"cmins\"].set_color(\"lightgray\")\n",
    "\n",
    "    ax.xaxis.set_ticks(range(1, len(data)+1))\n",
    "    if (distribution_labels is not None) and (len(distribution_labels) == len(data)):\n",
    "        ax.xaxis.set_ticklabels(distribution_labels)\n",
    "    else:\n",
    "        ax.xaxis.set_ticklabels([])\n",
    "    \n",
    "    if ylabel is not None:\n",
    "        ax.set_ylabel(ylabel)\n",
    "    \n",
    "    if title is not None:\n",
    "        ax.set_title(title)\n",
    "\n",
    "distance_metrics = [\"split_joint_distance\", \"mirkin_distance\", \"variation_of_info_distance\"]\n",
    "consensus_methods = [\"mcla\", \"hbgf\", \"nmf\", \"boem\", \"v3\", \"v4\", \"v5\"]\n",
    "consensus_methods_colors = [\"tab:blue\", \"tab:orange\", \"tab:green\", \"tab:red\", \"tab:purple\", \"tab:brown\", \"tab:pink\"]\n",
    "mus = [1, 2, 3, 4]\n",
    "ns = [200, 1000, 5000]\n",
    "for n in ns:\n",
    "    df = pd.read_csv(\"benchmark-consensus-distance-stats.csv\")\n",
    "    df = df[df[\"n\"] == 200]\n",
    "    for distance_metric in distance_metrics:\n",
    "        naxr = 2 \n",
    "        naxc = 2\n",
    "\n",
    "        fig = plt.figure(figsize=(6, 6))\n",
    "        gs = GridSpec(nrows=naxr, ncols=naxc)\n",
    "\n",
    "        axes = []\n",
    "        for i in range(naxr):\n",
    "            axr = []\n",
    "            for j in range(naxc):\n",
    "                axr.append(fig.add_subplot(gs[i,j]))\n",
    "            axes.append(axr)\n",
    "        \n",
    "        for i in range(naxr):\n",
    "            for j in range(naxc):\n",
    "                idx = (i * naxr + j)\n",
    "                mu = mus[idx]\n",
    "                data = []\n",
    "                \n",
    "                for k in range(len(consensus_methods)):\n",
    "                    cons_method = consensus_methods[k]\n",
    "                    mask = None\n",
    "                    if cons_method == \"best_candidate\":\n",
    "                        mask = (df[\"mu\"] == mu) & (df[\"distance_metric\"] == distance_metric) & (df[\"cons_method\"] == cons_method) & (df[\"optimized_distance\"] == distance_metric)\n",
    "                    else:\n",
    "                        mask = (df[\"mu\"] == mu) & (df[\"distance_metric\"] == distance_metric) & (df[\"cons_method\"] == cons_method) & (df[\"optimized_distance\"] == \"none\")\n",
    "                    df_target = df[mask]\n",
    "                    data.append(df_target[\"distance\"])\n",
    "                \n",
    "                plot_distance_distribution(data, axes[i][j], consensus_methods_colors, consensus_methods, distance_metric, \"$\\mu:\" + str(mu*1.0/10.0)+\"$\")\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\"benchmark-distance-distribution-\"+ \"n\"+str(n)+ \"-\" + distance_metric +\".pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b42190",
   "metadata": {},
   "source": [
    "### Quality of all clusterings of all benchmark graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d9b72ad4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LFR/n200/LFR_n200_mu01_gamma30_beta11.mtx\n",
      "LFR/n200/LFR_n200_mu02_gamma30_beta11.mtx\n",
      "LFR/n200/LFR_n200_mu03_gamma30_beta11.mtx\n",
      "LFR/n200/LFR_n200_mu04_gamma30_beta11.mtx\n",
      "LFR/n1000/LFR_n1000_mu01_gamma30_beta11.mtx\n",
      "LFR/n1000/LFR_n1000_mu02_gamma30_beta11.mtx\n",
      "LFR/n1000/LFR_n1000_mu03_gamma30_beta11.mtx\n",
      "LFR/n1000/LFR_n1000_mu04_gamma30_beta11.mtx\n",
      "LFR/n5000/LFR_n5000_mu01_gamma30_beta11.mtx\n",
      "LFR/n5000/LFR_n5000_mu02_gamma30_beta11.mtx\n",
      "LFR/n5000/LFR_n5000_mu03_gamma30_beta11.mtx\n",
      "LFR/n5000/LFR_n5000_mu04_gamma30_beta11.mtx\n"
     ]
    }
   ],
   "source": [
    "stats = []\n",
    "\n",
    "distance_metrics = [\"split_joint_distance\", \"mirkin_distance\", \"variation_of_info_distance\"]\n",
    "consensus_methods = [\"mcla\", \"hbgf\", \"nmf\", \"v1\", \"boem\", \"v2\", \"v3\", \"v4\", \"v5\"]\n",
    "#consensus_methods = [\"v4\"]\n",
    "ns = [200, 1000, 5000]\n",
    "mus = [1, 2, 3, 4]\n",
    "#mus = [2]\n",
    "gammas = [30]\n",
    "betas = [11]\n",
    "for n in ns:\n",
    "    for mu in mus:\n",
    "        for gamma in gammas:\n",
    "            for beta in betas:\n",
    "                P_list = []\n",
    "                fileprefix = \"LFR/\" + \"n\" + str(n) + \"/\"\n",
    "                fname = \"LFR_n\" + str(n) + \"_mu0\" + str(mu) + \"_gamma\" + str(gamma) + \"_beta\" + str(beta)\n",
    "                graph_file = fileprefix + fname + \".mtx\"\n",
    "                print(graph_file)\n",
    "                G = None\n",
    "                with open(graph_file) as f:\n",
    "                    G = nx.from_scipy_sparse_array(spio.mmread(f), create_using=nx.Graph)\n",
    "                    gt_clust_lst = read_clust_lst(fileprefix + fname + \".gt\")\n",
    "                    gt_clust_asn = clust_lst_to_asn(gt_clust_lst)\n",
    "\n",
    "                    common_stat = {}\n",
    "                    common_stat[\"mu\"] = mu\n",
    "                    common_stat[\"n\"] = n\n",
    "                    common_stat[\"gamma\"] = gamma\n",
    "                    common_stat[\"beta\"] = beta\n",
    "\n",
    "                    for cons_method in consensus_methods:\n",
    "                        #print(cons_method)\n",
    "                        clust_file = fileprefix + fname + \".\" + cons_method\n",
    "                        if Path(alg_clust_file).is_file():\n",
    "                            clust_lst = read_clust_lst(clust_file)\n",
    "                            clust_asn = clust_lst_to_asn(clust_lst)\n",
    "                            \n",
    "                            stat = dict(common_stat)\n",
    "                            stat[\"cons_method\"] = cons_method\n",
    "                            stat[\"ncluster\"] = len(clust_lst)\n",
    "\n",
    "                            F, precision, recall = fscore(gt_clust_lst, clust_lst)\n",
    "\n",
    "                            stat[\"fscore\"] = F\n",
    "                            stat[\"precision\"] = precision\n",
    "                            stat[\"recall\"] = recall\n",
    "\n",
    "                            clust_lst_temp = clust_asn_to_lst(clust_asn)\n",
    "                            modularity = nx.community.modularity(G, clust_lst_temp)\n",
    "                            stat[\"modularity\"] = modularity\n",
    "\n",
    "                            stat[\"nmi\"] = normalized_mutual_info_score(gt_clust_asn, clust_asn)\n",
    "\n",
    "                            stats.append(stat)\n",
    "\n",
    "df = pd.DataFrame(stats)\n",
    "filename = \"benchmark-quality-stats.csv\"\n",
    "df.to_csv(filename, index=False, mode='w', header=True)\n",
    "#df.to_csv(filename, index=False, mode='a', header=not os.path.exists(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3499207b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import networkx.algorithms.community as nx_comm\n",
    "from networkx.generators.community import LFR_benchmark_graph\n",
    "from networkx.algorithms import bipartite\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy import sparse\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from matplotlib import rc\n",
    "import matplotlib.colors as mcolors\n",
    "matplotlib.rcParams.update(matplotlib.rcParamsDefault)\n",
    "plt.rcParams.update({\n",
    "    \"text.usetex\": True,\n",
    "    #\"font.family\": \"Helvetica\"\n",
    "    \"font.family\": \"Arial\"\n",
    "})\n",
    "import math\n",
    "\n",
    "quality_metrics = [\"precision\", \"recall\", \"fscore\", \"nmi\"]\n",
    "consensus_methods = [\"mcla\", \"hbgf\", \"nmf\", \"boem\", \"v3\", \"v4\", \"v5\"]\n",
    "consensus_methods_colors = [\"tab:blue\", \"tab:orange\", \"tab:green\", \"tab:red\", \"tab:purple\", \"tab:brown\", \"tab:pink\"]\n",
    "mus = [1, 2, 3, 4]\n",
    "ns = [200, 1000, 5000]\n",
    "for n in ns:\n",
    "    df = pd.read_csv(\"benchmark-quality-stats.csv\")\n",
    "    df = df[df[\"n\"] == n]\n",
    "    \n",
    "    fig = plt.figure(figsize=(9, 6))\n",
    "    naxr = 2 \n",
    "    naxc = 2\n",
    "    gs = GridSpec(nrows=naxr, ncols=naxc)\n",
    "    axes = []\n",
    "    for i in range(naxr):\n",
    "        axr = []\n",
    "        for j in range(naxc):\n",
    "            axr.append(fig.add_subplot(gs[i,j]))\n",
    "        axes.append(axr)\n",
    "        \n",
    "    group_items = list(consensus_methods)\n",
    "    group_width = 0.7\n",
    "    bar_width = group_width/len(group_items)\n",
    "    middle_bar = math.floor(len(group_items) / 2.0)\n",
    "    even = len(group_items) % 2 == 0\n",
    "    for i in range(naxr):\n",
    "        for j in range(naxc):\n",
    "            idx = (i * naxr + j)\n",
    "            quality_metric = quality_metrics[idx]\n",
    "            for k in range(len(consensus_methods)):\n",
    "                df_target = df[df[\"cons_method\"] == consensus_methods[k]]\n",
    "                offset = None\n",
    "                if(even):\n",
    "                    offset = bar_width / 2.0 + (k - middle_bar) * bar_width\n",
    "                else:\n",
    "                    offset = (k - middle_bar) * bar_width\n",
    "                axes[i][j].bar(df_target[\"mu\"] + offset, df_target[quality_metric], color=consensus_methods_colors[k], width=bar_width, alpha=0.5, edgecolor='black', linewidth=bar_width/10.0, label=consensus_methods[k])\n",
    "            axes[i][j].set_xlabel(\"$\\mu$\")\n",
    "            axes[i][j].set_ylabel(quality_metric)\n",
    "            axes[i][j].set_xticks(np.array(mus))\n",
    "            axes[i][j].set_xticklabels(np.array(mus) / 10.0)\n",
    "            axes[i][j].grid(axis='y')\n",
    "            #axes[i][j].legend()\n",
    "                \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"benchmark-quality-\"+ \"n\"+str(n)+\".pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bcecec4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import networkx.algorithms.community as nx_comm\n",
    "from networkx.generators.community import LFR_benchmark_graph\n",
    "from networkx.algorithms import bipartite\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy import sparse\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "from matplotlib import rc\n",
    "import matplotlib.colors as mcolors\n",
    "matplotlib.rcParams.update(matplotlib.rcParamsDefault)\n",
    "plt.rcParams.update({\n",
    "    \"text.usetex\": True,\n",
    "    #\"font.family\": \"Helvetica\"\n",
    "    \"font.family\": \"Arial\"\n",
    "})\n",
    "import math\n",
    "\n",
    "rt_data = [\n",
    "    { \"n\": 200, \"mu\": 0.1, \"cons_method\": \"mcla\", \"rt\": 149.44089198112488},\n",
    "    { \"n\": 200, \"mu\": 0.2, \"cons_method\": \"mcla\", \"rt\": 162.56297039985657},\n",
    "    { \"n\": 200, \"mu\": 0.3, \"cons_method\": \"mcla\", \"rt\": 206.48962783813477},\n",
    "    { \"n\": 200, \"mu\": 0.4, \"cons_method\": \"mcla\", \"rt\": 292.8949866294861},\n",
    "    { \"n\": 1000, \"mu\": 0.1, \"cons_method\": \"mcla\", \"rt\": 1342.4395899772644},\n",
    "    { \"n\": 1000, \"mu\": 0.2, \"cons_method\": \"mcla\", \"rt\": 1562.3081963062286},\n",
    "    { \"n\": 1000, \"mu\": 0.3, \"cons_method\": \"mcla\", \"rt\": 3899.515527486801},\n",
    "    { \"n\": 1000, \"mu\": 0.4, \"cons_method\": \"mcla\", \"rt\": 7178.795511007309},\n",
    "    { \"n\": 5000, \"mu\": 0.1, \"cons_method\": \"mcla\", \"rt\": 25727.96590065956},\n",
    "    { \"n\": 5000, \"mu\": 0.2, \"cons_method\": \"mcla\", \"rt\": 29203.03486943245},\n",
    "    { \"n\": 5000, \"mu\": 0.3, \"cons_method\": \"mcla\", \"rt\": 78482.53806829453},\n",
    "    { \"n\": 5000, \"mu\": 0.4, \"cons_method\": \"mcla\", \"rt\": 165258.80073308945},\n",
    "    { \"n\": 200, \"mu\": 0.1, \"cons_method\": \"hbgf\", \"rt\": 0.40747547149658203},\n",
    "    { \"n\": 200, \"mu\": 0.2, \"cons_method\": \"hbgf\", \"rt\": 0.41968536376953125},\n",
    "    { \"n\": 200, \"mu\": 0.3, \"cons_method\": \"hbgf\", \"rt\": 0.4672977924346924},\n",
    "    { \"n\": 200, \"mu\": 0.4, \"cons_method\": \"hbgf\", \"rt\": 0.5079178810119629},\n",
    "    { \"n\": 1000, \"mu\": 0.1, \"cons_method\": \"hbgf\", \"rt\": 0.8461880683898926},\n",
    "    { \"n\": 1000, \"mu\": 0.2, \"cons_method\": \"hbgf\", \"rt\": 0.8739335536956787},\n",
    "    { \"n\": 1000, \"mu\": 0.3, \"cons_method\": \"hbgf\", \"rt\": 1.1762597560882568},\n",
    "    { \"n\": 1000, \"mu\": 0.4, \"cons_method\": \"hbgf\", \"rt\": 1.426685094833374},\n",
    "    { \"n\": 5000, \"mu\": 0.1, \"cons_method\": \"hbgf\", \"rt\": 4.917860984802246},\n",
    "    { \"n\": 5000, \"mu\": 0.2, \"cons_method\": \"hbgf\", \"rt\": 4.905524730682373},\n",
    "    { \"n\": 5000, \"mu\": 0.3, \"cons_method\": \"hbgf\", \"rt\": 6.563857078552246},\n",
    "    { \"n\": 5000, \"mu\": 0.4, \"cons_method\": \"hbgf\", \"rt\": 8.91361403465271},\n",
    "    { \"n\": 200, \"mu\": 0.1, \"cons_method\": \"nmf\", \"rt\": 5.5484983921051025},\n",
    "    { \"n\": 200, \"mu\": 0.2, \"cons_method\": \"nmf\", \"rt\": 4.889721632003784},\n",
    "    { \"n\": 200, \"mu\": 0.3, \"cons_method\": \"nmf\", \"rt\": 4.957129716873169},\n",
    "    { \"n\": 200, \"mu\": 0.4, \"cons_method\": \"nmf\", \"rt\": 5.1594343185424805},\n",
    "    { \"n\": 1000, \"mu\": 0.1, \"cons_method\": \"nmf\", \"rt\": 171.75516819953918},\n",
    "    { \"n\": 1000, \"mu\": 0.2, \"cons_method\": \"nmf\", \"rt\": 264.1879839897156},\n",
    "    { \"n\": 1000, \"mu\": 0.3, \"cons_method\": \"nmf\", \"rt\": 341.15653467178345},\n",
    "    { \"n\": 1000, \"mu\": 0.4, \"cons_method\": \"nmf\", \"rt\": 335.9212169647217},\n",
    "    { \"n\": 5000, \"mu\": 0.1, \"cons_method\": \"nmf\", \"rt\": 15585.253784656525},\n",
    "    { \"n\": 5000, \"mu\": 0.2, \"cons_method\": \"nmf\", \"rt\": 18174.84340786934},\n",
    "    { \"n\": 5000, \"mu\": 0.3, \"cons_method\": \"nmf\", \"rt\": 25836.429513454437},\n",
    "    { \"n\": 5000, \"mu\": 0.4, \"cons_method\": \"nmf\", \"rt\": 38797.094098091125},\n",
    "    { \"n\": 200, \"mu\": 0.1, \"cons_method\": \"boem\", \"rt\": 0.4165503978729248},\n",
    "    { \"n\": 200, \"mu\": 0.2, \"cons_method\": \"boem\", \"rt\": 0.42778563499450684},\n",
    "    { \"n\": 200, \"mu\": 0.3, \"cons_method\": \"boem\", \"rt\": 0.5192949771881104},\n",
    "    { \"n\": 200, \"mu\": 0.4, \"cons_method\": \"boem\", \"rt\": 0.6321694850921631},\n",
    "    { \"n\": 1000, \"mu\": 0.1, \"cons_method\": \"boem\", \"rt\": 6.6967573165893555},\n",
    "    { \"n\": 1000, \"mu\": 0.2, \"cons_method\": \"boem\", \"rt\": 8.391771078109741},\n",
    "    { \"n\": 1000, \"mu\": 0.3, \"cons_method\": \"boem\", \"rt\": 10.886692523956299},\n",
    "    { \"n\": 1000, \"mu\": 0.4, \"cons_method\": \"boem\", \"rt\": 12.241299867630005},\n",
    "    { \"n\": 5000, \"mu\": 0.1, \"cons_method\": \"boem\", \"rt\": 257.0957062244415},\n",
    "    { \"n\": 5000, \"mu\": 0.2, \"cons_method\": \"boem\", \"rt\": 247.48991179466248},\n",
    "    { \"n\": 5000, \"mu\": 0.3, \"cons_method\": \"boem\", \"rt\": 269.07662653923035},\n",
    "    { \"n\": 5000, \"mu\": 0.4, \"cons_method\": \"boem\", \"rt\": 305.25197196006775},\n",
    "    { \"n\": 200, \"mu\": 0.1, \"cons_method\": \"v3\", \"rt\": 0.20238280296325684},\n",
    "    { \"n\": 200, \"mu\": 0.2, \"cons_method\": \"v3\", \"rt\": 0.21066570281982422},\n",
    "    { \"n\": 200, \"mu\": 0.3, \"cons_method\": \"v3\", \"rt\": 0.27460193634033203},\n",
    "    { \"n\": 200, \"mu\": 0.4, \"cons_method\": \"v3\", \"rt\": 0.4301011562347412},\n",
    "    { \"n\": 1000, \"mu\": 0.1, \"cons_method\": \"v3\", \"rt\": 2.2396063804626465},\n",
    "    { \"n\": 1000, \"mu\": 0.2, \"cons_method\": \"v3\", \"rt\": 2.9395501613616943},\n",
    "    { \"n\": 1000, \"mu\": 0.3, \"cons_method\": \"v3\", \"rt\": 3.9071197509765625},\n",
    "    { \"n\": 1000, \"mu\": 0.4, \"cons_method\": \"v3\", \"rt\": 5.536072492599487},\n",
    "    { \"n\": 5000, \"mu\": 0.1, \"cons_method\": \"v3\", \"rt\": 41.573002576828},\n",
    "    { \"n\": 5000, \"mu\": 0.2, \"cons_method\": \"v3\", \"rt\": 41.824567794799805},\n",
    "    { \"n\": 5000, \"mu\": 0.3, \"cons_method\": \"v3\", \"rt\": 49.67441773414612},\n",
    "    { \"n\": 5000, \"mu\": 0.4, \"cons_method\": \"v3\", \"rt\": 53.16094374656677},\n",
    "    { \"n\": 200, \"mu\": 0.1, \"cons_method\": \"v4\", \"rt\": 1.3950552940368652},\n",
    "    { \"n\": 200, \"mu\": 0.2, \"cons_method\": \"v4\", \"rt\": 1.3167805671691895},\n",
    "    { \"n\": 200, \"mu\": 0.3, \"cons_method\": \"v4\", \"rt\": 2.109605073928833},\n",
    "    { \"n\": 200, \"mu\": 0.4, \"cons_method\": \"v4\", \"rt\": 1.858361005783081},\n",
    "    { \"n\": 1000, \"mu\": 0.1, \"cons_method\": \"v4\", \"rt\": 21.3703191280365},\n",
    "    { \"n\": 1000, \"mu\": 0.2, \"cons_method\": \"v4\", \"rt\": 22.90269923210144},\n",
    "    { \"n\": 1000, \"mu\": 0.3, \"cons_method\": \"v4\", \"rt\": 23.381633520126343},\n",
    "    { \"n\": 1000, \"mu\": 0.4, \"cons_method\": \"v4\", \"rt\": 36.66318416595459},\n",
    "    { \"n\": 5000, \"mu\": 0.1, \"cons_method\": \"v4\", \"rt\": 109.35808682441711},\n",
    "    { \"n\": 5000, \"mu\": 0.2, \"cons_method\": \"v4\", \"rt\": 168.69196343421936},\n",
    "    { \"n\": 5000, \"mu\": 0.3, \"cons_method\": \"v4\", \"rt\": 114.65513181686401},\n",
    "    { \"n\": 5000, \"mu\": 0.4, \"cons_method\": \"v4\", \"rt\": 172.6126413345337},\n",
    "    { \"n\": 200, \"mu\": 0.1, \"cons_method\": \"v5\", \"rt\": 1.5365149974822998},\n",
    "    { \"n\": 200, \"mu\": 0.2, \"cons_method\": \"v5\", \"rt\": 2.2426939010620117},\n",
    "    { \"n\": 200, \"mu\": 0.3, \"cons_method\": \"v5\", \"rt\": 1.678490161895752},\n",
    "    { \"n\": 200, \"mu\": 0.4, \"cons_method\": \"v5\", \"rt\": 2.2428464889526367},\n",
    "    { \"n\": 1000, \"mu\": 0.1, \"cons_method\": \"v5\", \"rt\": 24.272643566131592},\n",
    "    { \"n\": 1000, \"mu\": 0.2, \"cons_method\": \"v5\", \"rt\": 29.0472674369812},\n",
    "    { \"n\": 1000, \"mu\": 0.3, \"cons_method\": \"v5\", \"rt\": 34.028849363327026},\n",
    "    { \"n\": 1000, \"mu\": 0.4, \"cons_method\": \"v5\", \"rt\": 28.32345175743103},\n",
    "    { \"n\": 5000, \"mu\": 0.1, \"cons_method\": \"v5\", \"rt\": 149.31756925582886},\n",
    "    { \"n\": 5000, \"mu\": 0.2, \"cons_method\": \"v5\", \"rt\": 143.45976519584656},\n",
    "    { \"n\": 5000, \"mu\": 0.3, \"cons_method\": \"v5\", \"rt\": 172.6393985748291},\n",
    "    { \"n\": 5000, \"mu\": 0.4, \"cons_method\": \"v5\", \"rt\": 195.28433871269226},\n",
    "]\n",
    "df = pd.DataFrame(rt_data)\n",
    "\n",
    "quality_metrics = [\"precision\", \"recall\", \"fscore\", \"nmi\"]\n",
    "consensus_methods = [\"mcla\", \"hbgf\", \"nmf\", \"boem\", \"v3\", \"v4\", \"v5\"]\n",
    "consensus_methods_colors = [\"tab:blue\", \"tab:orange\", \"tab:green\", \"tab:red\", \"tab:purple\", \"tab:brown\", \"tab:pink\"]\n",
    "mus = [0.1, 0.2, 0.3, 0.4]\n",
    "ns = [200, 1000, 5000]\n",
    "\n",
    "fig = plt.figure(figsize=(9, 6))\n",
    "naxr = 2 \n",
    "naxc = 2\n",
    "gs = GridSpec(nrows=naxr, ncols=naxc)\n",
    "axes = []\n",
    "for i in range(naxr):\n",
    "    axr = []\n",
    "    for j in range(naxc):\n",
    "        axr.append(fig.add_subplot(gs[i,j]))\n",
    "    axes.append(axr)\n",
    "\n",
    "for i in range(naxr):\n",
    "    axr = []\n",
    "    for j in range(naxc):\n",
    "        idx = (i * naxr + j)\n",
    "        mu = mus[idx]\n",
    "        for k in range(len(consensus_methods)):\n",
    "            df_target = df[(df[\"mu\"] == mu) & (df[\"cons_method\"] == consensus_methods[k])]\n",
    "            axes[i][j].plot(df_target[\"n\"], df_target[\"rt\"], color=consensus_methods_colors[k], marker='x', label=consensus_methods[k])\n",
    "            pass\n",
    "        axes[i][j].set_title(\"$\\mu:\" + str(mu)+\"$\")\n",
    "        axes[i][j].set_xscale('log', base=2)\n",
    "        axes[i][j].set_yscale('log', base=2)\n",
    "        axes[i][j].grid(True, axis='both', which='both', alpha=0.5)\n",
    "        axes[i][j].set_xticks(ns)\n",
    "        axes[i][j].set_xticklabels(ns)\n",
    "        axes[i][j].set_xlabel(\"n\")\n",
    "        axes[i][j].set_ylabel(\"runtime (sec)\")\n",
    "        axes[i][j].yaxis.set_major_formatter(FormatStrFormatter('%.0f'))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"benchmark-runtime.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc2c5d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
