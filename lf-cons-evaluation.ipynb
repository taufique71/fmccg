{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "08df444c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import networkx.algorithms.community as nx_comm\n",
    "from networkx.generators.community import LFR_benchmark_graph\n",
    "from networkx.algorithms import bipartite\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy.sparse import coo_array\n",
    "from scipy import sparse\n",
    "from cdlib import algorithms\n",
    "from cdlib import evaluation\n",
    "import sklearn\n",
    "from utils import *\n",
    "from distances import *\n",
    "from consensus import *\n",
    "import math\n",
    "import itertools\n",
    "import random\n",
    "import time\n",
    "from pathlib import Path\n",
    "from sklearn.metrics.cluster import normalized_mutual_info_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ffaa993",
   "metadata": {},
   "outputs": [],
   "source": [
    "cons_name = \"lf\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac0ea4b",
   "metadata": {},
   "source": [
    "## Parameter configurations for clustering generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e24da99",
   "metadata": {},
   "outputs": [],
   "source": [
    "alg_params = {\n",
    "    \"louvain\": {\n",
    "        \"resolution\": [0.5, 0.75, 1.0, 1.25, 1.5],\n",
    "        \"randomize\": [314159, 2718, 1234, 4321, 987654321]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8558fa",
   "metadata": {},
   "source": [
    "## Enumerate clusterings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4b22489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('algorithms.louvain(G,resolution=0.5,randomize=314159)', 0), ('algorithms.louvain(G,resolution=0.5,randomize=2718)', 1), ('algorithms.louvain(G,resolution=0.5,randomize=1234)', 2), ('algorithms.louvain(G,resolution=0.5,randomize=4321)', 3), ('algorithms.louvain(G,resolution=0.5,randomize=987654321)', 4), ('algorithms.louvain(G,resolution=0.75,randomize=314159)', 5), ('algorithms.louvain(G,resolution=0.75,randomize=2718)', 6), ('algorithms.louvain(G,resolution=0.75,randomize=1234)', 7), ('algorithms.louvain(G,resolution=0.75,randomize=4321)', 8), ('algorithms.louvain(G,resolution=0.75,randomize=987654321)', 9), ('algorithms.louvain(G,resolution=1.0,randomize=314159)', 10), ('algorithms.louvain(G,resolution=1.0,randomize=2718)', 11), ('algorithms.louvain(G,resolution=1.0,randomize=1234)', 12), ('algorithms.louvain(G,resolution=1.0,randomize=4321)', 13), ('algorithms.louvain(G,resolution=1.0,randomize=987654321)', 14), ('algorithms.louvain(G,resolution=1.25,randomize=314159)', 15), ('algorithms.louvain(G,resolution=1.25,randomize=2718)', 16), ('algorithms.louvain(G,resolution=1.25,randomize=1234)', 17), ('algorithms.louvain(G,resolution=1.25,randomize=4321)', 18), ('algorithms.louvain(G,resolution=1.25,randomize=987654321)', 19), ('algorithms.louvain(G,resolution=1.5,randomize=314159)', 20), ('algorithms.louvain(G,resolution=1.5,randomize=2718)', 21), ('algorithms.louvain(G,resolution=1.5,randomize=1234)', 22), ('algorithms.louvain(G,resolution=1.5,randomize=4321)', 23), ('algorithms.louvain(G,resolution=1.5,randomize=987654321)', 24)]\n"
     ]
    }
   ],
   "source": [
    "clustering_enumeration = []\n",
    "count = 0\n",
    "for alg, params in alg_params.items():\n",
    "    param_combinations = []\n",
    "    param_names = []\n",
    "    if params is not None:\n",
    "        iterables = []\n",
    "        param_names = []\n",
    "        for param in params.keys():\n",
    "            iterables.append(list(params[param]))\n",
    "            param_names.append(param)\n",
    "        param_combinations = list(itertools.product(*iterables))\n",
    "    if len(param_combinations) > 0:\n",
    "        for param_combination in param_combinations:\n",
    "            expr = \"algorithms.\"+alg+\"(G\"\n",
    "            for i in range(len(param_names)):\n",
    "                expr = expr + \",\" + param_names[i] + \"=\" + str(param_combination[i])\n",
    "            expr = expr + \")\"\n",
    "            clustering_enumeration.append((expr,count))\n",
    "            count = count + 1      \n",
    "    else:\n",
    "        expr = \"algorithms.\"+alg+\"(G)\"\n",
    "        clustering_enumeration.append((expr,count))\n",
    "        count = count + 1\n",
    "print(clustering_enumeration)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8c4557",
   "metadata": {},
   "source": [
    "# v5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "34ee4858",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import coo_array\n",
    "from scipy.sparse import csr_array\n",
    "\n",
    "# DeltaSOD is calculated following the paper titled \"Integrating Microarray Data by Consensus Clustering\"\n",
    "# by Filkov and Skiena\n",
    "# Assumes the elements of the cluster are named as 0-based indices\n",
    "def v5_consensus(P_list, niter=10, starting_partition=None, verbose=False):\n",
    "    G = nx.Graph(P_list[0][\"graph\"])\n",
    "    n = len(list(G.nodes()))\n",
    "    k = len(P_list)\n",
    "    print(\"Number of edges in G:\", len(list(G.edges())))\n",
    "\n",
    "    t1 = time.time()\n",
    "    A = nx.to_scipy_sparse_array(G, format=\"coo\")\n",
    "    t2 = time.time()\n",
    "    print(\"Time to get sparse matrix of the graph:\", t2-t1)\n",
    "\n",
    "    nz_rows = A.row \n",
    "    nz_cols = A.col\n",
    "    \n",
    "    t1 = time.time()\n",
    "    P_list_asn = []\n",
    "    c = np.zeros((n,k))\n",
    "    for i in range(k):\n",
    "        clust_lst = P_list[i][\"partition\"]\n",
    "        clust_asn = clust_lst_to_asn(clust_lst)\n",
    "        c[:,i] = np.array(clust_asn)\n",
    "    t2 = time.time()\n",
    "    print(\"Time to generate cluster assignment matrix:\", t2-t1)\n",
    "    \n",
    "    Aw_rows = A.row\n",
    "    Aw_cols = A.col\n",
    "    Aw_vals = A.data\n",
    "    #nz_elems = []\n",
    "    t1 = time.time()\n",
    "    for i in range(len(nz_rows)):\n",
    "        Aw_vals[i] = np.sum( c[nz_rows[i],:] == c[nz_cols[i],:] )\n",
    "        #nz_elems.append((nz_rows[i], nz_cols[i], Aw_vals[i]))\n",
    "    #Gw = nx.from_scipy_sparse_array(coo_array((Aw_vals, (Aw_rows, Aw_cols)), shape=(n, n)))\n",
    "    #nz_elems = sorted(nz_elems, key=lambda x: x[2], reverse=True)\n",
    "    Aw = csr_array((Aw_vals, (Aw_rows, Aw_cols)), shape=(n, n))\n",
    "    t2 = time.time()\n",
    "    print(\"Time to generate weighted consensus graph:\", t2-t1)\n",
    "    print(\"Number of non-zeroes in Aw:\", Aw.count_nonzero())\n",
    "    \n",
    "    t1 = time.time()\n",
    "    refined_partition = None\n",
    "    if starting_partition:\n",
    "        refined_partition = list(starting_partition)\n",
    "    else:\n",
    "        refined_partition = []\n",
    "        for i in range(n):\n",
    "            refined_partition.append([str(i)])\n",
    "    \n",
    "    refined_partition_map = clust_lst_to_map(refined_partition)\n",
    "    items = list(refined_partition_map.keys())\n",
    "    t2 = time.time()\n",
    "    print(\"Time to initialize:\", t2-t1)\n",
    "    \n",
    "    tSearch = 0\n",
    "    tUpdate = 0\n",
    "    tMovement = 0\n",
    "    count = 0\n",
    "    it = 1\n",
    "    last_valid = np.zeros(n)\n",
    "    last_deltaS = np.zeros(n)\n",
    "    while(it <= niter):\n",
    "        potential_moves = {\n",
    "            \"from\": np.arange(n),\n",
    "            \"to\": np.arange(n),\n",
    "            \"attractor\": np.arange(n),\n",
    "            \"deltaS\": np.zeros(n),\n",
    "            \"valid\": np.zeros(n)\n",
    "        }\n",
    "        for u in range(n):\n",
    "            row_start = Aw.indptr[u]\n",
    "            row_end = Aw.indptr[u+1]\n",
    "            for j in range(row_start, row_end):\n",
    "                v = Aw.indices[j]\n",
    "                w = Aw.data[j]\n",
    "                \n",
    "                t1 = time.time()\n",
    "                \n",
    "                a = refined_partition_map[str(u)]\n",
    "                b = refined_partition_map[str(v)]\n",
    "                \n",
    "                Mua = 0\n",
    "                Mub = 0\n",
    "                for elem in refined_partition[a]:\n",
    "                    if str(elem) != str(u):\n",
    "                        Mua = Mua + (k - 2 * np.sum( (c[int(u),:] == c[int(elem),:]) ) )\n",
    "                for elem in refined_partition[b]:    \n",
    "                    if str(elem) != str(u):\n",
    "                        Mub = Mub + (k - 2 * np.sum( (c[int(u),:] == c[int(elem),:]) ) )\n",
    "                \n",
    "                deltaS = Mub - Mua\n",
    "                t2 = time.time()\n",
    "                tSearch = tSearch + t2-t1\n",
    "                \n",
    "                if (deltaS is not None) and (deltaS < 0) and (a != b):\n",
    "                    potential_moves[\"from\"][u] = a\n",
    "                    potential_moves[\"to\"][u] = b\n",
    "                    potential_moves[\"attractor\"][u] = v\n",
    "                    potential_moves[\"deltaS\"][u] = deltaS\n",
    "                    potential_moves[\"valid\"][u] = 1\n",
    "        \n",
    "        t1 = time.time()\n",
    "        for u in range(n):\n",
    "            v = potential_moves[\"attractor\"][u]\n",
    "            if (potential_moves[\"valid\"][u] == 1) and (potential_moves[\"attractor\"][v] == u) and (potential_moves[\"valid\"][v] == 1):\n",
    "                # Question mark\n",
    "                if potential_moves[\"deltaS\"][u] < potential_moves[\"deltaS\"][v]:\n",
    "                    potential_moves[\"valid\"][v] = 0\n",
    "                    potential_moves[\"deltaS\"][v] = 0\n",
    "                else:\n",
    "                    potential_moves[\"valid\"][u] = 0\n",
    "                    potential_moves[\"deltaS\"][u] = 0\n",
    "        t2 = time.time()\n",
    "        tSearch = tSearch + (t2 - t1)\n",
    "        \n",
    "        flag = False\n",
    "        if np.sum( (potential_moves[\"valid\"] != last_valid) ) == 0:\n",
    "            # Same set of elements are being moved\n",
    "            if np.sum(potential_moves[\"deltaS\"]) < np.sum(last_deltaS):\n",
    "                last_valid = potential_moves[\"valid\"]\n",
    "                last_deltaS = potential_moves[\"deltaS\"]\n",
    "                flag = True\n",
    "        else:\n",
    "            last_valid = potential_moves[\"valid\"]\n",
    "            last_deltaS = potential_moves[\"deltaS\"]\n",
    "            flag = True\n",
    "        \n",
    "        if flag == True:\n",
    "            for u in range(n):\n",
    "                if potential_moves[\"valid\"][u] == True:\n",
    "                    a = potential_moves[\"from\"][u]\n",
    "                    b = potential_moves[\"to\"][u]\n",
    "\n",
    "                    t1 = time.time()\n",
    "                    if verbose:\n",
    "                        print(\"---\")\n",
    "                        print(\"Iteration:\", it, \"Move Count:\", count+1, \">> results in deltaS\", potential_moves[\"deltaS\"][u])\n",
    "                        print(\"Move:\", u)\n",
    "                        print(\"From partition\", a, \":\", refined_partition[a])\n",
    "                        print(\"To partition\", b, \":\", refined_partition[b])\n",
    "                        print(\"---\")\n",
    "                    refined_partition[a].remove(str(u))\n",
    "                    refined_partition[b].append(str(u))\n",
    "                    refined_partition_map[str(u)] = b\n",
    "                    t2 = time.time()\n",
    "                    tUpdate = tUpdate + (t2-t1)\n",
    "\n",
    "                    count = count + 1\n",
    "        \n",
    "        if flag == False:\n",
    "            break\n",
    "        \n",
    "        it = it + 1\n",
    "    print(\"Time to search moves:\", tSearch)\n",
    "    print(\"Time to update M:\", tUpdate)\n",
    "    \n",
    "    t1 = time.time()\n",
    "    empty_clusters = []\n",
    "    for i in range(len(refined_partition)):\n",
    "        if len(refined_partition[i]) == 0:\n",
    "            empty_clusters.append(i)\n",
    "            \n",
    "    empty_clusters.sort(reverse=True)\n",
    "    for e in empty_clusters:\n",
    "        del refined_partition[e]\n",
    "    t2 = time.time()\n",
    "    print(\"Time to delete empty partitions:\", t2-t1)\n",
    "    \n",
    "    Gw = nx.from_scipy_sparse_array(Aw)\n",
    "    return {\"graph\": nx.Graph(Gw), \"partition\": list(refined_partition)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c973480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 algorithms.louvain(G,resolution=0.5,randomize=314159) 201\n",
      "1 algorithms.louvain(G,resolution=0.5,randomize=2718) 202\n",
      "2 algorithms.louvain(G,resolution=0.5,randomize=1234) 203\n",
      "3 algorithms.louvain(G,resolution=0.5,randomize=4321) 203\n",
      "4 algorithms.louvain(G,resolution=0.5,randomize=987654321) 201\n",
      "5 algorithms.louvain(G,resolution=0.75,randomize=314159) 100\n",
      "6 algorithms.louvain(G,resolution=0.75,randomize=2718) 95\n",
      "7 algorithms.louvain(G,resolution=0.75,randomize=1234) 97\n",
      "8 algorithms.louvain(G,resolution=0.75,randomize=4321) 99\n",
      "9 algorithms.louvain(G,resolution=0.75,randomize=987654321) 97\n",
      "10 algorithms.louvain(G,resolution=1.0,randomize=314159) 113\n",
      "11 algorithms.louvain(G,resolution=1.0,randomize=2718) 116\n",
      "12 algorithms.louvain(G,resolution=1.0,randomize=1234) 115\n",
      "13 algorithms.louvain(G,resolution=1.0,randomize=4321) 113\n",
      "14 algorithms.louvain(G,resolution=1.0,randomize=987654321) 112\n",
      "15 algorithms.louvain(G,resolution=1.25,randomize=314159) 127\n",
      "16 algorithms.louvain(G,resolution=1.25,randomize=2718) 126\n",
      "17 algorithms.louvain(G,resolution=1.25,randomize=1234) 126\n",
      "18 algorithms.louvain(G,resolution=1.25,randomize=4321) 128\n",
      "19 algorithms.louvain(G,resolution=1.25,randomize=987654321) 125\n",
      "20 algorithms.louvain(G,resolution=1.5,randomize=314159) 136\n",
      "21 algorithms.louvain(G,resolution=1.5,randomize=2718) 138\n",
      "22 algorithms.louvain(G,resolution=1.5,randomize=1234) 134\n",
      "23 algorithms.louvain(G,resolution=1.5,randomize=4321) 135\n",
      "24 algorithms.louvain(G,resolution=1.5,randomize=987654321) 134\n",
      "0 algorithms.louvain(G,resolution=0.5,randomize=314159) 201\n",
      "1 algorithms.louvain(G,resolution=0.5,randomize=2718) 203\n",
      "2 algorithms.louvain(G,resolution=0.5,randomize=1234) 202\n",
      "3 algorithms.louvain(G,resolution=0.5,randomize=4321) 202\n",
      "4 algorithms.louvain(G,resolution=0.5,randomize=987654321) 204\n",
      "5 algorithms.louvain(G,resolution=0.75,randomize=314159) 71\n",
      "6 algorithms.louvain(G,resolution=0.75,randomize=2718) 76\n",
      "7 algorithms.louvain(G,resolution=0.75,randomize=1234) 74\n",
      "8 algorithms.louvain(G,resolution=0.75,randomize=4321) 72\n",
      "9 algorithms.louvain(G,resolution=0.75,randomize=987654321) 74\n",
      "10 algorithms.louvain(G,resolution=1.0,randomize=314159) 90\n",
      "11 algorithms.louvain(G,resolution=1.0,randomize=2718) 90\n",
      "12 algorithms.louvain(G,resolution=1.0,randomize=1234) 91\n",
      "13 algorithms.louvain(G,resolution=1.0,randomize=4321) 89\n",
      "14 algorithms.louvain(G,resolution=1.0,randomize=987654321) 90\n",
      "15 algorithms.louvain(G,resolution=1.25,randomize=314159) 104\n",
      "16 algorithms.louvain(G,resolution=1.25,randomize=2718) 108\n",
      "17 algorithms.louvain(G,resolution=1.25,randomize=1234) 109\n",
      "18 algorithms.louvain(G,resolution=1.25,randomize=4321) 107\n",
      "19 algorithms.louvain(G,resolution=1.25,randomize=987654321) 108\n",
      "20 algorithms.louvain(G,resolution=1.5,randomize=314159) 121\n",
      "21 algorithms.louvain(G,resolution=1.5,randomize=2718) 119\n",
      "22 algorithms.louvain(G,resolution=1.5,randomize=1234) 120\n",
      "23 algorithms.louvain(G,resolution=1.5,randomize=4321) 119\n",
      "24 algorithms.louvain(G,resolution=1.5,randomize=987654321) 121\n",
      "0 algorithms.louvain(G,resolution=0.5,randomize=314159) 206\n",
      "1 algorithms.louvain(G,resolution=0.5,randomize=2718) 205\n",
      "2 algorithms.louvain(G,resolution=0.5,randomize=1234) 211\n",
      "3 algorithms.louvain(G,resolution=0.5,randomize=4321) 206\n",
      "4 algorithms.louvain(G,resolution=0.5,randomize=987654321) 211\n",
      "5 algorithms.louvain(G,resolution=0.75,randomize=314159) 58\n",
      "6 algorithms.louvain(G,resolution=0.75,randomize=2718) 65\n",
      "7 algorithms.louvain(G,resolution=0.75,randomize=1234) 59\n",
      "8 algorithms.louvain(G,resolution=0.75,randomize=4321) 59\n",
      "9 algorithms.louvain(G,resolution=0.75,randomize=987654321) 61\n",
      "10 algorithms.louvain(G,resolution=1.0,randomize=314159) 69\n",
      "11 algorithms.louvain(G,resolution=1.0,randomize=2718) 72\n",
      "12 algorithms.louvain(G,resolution=1.0,randomize=1234) 73\n",
      "13 algorithms.louvain(G,resolution=1.0,randomize=4321) 67\n",
      "14 algorithms.louvain(G,resolution=1.0,randomize=987654321) 73\n",
      "15 algorithms.louvain(G,resolution=1.25,randomize=314159) 93\n",
      "16 algorithms.louvain(G,resolution=1.25,randomize=2718) 93\n",
      "17 algorithms.louvain(G,resolution=1.25,randomize=1234) 92\n",
      "18 algorithms.louvain(G,resolution=1.25,randomize=4321) 96\n",
      "19 algorithms.louvain(G,resolution=1.25,randomize=987654321) 95\n",
      "20 algorithms.louvain(G,resolution=1.5,randomize=314159) 108\n",
      "21 algorithms.louvain(G,resolution=1.5,randomize=2718) 110\n",
      "22 algorithms.louvain(G,resolution=1.5,randomize=1234) 106\n",
      "23 algorithms.louvain(G,resolution=1.5,randomize=4321) 110\n",
      "24 algorithms.louvain(G,resolution=1.5,randomize=987654321) 108\n",
      "0 algorithms.louvain(G,resolution=0.5,randomize=314159) 240\n",
      "1 algorithms.louvain(G,resolution=0.5,randomize=2718) 246\n",
      "2 algorithms.louvain(G,resolution=0.5,randomize=1234) 247\n",
      "3 algorithms.louvain(G,resolution=0.5,randomize=4321) 253\n",
      "4 algorithms.louvain(G,resolution=0.5,randomize=987654321) 229\n",
      "5 algorithms.louvain(G,resolution=0.75,randomize=314159) 55\n",
      "6 algorithms.louvain(G,resolution=0.75,randomize=2718) 51\n",
      "7 algorithms.louvain(G,resolution=0.75,randomize=1234) 56\n",
      "8 algorithms.louvain(G,resolution=0.75,randomize=4321) 53\n",
      "9 algorithms.louvain(G,resolution=0.75,randomize=987654321) 52\n",
      "10 algorithms.louvain(G,resolution=1.0,randomize=314159) 56\n",
      "11 algorithms.louvain(G,resolution=1.0,randomize=2718) 52\n",
      "12 algorithms.louvain(G,resolution=1.0,randomize=1234) 52\n",
      "13 algorithms.louvain(G,resolution=1.0,randomize=4321) 54\n",
      "14 algorithms.louvain(G,resolution=1.0,randomize=987654321) 54\n",
      "15 algorithms.louvain(G,resolution=1.25,randomize=314159) 72\n",
      "16 algorithms.louvain(G,resolution=1.25,randomize=2718) 77\n",
      "17 algorithms.louvain(G,resolution=1.25,randomize=1234) 72\n",
      "18 algorithms.louvain(G,resolution=1.25,randomize=4321) 78\n",
      "19 algorithms.louvain(G,resolution=1.25,randomize=987654321) 77\n",
      "20 algorithms.louvain(G,resolution=1.5,randomize=314159) 92\n",
      "21 algorithms.louvain(G,resolution=1.5,randomize=2718) 93\n",
      "22 algorithms.louvain(G,resolution=1.5,randomize=1234) 95\n",
      "23 algorithms.louvain(G,resolution=1.5,randomize=4321) 92\n",
      "24 algorithms.louvain(G,resolution=1.5,randomize=987654321) 93\n"
     ]
    }
   ],
   "source": [
    "n = 5000\n",
    "fileprefix = \"LFR/\" + \"n\" + str(n) + \"/\"\n",
    "mus = [1, 2, 3, 4]\n",
    "#mus = [1]\n",
    "gammas = [30]\n",
    "betas = [11]\n",
    "for mu in mus:\n",
    "    for gamma in gammas:\n",
    "        for beta in betas:\n",
    "            fname = \"LFR_n\" + str(n) + \"_mu0\" + str(mu) + \"_gamma\" + str(gamma) + \"_beta\" + str(beta)\n",
    "            graph_file = fileprefix + fname + \".mtx\"\n",
    "            G = None\n",
    "            with open(graph_file) as f:\n",
    "                G = nx.from_scipy_sparse_array(spio.mmread(f), create_using=nx.Graph)\n",
    "                count = 0\n",
    "                comms = None\n",
    "                for alg, params in alg_params.items():\n",
    "                    param_combinations = []\n",
    "                    param_names = []\n",
    "                    if params is not None:\n",
    "                        iterables = []\n",
    "                        param_names = []\n",
    "                        for param in params.keys():\n",
    "                            iterables.append(list(params[param]))\n",
    "                            param_names.append(param)\n",
    "                        param_combinations = list(itertools.product(*iterables))\n",
    "                    if len(param_combinations) > 0:\n",
    "                        for param_combination in param_combinations:\n",
    "                            expr = \"algorithms.\"+alg+\"(G\"\n",
    "                            for i in range(len(param_names)):\n",
    "                                expr = expr + \",\" + param_names[i] + \"=\" + str(param_combination[i])\n",
    "                            expr = expr + \")\"\n",
    "                            try:\n",
    "                                coms = eval(expr)\n",
    "                                print(count, expr, len(coms.communities))\n",
    "                                write_clust_lst(coms.communities, \"LFR-lf-cons-evaluation/\" + \"n\" + str(n) + \"/\" + fname + \".\" + str(count))\n",
    "                                count = count + 1\n",
    "                            except:\n",
    "                                print(\"UNSUCCESSFUL\", expr)       \n",
    "                    else:\n",
    "                        expr = \"algorithms.\"+alg+\"(G)\"\n",
    "                        try:\n",
    "                            coms = eval(expr)\n",
    "                            print(count, expr, len(coms.communities))\n",
    "                            write_clust_lst(coms.communities, \"LFR-lf-cons-evaluation/\" + \"n\" + str(n) + \"/\" + fname + \".\" + str(count))\n",
    "                            count = count + 1\n",
    "                        except:\n",
    "                            print(\"UNSUCCESSFUL\", expr)\n",
    "\n",
    "                    #coms = eval()\n",
    "                #write_clust_lst(coms.communities, fileprefix + fname + \".\" + alg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8134bf47",
   "metadata": {},
   "source": [
    "# Iterative LF runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e306c8b1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LFR/n5000/LFR_n5000_mu01_gamma30_beta11.mtx\n",
      "mu: 1 it: 0 algorithms.louvain(G,resolution=0.5,randomize=314159) 201\n",
      "mu: 1 it: 0 algorithms.louvain(G,resolution=0.5,randomize=2718) 202\n",
      "mu: 1 it: 0 algorithms.louvain(G,resolution=0.5,randomize=1234) 203\n",
      "mu: 1 it: 0 algorithms.louvain(G,resolution=0.5,randomize=4321) 203\n",
      "mu: 1 it: 0 algorithms.louvain(G,resolution=0.5,randomize=987654321) 201\n",
      "mu: 1 it: 0 algorithms.louvain(G,resolution=0.75,randomize=314159) 100\n",
      "mu: 1 it: 0 algorithms.louvain(G,resolution=0.75,randomize=2718) 95\n",
      "mu: 1 it: 0 algorithms.louvain(G,resolution=0.75,randomize=1234) 97\n",
      "mu: 1 it: 0 algorithms.louvain(G,resolution=0.75,randomize=4321) 99\n",
      "mu: 1 it: 0 algorithms.louvain(G,resolution=0.75,randomize=987654321) 97\n",
      "mu: 1 it: 0 algorithms.louvain(G,resolution=1.0,randomize=314159) 113\n",
      "mu: 1 it: 0 algorithms.louvain(G,resolution=1.0,randomize=2718) 116\n",
      "mu: 1 it: 0 algorithms.louvain(G,resolution=1.0,randomize=1234) 115\n",
      "mu: 1 it: 0 algorithms.louvain(G,resolution=1.0,randomize=4321) 113\n",
      "mu: 1 it: 0 algorithms.louvain(G,resolution=1.0,randomize=987654321) 112\n",
      "mu: 1 it: 0 algorithms.louvain(G,resolution=1.25,randomize=314159) 127\n",
      "mu: 1 it: 0 algorithms.louvain(G,resolution=1.25,randomize=2718) 126\n",
      "mu: 1 it: 0 algorithms.louvain(G,resolution=1.25,randomize=1234) 126\n",
      "mu: 1 it: 0 algorithms.louvain(G,resolution=1.25,randomize=4321) 128\n",
      "mu: 1 it: 0 algorithms.louvain(G,resolution=1.25,randomize=987654321) 125\n",
      "mu: 1 it: 0 algorithms.louvain(G,resolution=1.5,randomize=314159) 136\n",
      "mu: 1 it: 0 algorithms.louvain(G,resolution=1.5,randomize=2718) 138\n",
      "mu: 1 it: 0 algorithms.louvain(G,resolution=1.5,randomize=1234) 134\n",
      "mu: 1 it: 0 algorithms.louvain(G,resolution=1.5,randomize=4321) 135\n",
      "mu: 1 it: 0 algorithms.louvain(G,resolution=1.5,randomize=987654321) 134\n",
      "mu: 1 it: 0 norm: 9962.149868376806\n",
      "mu: 1 it: 1 algorithms.louvain(G,resolution=0.5,randomize=314159) 150\n",
      "mu: 1 it: 1 algorithms.louvain(G,resolution=0.5,randomize=2718) 150\n",
      "mu: 1 it: 1 algorithms.louvain(G,resolution=0.5,randomize=1234) 150\n",
      "mu: 1 it: 1 algorithms.louvain(G,resolution=0.5,randomize=4321) 150\n",
      "mu: 1 it: 1 algorithms.louvain(G,resolution=0.5,randomize=987654321) 150\n",
      "mu: 1 it: 1 algorithms.louvain(G,resolution=0.75,randomize=314159) 150\n",
      "mu: 1 it: 1 algorithms.louvain(G,resolution=0.75,randomize=2718) 150\n",
      "mu: 1 it: 1 algorithms.louvain(G,resolution=0.75,randomize=1234) 150\n",
      "mu: 1 it: 1 algorithms.louvain(G,resolution=0.75,randomize=4321) 150\n",
      "mu: 1 it: 1 algorithms.louvain(G,resolution=0.75,randomize=987654321) 150\n",
      "mu: 1 it: 1 algorithms.louvain(G,resolution=1.0,randomize=314159) 150\n",
      "mu: 1 it: 1 algorithms.louvain(G,resolution=1.0,randomize=2718) 150\n",
      "mu: 1 it: 1 algorithms.louvain(G,resolution=1.0,randomize=1234) 150\n",
      "mu: 1 it: 1 algorithms.louvain(G,resolution=1.0,randomize=4321) 150\n",
      "mu: 1 it: 1 algorithms.louvain(G,resolution=1.0,randomize=987654321) 150\n",
      "mu: 1 it: 1 algorithms.louvain(G,resolution=1.25,randomize=314159) 150\n",
      "mu: 1 it: 1 algorithms.louvain(G,resolution=1.25,randomize=2718) 150\n",
      "mu: 1 it: 1 algorithms.louvain(G,resolution=1.25,randomize=1234) 150\n",
      "mu: 1 it: 1 algorithms.louvain(G,resolution=1.25,randomize=4321) 150\n",
      "mu: 1 it: 1 algorithms.louvain(G,resolution=1.25,randomize=987654321) 150\n",
      "mu: 1 it: 1 algorithms.louvain(G,resolution=1.5,randomize=314159) 150\n",
      "mu: 1 it: 1 algorithms.louvain(G,resolution=1.5,randomize=2718) 150\n",
      "mu: 1 it: 1 algorithms.louvain(G,resolution=1.5,randomize=1234) 150\n",
      "mu: 1 it: 1 algorithms.louvain(G,resolution=1.5,randomize=4321) 150\n",
      "mu: 1 it: 1 algorithms.louvain(G,resolution=1.5,randomize=987654321) 150\n",
      "mu: 1 it: 1 norm: 1948.6549207081277\n",
      "mu: 1 it: 2 algorithms.louvain(G,resolution=0.5,randomize=314159) 150\n",
      "mu: 1 it: 2 algorithms.louvain(G,resolution=0.5,randomize=2718) 150\n",
      "mu: 1 it: 2 algorithms.louvain(G,resolution=0.5,randomize=1234) 150\n",
      "mu: 1 it: 2 algorithms.louvain(G,resolution=0.5,randomize=4321) 150\n",
      "mu: 1 it: 2 algorithms.louvain(G,resolution=0.5,randomize=987654321) 150\n",
      "mu: 1 it: 2 algorithms.louvain(G,resolution=0.75,randomize=314159) 150\n",
      "mu: 1 it: 2 algorithms.louvain(G,resolution=0.75,randomize=2718) 150\n",
      "mu: 1 it: 2 algorithms.louvain(G,resolution=0.75,randomize=1234) 150\n",
      "mu: 1 it: 2 algorithms.louvain(G,resolution=0.75,randomize=4321) 150\n",
      "mu: 1 it: 2 algorithms.louvain(G,resolution=0.75,randomize=987654321) 150\n",
      "mu: 1 it: 2 algorithms.louvain(G,resolution=1.0,randomize=314159) 150\n",
      "mu: 1 it: 2 algorithms.louvain(G,resolution=1.0,randomize=2718) 150\n",
      "mu: 1 it: 2 algorithms.louvain(G,resolution=1.0,randomize=1234) 150\n",
      "mu: 1 it: 2 algorithms.louvain(G,resolution=1.0,randomize=4321) 150\n",
      "mu: 1 it: 2 algorithms.louvain(G,resolution=1.0,randomize=987654321) 150\n",
      "mu: 1 it: 2 algorithms.louvain(G,resolution=1.25,randomize=314159) 150\n",
      "mu: 1 it: 2 algorithms.louvain(G,resolution=1.25,randomize=2718) 150\n",
      "mu: 1 it: 2 algorithms.louvain(G,resolution=1.25,randomize=1234) 150\n",
      "mu: 1 it: 2 algorithms.louvain(G,resolution=1.25,randomize=4321) 150\n",
      "mu: 1 it: 2 algorithms.louvain(G,resolution=1.25,randomize=987654321) 150\n",
      "mu: 1 it: 2 algorithms.louvain(G,resolution=1.5,randomize=314159) 150\n",
      "mu: 1 it: 2 algorithms.louvain(G,resolution=1.5,randomize=2718) 150\n",
      "mu: 1 it: 2 algorithms.louvain(G,resolution=1.5,randomize=1234) 150\n",
      "mu: 1 it: 2 algorithms.louvain(G,resolution=1.5,randomize=4321) 150\n",
      "mu: 1 it: 2 algorithms.louvain(G,resolution=1.5,randomize=987654321) 150\n",
      "mu: 1 it: 2 norm: 0.0\n",
      "LFR/n5000/LFR_n5000_mu02_gamma30_beta11.mtx\n",
      "mu: 2 it: 0 algorithms.louvain(G,resolution=0.5,randomize=314159) 201\n",
      "mu: 2 it: 0 algorithms.louvain(G,resolution=0.5,randomize=2718) 203\n",
      "mu: 2 it: 0 algorithms.louvain(G,resolution=0.5,randomize=1234) 202\n",
      "mu: 2 it: 0 algorithms.louvain(G,resolution=0.5,randomize=4321) 202\n",
      "mu: 2 it: 0 algorithms.louvain(G,resolution=0.5,randomize=987654321) 204\n",
      "mu: 2 it: 0 algorithms.louvain(G,resolution=0.75,randomize=314159) 71\n",
      "mu: 2 it: 0 algorithms.louvain(G,resolution=0.75,randomize=2718) 76\n",
      "mu: 2 it: 0 algorithms.louvain(G,resolution=0.75,randomize=1234) 74\n",
      "mu: 2 it: 0 algorithms.louvain(G,resolution=0.75,randomize=4321) 72\n",
      "mu: 2 it: 0 algorithms.louvain(G,resolution=0.75,randomize=987654321) 74\n",
      "mu: 2 it: 0 algorithms.louvain(G,resolution=1.0,randomize=314159) 90\n",
      "mu: 2 it: 0 algorithms.louvain(G,resolution=1.0,randomize=2718) 90\n",
      "mu: 2 it: 0 algorithms.louvain(G,resolution=1.0,randomize=1234) 91\n",
      "mu: 2 it: 0 algorithms.louvain(G,resolution=1.0,randomize=4321) 89\n",
      "mu: 2 it: 0 algorithms.louvain(G,resolution=1.0,randomize=987654321) 90\n",
      "mu: 2 it: 0 algorithms.louvain(G,resolution=1.25,randomize=314159) 104\n",
      "mu: 2 it: 0 algorithms.louvain(G,resolution=1.25,randomize=2718) 108\n",
      "mu: 2 it: 0 algorithms.louvain(G,resolution=1.25,randomize=1234) 109\n",
      "mu: 2 it: 0 algorithms.louvain(G,resolution=1.25,randomize=4321) 107\n",
      "mu: 2 it: 0 algorithms.louvain(G,resolution=1.25,randomize=987654321) 108\n",
      "mu: 2 it: 0 algorithms.louvain(G,resolution=1.5,randomize=314159) 121\n",
      "mu: 2 it: 0 algorithms.louvain(G,resolution=1.5,randomize=2718) 119\n",
      "mu: 2 it: 0 algorithms.louvain(G,resolution=1.5,randomize=1234) 120\n",
      "mu: 2 it: 0 algorithms.louvain(G,resolution=1.5,randomize=4321) 119\n",
      "mu: 2 it: 0 algorithms.louvain(G,resolution=1.5,randomize=987654321) 121\n",
      "mu: 2 it: 0 norm: 9977.170089759922\n",
      "mu: 2 it: 1 algorithms.louvain(G,resolution=0.5,randomize=314159) 157\n",
      "mu: 2 it: 1 algorithms.louvain(G,resolution=0.5,randomize=2718) 157\n",
      "mu: 2 it: 1 algorithms.louvain(G,resolution=0.5,randomize=1234) 157\n",
      "mu: 2 it: 1 algorithms.louvain(G,resolution=0.5,randomize=4321) 157\n",
      "mu: 2 it: 1 algorithms.louvain(G,resolution=0.5,randomize=987654321) 157\n",
      "mu: 2 it: 1 algorithms.louvain(G,resolution=0.75,randomize=314159) 157\n",
      "mu: 2 it: 1 algorithms.louvain(G,resolution=0.75,randomize=2718) 157\n",
      "mu: 2 it: 1 algorithms.louvain(G,resolution=0.75,randomize=1234) 157\n",
      "mu: 2 it: 1 algorithms.louvain(G,resolution=0.75,randomize=4321) 157\n",
      "mu: 2 it: 1 algorithms.louvain(G,resolution=0.75,randomize=987654321) 157\n",
      "mu: 2 it: 1 algorithms.louvain(G,resolution=1.0,randomize=314159) 157\n",
      "mu: 2 it: 1 algorithms.louvain(G,resolution=1.0,randomize=2718) 157\n",
      "mu: 2 it: 1 algorithms.louvain(G,resolution=1.0,randomize=1234) 157\n",
      "mu: 2 it: 1 algorithms.louvain(G,resolution=1.0,randomize=4321) 157\n",
      "mu: 2 it: 1 algorithms.louvain(G,resolution=1.0,randomize=987654321) 157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mu: 2 it: 1 algorithms.louvain(G,resolution=1.25,randomize=314159) 157\n",
      "mu: 2 it: 1 algorithms.louvain(G,resolution=1.25,randomize=2718) 157\n",
      "mu: 2 it: 1 algorithms.louvain(G,resolution=1.25,randomize=1234) 157\n",
      "mu: 2 it: 1 algorithms.louvain(G,resolution=1.25,randomize=4321) 157\n",
      "mu: 2 it: 1 algorithms.louvain(G,resolution=1.25,randomize=987654321) 157\n",
      "mu: 2 it: 1 algorithms.louvain(G,resolution=1.5,randomize=314159) 157\n",
      "mu: 2 it: 1 algorithms.louvain(G,resolution=1.5,randomize=2718) 157\n",
      "mu: 2 it: 1 algorithms.louvain(G,resolution=1.5,randomize=1234) 157\n",
      "mu: 2 it: 1 algorithms.louvain(G,resolution=1.5,randomize=4321) 157\n",
      "mu: 2 it: 1 algorithms.louvain(G,resolution=1.5,randomize=987654321) 157\n",
      "mu: 2 it: 1 norm: 2482.549495981903\n",
      "mu: 2 it: 2 algorithms.louvain(G,resolution=0.5,randomize=314159) 157\n",
      "mu: 2 it: 2 algorithms.louvain(G,resolution=0.5,randomize=2718) 157\n",
      "mu: 2 it: 2 algorithms.louvain(G,resolution=0.5,randomize=1234) 157\n",
      "mu: 2 it: 2 algorithms.louvain(G,resolution=0.5,randomize=4321) 157\n",
      "mu: 2 it: 2 algorithms.louvain(G,resolution=0.5,randomize=987654321) 157\n",
      "mu: 2 it: 2 algorithms.louvain(G,resolution=0.75,randomize=314159) 157\n",
      "mu: 2 it: 2 algorithms.louvain(G,resolution=0.75,randomize=2718) 157\n",
      "mu: 2 it: 2 algorithms.louvain(G,resolution=0.75,randomize=1234) 157\n",
      "mu: 2 it: 2 algorithms.louvain(G,resolution=0.75,randomize=4321) 157\n",
      "mu: 2 it: 2 algorithms.louvain(G,resolution=0.75,randomize=987654321) 157\n",
      "mu: 2 it: 2 algorithms.louvain(G,resolution=1.0,randomize=314159) 157\n",
      "mu: 2 it: 2 algorithms.louvain(G,resolution=1.0,randomize=2718) 157\n",
      "mu: 2 it: 2 algorithms.louvain(G,resolution=1.0,randomize=1234) 157\n",
      "mu: 2 it: 2 algorithms.louvain(G,resolution=1.0,randomize=4321) 157\n",
      "mu: 2 it: 2 algorithms.louvain(G,resolution=1.0,randomize=987654321) 157\n",
      "mu: 2 it: 2 algorithms.louvain(G,resolution=1.25,randomize=314159) 157\n",
      "mu: 2 it: 2 algorithms.louvain(G,resolution=1.25,randomize=2718) 157\n",
      "mu: 2 it: 2 algorithms.louvain(G,resolution=1.25,randomize=1234) 157\n",
      "mu: 2 it: 2 algorithms.louvain(G,resolution=1.25,randomize=4321) 157\n",
      "mu: 2 it: 2 algorithms.louvain(G,resolution=1.25,randomize=987654321) 157\n",
      "mu: 2 it: 2 algorithms.louvain(G,resolution=1.5,randomize=314159) 157\n",
      "mu: 2 it: 2 algorithms.louvain(G,resolution=1.5,randomize=2718) 157\n",
      "mu: 2 it: 2 algorithms.louvain(G,resolution=1.5,randomize=1234) 157\n",
      "mu: 2 it: 2 algorithms.louvain(G,resolution=1.5,randomize=4321) 157\n",
      "mu: 2 it: 2 algorithms.louvain(G,resolution=1.5,randomize=987654321) 157\n",
      "mu: 2 it: 2 norm: 0.0\n",
      "LFR/n5000/LFR_n5000_mu03_gamma30_beta11.mtx\n",
      "mu: 3 it: 0 algorithms.louvain(G,resolution=0.5,randomize=314159) 206\n",
      "mu: 3 it: 0 algorithms.louvain(G,resolution=0.5,randomize=2718) 205\n",
      "mu: 3 it: 0 algorithms.louvain(G,resolution=0.5,randomize=1234) 211\n",
      "mu: 3 it: 0 algorithms.louvain(G,resolution=0.5,randomize=4321) 206\n",
      "mu: 3 it: 0 algorithms.louvain(G,resolution=0.5,randomize=987654321) 211\n",
      "mu: 3 it: 0 algorithms.louvain(G,resolution=0.75,randomize=314159) 58\n",
      "mu: 3 it: 0 algorithms.louvain(G,resolution=0.75,randomize=2718) 65\n",
      "mu: 3 it: 0 algorithms.louvain(G,resolution=0.75,randomize=1234) 59\n",
      "mu: 3 it: 0 algorithms.louvain(G,resolution=0.75,randomize=4321) 59\n",
      "mu: 3 it: 0 algorithms.louvain(G,resolution=0.75,randomize=987654321) 61\n",
      "mu: 3 it: 0 algorithms.louvain(G,resolution=1.0,randomize=314159) 69\n",
      "mu: 3 it: 0 algorithms.louvain(G,resolution=1.0,randomize=2718) 72\n",
      "mu: 3 it: 0 algorithms.louvain(G,resolution=1.0,randomize=1234) 73\n",
      "mu: 3 it: 0 algorithms.louvain(G,resolution=1.0,randomize=4321) 67\n",
      "mu: 3 it: 0 algorithms.louvain(G,resolution=1.0,randomize=987654321) 73\n",
      "mu: 3 it: 0 algorithms.louvain(G,resolution=1.25,randomize=314159) 93\n",
      "mu: 3 it: 0 algorithms.louvain(G,resolution=1.25,randomize=2718) 93\n",
      "mu: 3 it: 0 algorithms.louvain(G,resolution=1.25,randomize=1234) 92\n",
      "mu: 3 it: 0 algorithms.louvain(G,resolution=1.25,randomize=4321) 96\n",
      "mu: 3 it: 0 algorithms.louvain(G,resolution=1.25,randomize=987654321) 95\n",
      "mu: 3 it: 0 algorithms.louvain(G,resolution=1.5,randomize=314159) 108\n",
      "mu: 3 it: 0 algorithms.louvain(G,resolution=1.5,randomize=2718) 110\n",
      "mu: 3 it: 0 algorithms.louvain(G,resolution=1.5,randomize=1234) 106\n",
      "mu: 3 it: 0 algorithms.louvain(G,resolution=1.5,randomize=4321) 110\n",
      "mu: 3 it: 0 algorithms.louvain(G,resolution=1.5,randomize=987654321) 108\n",
      "mu: 3 it: 0 norm: 10041.795556572539\n",
      "mu: 3 it: 1 algorithms.louvain(G,resolution=0.5,randomize=314159) 158\n",
      "mu: 3 it: 1 algorithms.louvain(G,resolution=0.5,randomize=2718) 158\n",
      "mu: 3 it: 1 algorithms.louvain(G,resolution=0.5,randomize=1234) 158\n",
      "mu: 3 it: 1 algorithms.louvain(G,resolution=0.5,randomize=4321) 158\n",
      "mu: 3 it: 1 algorithms.louvain(G,resolution=0.5,randomize=987654321) 158\n",
      "mu: 3 it: 1 algorithms.louvain(G,resolution=0.75,randomize=314159) 158\n",
      "mu: 3 it: 1 algorithms.louvain(G,resolution=0.75,randomize=2718) 158\n",
      "mu: 3 it: 1 algorithms.louvain(G,resolution=0.75,randomize=1234) 158\n",
      "mu: 3 it: 1 algorithms.louvain(G,resolution=0.75,randomize=4321) 158\n",
      "mu: 3 it: 1 algorithms.louvain(G,resolution=0.75,randomize=987654321) 158\n",
      "mu: 3 it: 1 algorithms.louvain(G,resolution=1.0,randomize=314159) 158\n",
      "mu: 3 it: 1 algorithms.louvain(G,resolution=1.0,randomize=2718) 158\n",
      "mu: 3 it: 1 algorithms.louvain(G,resolution=1.0,randomize=1234) 158\n",
      "mu: 3 it: 1 algorithms.louvain(G,resolution=1.0,randomize=4321) 158\n",
      "mu: 3 it: 1 algorithms.louvain(G,resolution=1.0,randomize=987654321) 158\n",
      "mu: 3 it: 1 algorithms.louvain(G,resolution=1.25,randomize=314159) 158\n",
      "mu: 3 it: 1 algorithms.louvain(G,resolution=1.25,randomize=2718) 158\n",
      "mu: 3 it: 1 algorithms.louvain(G,resolution=1.25,randomize=1234) 158\n",
      "mu: 3 it: 1 algorithms.louvain(G,resolution=1.25,randomize=4321) 158\n",
      "mu: 3 it: 1 algorithms.louvain(G,resolution=1.25,randomize=987654321) 158\n",
      "mu: 3 it: 1 algorithms.louvain(G,resolution=1.5,randomize=314159) 158\n",
      "mu: 3 it: 1 algorithms.louvain(G,resolution=1.5,randomize=2718) 158\n",
      "mu: 3 it: 1 algorithms.louvain(G,resolution=1.5,randomize=1234) 158\n",
      "mu: 3 it: 1 algorithms.louvain(G,resolution=1.5,randomize=4321) 158\n",
      "mu: 3 it: 1 algorithms.louvain(G,resolution=1.5,randomize=987654321) 158\n",
      "mu: 3 it: 1 norm: 2237.7350155905415\n",
      "mu: 3 it: 2 algorithms.louvain(G,resolution=0.5,randomize=314159) 158\n",
      "mu: 3 it: 2 algorithms.louvain(G,resolution=0.5,randomize=2718) 158\n",
      "mu: 3 it: 2 algorithms.louvain(G,resolution=0.5,randomize=1234) 158\n",
      "mu: 3 it: 2 algorithms.louvain(G,resolution=0.5,randomize=4321) 158\n",
      "mu: 3 it: 2 algorithms.louvain(G,resolution=0.5,randomize=987654321) 158\n",
      "mu: 3 it: 2 algorithms.louvain(G,resolution=0.75,randomize=314159) 158\n",
      "mu: 3 it: 2 algorithms.louvain(G,resolution=0.75,randomize=2718) 158\n",
      "mu: 3 it: 2 algorithms.louvain(G,resolution=0.75,randomize=1234) 158\n",
      "mu: 3 it: 2 algorithms.louvain(G,resolution=0.75,randomize=4321) 158\n",
      "mu: 3 it: 2 algorithms.louvain(G,resolution=0.75,randomize=987654321) 158\n",
      "mu: 3 it: 2 algorithms.louvain(G,resolution=1.0,randomize=314159) 158\n",
      "mu: 3 it: 2 algorithms.louvain(G,resolution=1.0,randomize=2718) 158\n",
      "mu: 3 it: 2 algorithms.louvain(G,resolution=1.0,randomize=1234) 158\n",
      "mu: 3 it: 2 algorithms.louvain(G,resolution=1.0,randomize=4321) 158\n",
      "mu: 3 it: 2 algorithms.louvain(G,resolution=1.0,randomize=987654321) 158\n",
      "mu: 3 it: 2 algorithms.louvain(G,resolution=1.25,randomize=314159) 158\n",
      "mu: 3 it: 2 algorithms.louvain(G,resolution=1.25,randomize=2718) 158\n",
      "mu: 3 it: 2 algorithms.louvain(G,resolution=1.25,randomize=1234) 158\n",
      "mu: 3 it: 2 algorithms.louvain(G,resolution=1.25,randomize=4321) 158\n",
      "mu: 3 it: 2 algorithms.louvain(G,resolution=1.25,randomize=987654321) 158\n",
      "mu: 3 it: 2 algorithms.louvain(G,resolution=1.5,randomize=314159) 158\n",
      "mu: 3 it: 2 algorithms.louvain(G,resolution=1.5,randomize=2718) 158\n",
      "mu: 3 it: 2 algorithms.louvain(G,resolution=1.5,randomize=1234) 158\n",
      "mu: 3 it: 2 algorithms.louvain(G,resolution=1.5,randomize=4321) 158\n",
      "mu: 3 it: 2 algorithms.louvain(G,resolution=1.5,randomize=987654321) 158\n",
      "mu: 3 it: 2 norm: 0.0\n",
      "LFR/n5000/LFR_n5000_mu04_gamma30_beta11.mtx\n",
      "mu: 4 it: 0 algorithms.louvain(G,resolution=0.5,randomize=314159) 240\n",
      "mu: 4 it: 0 algorithms.louvain(G,resolution=0.5,randomize=2718) 246\n",
      "mu: 4 it: 0 algorithms.louvain(G,resolution=0.5,randomize=1234) 247\n",
      "mu: 4 it: 0 algorithms.louvain(G,resolution=0.5,randomize=4321) 253\n",
      "mu: 4 it: 0 algorithms.louvain(G,resolution=0.5,randomize=987654321) 229\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mu: 4 it: 0 algorithms.louvain(G,resolution=0.75,randomize=314159) 55\n",
      "mu: 4 it: 0 algorithms.louvain(G,resolution=0.75,randomize=2718) 51\n",
      "mu: 4 it: 0 algorithms.louvain(G,resolution=0.75,randomize=1234) 56\n",
      "mu: 4 it: 0 algorithms.louvain(G,resolution=0.75,randomize=4321) 53\n",
      "mu: 4 it: 0 algorithms.louvain(G,resolution=0.75,randomize=987654321) 52\n",
      "mu: 4 it: 0 algorithms.louvain(G,resolution=1.0,randomize=314159) 56\n",
      "mu: 4 it: 0 algorithms.louvain(G,resolution=1.0,randomize=2718) 52\n",
      "mu: 4 it: 0 algorithms.louvain(G,resolution=1.0,randomize=1234) 52\n",
      "mu: 4 it: 0 algorithms.louvain(G,resolution=1.0,randomize=4321) 54\n",
      "mu: 4 it: 0 algorithms.louvain(G,resolution=1.0,randomize=987654321) 54\n",
      "mu: 4 it: 0 algorithms.louvain(G,resolution=1.25,randomize=314159) 72\n",
      "mu: 4 it: 0 algorithms.louvain(G,resolution=1.25,randomize=2718) 77\n",
      "mu: 4 it: 0 algorithms.louvain(G,resolution=1.25,randomize=1234) 72\n",
      "mu: 4 it: 0 algorithms.louvain(G,resolution=1.25,randomize=4321) 78\n",
      "mu: 4 it: 0 algorithms.louvain(G,resolution=1.25,randomize=987654321) 77\n",
      "mu: 4 it: 0 algorithms.louvain(G,resolution=1.5,randomize=314159) 92\n",
      "mu: 4 it: 0 algorithms.louvain(G,resolution=1.5,randomize=2718) 93\n",
      "mu: 4 it: 0 algorithms.louvain(G,resolution=1.5,randomize=1234) 95\n",
      "mu: 4 it: 0 algorithms.louvain(G,resolution=1.5,randomize=4321) 92\n",
      "mu: 4 it: 0 algorithms.louvain(G,resolution=1.5,randomize=987654321) 93\n",
      "mu: 4 it: 0 norm: 10214.10147785893\n",
      "mu: 4 it: 1 algorithms.louvain(G,resolution=0.5,randomize=314159) 156\n",
      "mu: 4 it: 1 algorithms.louvain(G,resolution=0.5,randomize=2718) 156\n",
      "mu: 4 it: 1 algorithms.louvain(G,resolution=0.5,randomize=1234) 156\n",
      "mu: 4 it: 1 algorithms.louvain(G,resolution=0.5,randomize=4321) 156\n",
      "mu: 4 it: 1 algorithms.louvain(G,resolution=0.5,randomize=987654321) 156\n",
      "mu: 4 it: 1 algorithms.louvain(G,resolution=0.75,randomize=314159) 157\n",
      "mu: 4 it: 1 algorithms.louvain(G,resolution=0.75,randomize=2718) 157\n",
      "mu: 4 it: 1 algorithms.louvain(G,resolution=0.75,randomize=1234) 156\n",
      "mu: 4 it: 1 algorithms.louvain(G,resolution=0.75,randomize=4321) 157\n",
      "mu: 4 it: 1 algorithms.louvain(G,resolution=0.75,randomize=987654321) 157\n",
      "mu: 4 it: 1 algorithms.louvain(G,resolution=1.0,randomize=314159) 157\n",
      "mu: 4 it: 1 algorithms.louvain(G,resolution=1.0,randomize=2718) 157\n",
      "mu: 4 it: 1 algorithms.louvain(G,resolution=1.0,randomize=1234) 157\n",
      "mu: 4 it: 1 algorithms.louvain(G,resolution=1.0,randomize=4321) 157\n",
      "mu: 4 it: 1 algorithms.louvain(G,resolution=1.0,randomize=987654321) 157\n",
      "mu: 4 it: 1 algorithms.louvain(G,resolution=1.25,randomize=314159) 157\n",
      "mu: 4 it: 1 algorithms.louvain(G,resolution=1.25,randomize=2718) 157\n",
      "mu: 4 it: 1 algorithms.louvain(G,resolution=1.25,randomize=1234) 157\n",
      "mu: 4 it: 1 algorithms.louvain(G,resolution=1.25,randomize=4321) 157\n",
      "mu: 4 it: 1 algorithms.louvain(G,resolution=1.25,randomize=987654321) 157\n",
      "mu: 4 it: 1 algorithms.louvain(G,resolution=1.5,randomize=314159) 157\n",
      "mu: 4 it: 1 algorithms.louvain(G,resolution=1.5,randomize=2718) 157\n",
      "mu: 4 it: 1 algorithms.louvain(G,resolution=1.5,randomize=1234) 157\n",
      "mu: 4 it: 1 algorithms.louvain(G,resolution=1.5,randomize=4321) 157\n",
      "mu: 4 it: 1 algorithms.louvain(G,resolution=1.5,randomize=987654321) 157\n",
      "mu: 4 it: 1 norm: 3574.601796004696\n",
      "mu: 4 it: 2 algorithms.louvain(G,resolution=0.5,randomize=314159) 157\n",
      "mu: 4 it: 2 algorithms.louvain(G,resolution=0.5,randomize=2718) 157\n",
      "mu: 4 it: 2 algorithms.louvain(G,resolution=0.5,randomize=1234) 157\n",
      "mu: 4 it: 2 algorithms.louvain(G,resolution=0.5,randomize=4321) 157\n",
      "mu: 4 it: 2 algorithms.louvain(G,resolution=0.5,randomize=987654321) 157\n",
      "mu: 4 it: 2 algorithms.louvain(G,resolution=0.75,randomize=314159) 157\n",
      "mu: 4 it: 2 algorithms.louvain(G,resolution=0.75,randomize=2718) 157\n",
      "mu: 4 it: 2 algorithms.louvain(G,resolution=0.75,randomize=1234) 157\n",
      "mu: 4 it: 2 algorithms.louvain(G,resolution=0.75,randomize=4321) 157\n",
      "mu: 4 it: 2 algorithms.louvain(G,resolution=0.75,randomize=987654321) 157\n",
      "mu: 4 it: 2 algorithms.louvain(G,resolution=1.0,randomize=314159) 157\n",
      "mu: 4 it: 2 algorithms.louvain(G,resolution=1.0,randomize=2718) 157\n",
      "mu: 4 it: 2 algorithms.louvain(G,resolution=1.0,randomize=1234) 157\n",
      "mu: 4 it: 2 algorithms.louvain(G,resolution=1.0,randomize=4321) 157\n",
      "mu: 4 it: 2 algorithms.louvain(G,resolution=1.0,randomize=987654321) 157\n",
      "mu: 4 it: 2 algorithms.louvain(G,resolution=1.25,randomize=314159) 157\n",
      "mu: 4 it: 2 algorithms.louvain(G,resolution=1.25,randomize=2718) 157\n",
      "mu: 4 it: 2 algorithms.louvain(G,resolution=1.25,randomize=1234) 157\n",
      "mu: 4 it: 2 algorithms.louvain(G,resolution=1.25,randomize=4321) 157\n",
      "mu: 4 it: 2 algorithms.louvain(G,resolution=1.25,randomize=987654321) 157\n",
      "mu: 4 it: 2 algorithms.louvain(G,resolution=1.5,randomize=314159) 157\n",
      "mu: 4 it: 2 algorithms.louvain(G,resolution=1.5,randomize=2718) 157\n",
      "mu: 4 it: 2 algorithms.louvain(G,resolution=1.5,randomize=1234) 157\n",
      "mu: 4 it: 2 algorithms.louvain(G,resolution=1.5,randomize=4321) 157\n",
      "mu: 4 it: 2 algorithms.louvain(G,resolution=1.5,randomize=987654321) 157\n",
      "mu: 4 it: 2 norm: 0.0\n"
     ]
    }
   ],
   "source": [
    "def prep_consensus_graph(P_list):\n",
    "    G = nx.Graph(P_list[0][\"graph\"])\n",
    "    n = len(list(G.nodes()))\n",
    "    k = len(P_list)\n",
    "    #print(\"Number of nodes\", n)\n",
    "    \n",
    "    row = []\n",
    "    col = []\n",
    "    val = []\n",
    "    for x in P_list:\n",
    "        graph = x[\"graph\"]\n",
    "        partition = x[\"partition\"]\n",
    "        for cluster in partition:\n",
    "            for i in range(len(cluster)):\n",
    "                for j in range(i+1, len(cluster)):\n",
    "                    item_1 = cluster[i]\n",
    "                    item_2 = cluster[j]\n",
    "                    row.append(int(item_1))\n",
    "                    col.append(int(item_2))\n",
    "                    val.append(int(1))\n",
    "                    \n",
    "    r = coo_array((val, (row, col)), shape=(n, n))\n",
    "    rDense = r.toarray()\n",
    "    threshold = k / 2\n",
    "    rDense[np.abs(rDense) < threshold] = 0\n",
    "    \n",
    "    G = nx.from_numpy_array(rDense)\n",
    "    return G\n",
    "\n",
    "n = 5000\n",
    "fileprefix = \"LFR-lf-cons-evaluation/\" + \"n\" + str(n) + \"/\"\n",
    "mus = [1, 2, 3, 4]\n",
    "#mus = [1]\n",
    "gammas = [30]\n",
    "betas = [11]\n",
    "\n",
    "stats = []\n",
    "\n",
    "for mu in mus:\n",
    "    for gamma in gammas:\n",
    "        for beta in betas:\n",
    "            P_list = []\n",
    "            fname = \"LFR_n\" + str(n) + \"_mu0\" + str(mu) + \"_gamma\" + str(gamma) + \"_beta\" + str(beta)\n",
    "            graph_file = \"LFR/\" + \"n\" + str(n) + \"/\" + fname + \".mtx\"\n",
    "            print(graph_file)\n",
    "            G = None\n",
    "            with open(graph_file) as f:\n",
    "                G = nx.from_scipy_sparse_array(spio.mmread(f), create_using=nx.Graph)\n",
    "                new_adj_mat = nx.to_numpy_array(G)\n",
    "                old_adj_mat = np.zeros(new_adj_mat.shape)\n",
    "                diff_mat = old_adj_mat - new_adj_mat\n",
    "                old_adj_mat = np.array(new_adj_mat)\n",
    "                norm = np.linalg.norm(diff_mat)\n",
    "                P_star = None\n",
    "                for it in range(20):\n",
    "                    P_list = []\n",
    "                    if it > 0:\n",
    "                        for k in clustering_enumeration:\n",
    "                            try:\n",
    "                                coms = eval(k[0])\n",
    "                                print(\"mu:\", mu, \"it:\", it, k[0], len(coms.communities))\n",
    "                                P_list.append({\"graph\": nx.Graph(G), \"partition\": list(coms.communities)})\n",
    "                                #stats.append({\"mu\": mu, \"it\": it, \"norm\": norm, \"alg\": k[0], \"ncluster\": len(coms.communities)})\n",
    "                                count = count + 1\n",
    "                            except:\n",
    "                                print(\"UNSUCCESSFUL\", expr)\n",
    "                    else:\n",
    "                        for k in clustering_enumeration:\n",
    "                            clust_file = fileprefix + fname + \".\" + str(k[1])\n",
    "                            if Path(clust_file).is_file():\n",
    "                                partition = read_clust_lst(clust_file)\n",
    "                                print(\"mu:\", mu, \"it:\", it, k[0], len(partition))\n",
    "                                P_list.append({\"graph\": nx.Graph(G), \"partition\": list(partition)})\n",
    "                                #stats.append({\"mu\": mu, \"it\": it, \"norm\": norm, \"alg\": k[0], \"ncluster\": len(partition)})\n",
    "                    G = prep_consensus_graph(P_list)\n",
    "                    \n",
    "                    new_adj_mat = nx.to_numpy_array(G)\n",
    "                    diff_mat = old_adj_mat - new_adj_mat\n",
    "                    norm = np.linalg.norm(diff_mat)\n",
    "                    old_adj_mat = np.array(new_adj_mat)\n",
    "                    #stats.append({\"mu\": mu, \"it\": it, \"norm\": norm, \"alg\": \"lf-louvain\", \"ncluster\": len(P_star[\"partition\"])})\n",
    "                    print(\"mu:\", mu, \"it:\", it, \"norm:\", norm)\n",
    "                    if norm < 1e-3:\n",
    "                        P_star = P_list[0]\n",
    "                        break\n",
    "                        \n",
    "                write_clust_lst(P_star[\"partition\"], fileprefix + fname + \".lf-louvain\")\n",
    "        \n",
    "#df = pd.DataFrame(stats)\n",
    "#df.to_csv(\"benchmark-lf-convergence-multi-alg.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13e484b",
   "metadata": {},
   "source": [
    "# Run v5 consensus "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0cf95052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LFR/n5000/LFR_n5000_mu01_gamma30_beta11.mtx\n",
      "Number of edges in G: 48950\n",
      "Time to get sparse matrix of the graph: 0.14106392860412598\n",
      "Time to generate cluster assignment matrix: 0.04734492301940918\n",
      "Time to generate weighted consensus graph: 0.5076236724853516\n",
      "Number of non-zeroes in Aw: 82828\n",
      "Time to initialize: 0.0018341541290283203\n",
      "Time to search moves: 244.1811809539795\n",
      "Time to update M: 0.005427360534667969\n",
      "Time to delete empty partitions: 0.0007901191711425781\n",
      "mu 1 , number of clusters 181\n",
      "Time: 246.88131737709045\n",
      "LFR/n5000/LFR_n5000_mu02_gamma30_beta11.mtx\n",
      "Number of edges in G: 50068\n",
      "Time to get sparse matrix of the graph: 0.3716106414794922\n",
      "Time to generate cluster assignment matrix: 0.04837512969970703\n",
      "Time to generate weighted consensus graph: 0.4734468460083008\n",
      "Number of non-zeroes in Aw: 71391\n",
      "Time to initialize: 0.0015609264373779297\n",
      "Time to search moves: 226.61562776565552\n",
      "Time to update M: 0.0057373046875\n",
      "Time to delete empty partitions: 0.0008802413940429688\n",
      "mu 2 , number of clusters 186\n",
      "Time: 229.45485424995422\n",
      "LFR/n5000/LFR_n5000_mu03_gamma30_beta11.mtx\n",
      "Number of edges in G: 51119\n",
      "Time to get sparse matrix of the graph: 0.14456892013549805\n",
      "Time to generate cluster assignment matrix: 0.04622030258178711\n",
      "Time to generate weighted consensus graph: 0.459827184677124\n",
      "Number of non-zeroes in Aw: 60964\n",
      "Time to initialize: 0.0014579296112060547\n",
      "Time to search moves: 253.88289427757263\n",
      "Time to update M: 0.0064623355865478516\n",
      "Time to delete empty partitions: 0.0009806156158447266\n",
      "mu 3 , number of clusters 187\n",
      "Time: 256.54250288009644\n",
      "LFR/n5000/LFR_n5000_mu04_gamma30_beta11.mtx\n",
      "Number of edges in G: 51757\n",
      "Time to get sparse matrix of the graph: 0.1286482810974121\n",
      "Time to generate cluster assignment matrix: 0.041759490966796875\n",
      "Time to generate weighted consensus graph: 0.4550180435180664\n",
      "Number of non-zeroes in Aw: 54779\n",
      "Time to initialize: 0.0015811920166015625\n",
      "Time to search moves: 296.5915985107422\n",
      "Time to update M: 0.008055686950683594\n",
      "Time to delete empty partitions: 0.0012385845184326172\n",
      "mu 4 , number of clusters 196\n",
      "Time: 299.6495134830475\n"
     ]
    }
   ],
   "source": [
    "n = 5000\n",
    "fileprefix = \"LFR-lf-cons-evaluation/\" + \"n\" + str(n) + \"/\"\n",
    "mus = [1, 2, 3, 4]\n",
    "#mus = [1]\n",
    "gammas = [30]\n",
    "betas = [11]\n",
    "\n",
    "stats = []\n",
    "\n",
    "for mu in mus:\n",
    "    for gamma in gammas:\n",
    "        for beta in betas:\n",
    "            P_list = []\n",
    "            fname = \"LFR_n\" + str(n) + \"_mu0\" + str(mu) + \"_gamma\" + str(gamma) + \"_beta\" + str(beta)\n",
    "            graph_file = \"LFR/\" + \"n\" + str(n) + \"/\" + fname + \".mtx\"\n",
    "            print(graph_file)\n",
    "            G = None\n",
    "            with open(graph_file) as f:\n",
    "                G = nx.from_scipy_sparse_array(spio.mmread(f), create_using=nx.Graph)\n",
    "                coms = None\n",
    "                for k in clustering_enumeration:\n",
    "                    clust_file = fileprefix + fname + \".\" + str(k[1])\n",
    "                    if Path(clust_file).is_file():\n",
    "                        partition = read_clust_lst(clust_file)\n",
    "                        P_list.append({\"graph\": nx.Graph(G), \"partition\": list(partition)})\n",
    "                t1 = time.time()\n",
    "                P_star = v5_consensus(P_list, niter=100, starting_partition=None, verbose=False)\n",
    "                t2 = time.time()\n",
    "                print(\"mu\", mu, \", number of clusters\", len(P_star[\"partition\"]))\n",
    "                print(\"Time:\", t2-t1)\n",
    "                write_clust_lst(P_star[\"partition\"], fileprefix + fname + \".\" + \"v5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deace344",
   "metadata": {},
   "source": [
    "### Quality of all clusterings of all benchmark graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e4c547ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LFR-lf-cons-evaluation/n200/LFR_n200_mu01_gamma30_beta11.mtx\n",
      "{'mu': 1, 'n': 200, 'gamma': 30, 'beta': 11, 'cons_method': 'lf-louvain', 'ncluster': 14, 'fscore': 0.9736225087924971, 'precision': 0.9486007995431183, 'recall': 1.0, 'nmi': 0.9818158832620204}\n",
      "{'mu': 1, 'n': 200, 'gamma': 30, 'beta': 11, 'cons_method': 'v5', 'ncluster': 15, 'fscore': 0.9857566765578635, 'precision': 0.9719133996489175, 'recall': 1.0, 'nmi': 0.9907011927026409}\n",
      "LFR-lf-cons-evaluation/n200/LFR_n200_mu02_gamma30_beta11.mtx\n",
      "{'mu': 2, 'n': 200, 'gamma': 30, 'beta': 11, 'cons_method': 'lf-louvain', 'ncluster': 14, 'fscore': 0.9709932610606504, 'precision': 0.9457762557077626, 'recall': 0.9975918121613486, 'nmi': 0.9774441680680727}\n",
      "{'mu': 2, 'n': 200, 'gamma': 30, 'beta': 11, 'cons_method': 'v5', 'ncluster': 16, 'fscore': 0.9919185872493266, 'precision': 0.9863095238095239, 'recall': 0.9975918121613486, 'nmi': 0.993572897296727}\n",
      "LFR-lf-cons-evaluation/n200/LFR_n200_mu03_gamma30_beta11.mtx\n",
      "{'mu': 3, 'n': 200, 'gamma': 30, 'beta': 11, 'cons_method': 'lf-louvain', 'ncluster': 15, 'fscore': 0.9190785587714116, 'precision': 0.9020289855072464, 'recall': 0.9367850692354004, 'nmi': 0.9370363678900646}\n",
      "{'mu': 3, 'n': 200, 'gamma': 30, 'beta': 11, 'cons_method': 'v5', 'ncluster': 18, 'fscore': 0.948780487804878, 'precision': 0.9610870907967881, 'recall': 0.9367850692354004, 'nmi': 0.9618765175159267}\n",
      "LFR-lf-cons-evaluation/n200/LFR_n200_mu04_gamma30_beta11.mtx\n",
      "{'mu': 4, 'n': 200, 'gamma': 30, 'beta': 11, 'cons_method': 'lf-louvain', 'ncluster': 18, 'fscore': 0.611427024099648, 'precision': 0.5556102362204725, 'recall': 0.6797110174593618, 'nmi': 0.7451561075134844}\n",
      "{'mu': 4, 'n': 200, 'gamma': 30, 'beta': 11, 'cons_method': 'v5', 'ncluster': 39, 'fscore': 0.5352439969016266, 'precision': 0.750271444082519, 'recall': 0.4160144491270319, 'nmi': 0.761788490572434}\n",
      "LFR-lf-cons-evaluation/n1000/LFR_n1000_mu01_gamma30_beta11.mtx\n",
      "{'mu': 1, 'n': 1000, 'gamma': 30, 'beta': 11, 'cons_method': 'lf-louvain', 'ncluster': 38, 'fscore': 1.0, 'precision': 1.0, 'recall': 1.0, 'nmi': 1.0000000000000002}\n",
      "{'mu': 1, 'n': 1000, 'gamma': 30, 'beta': 11, 'cons_method': 'v5', 'ncluster': 38, 'fscore': 1.0, 'precision': 1.0, 'recall': 1.0, 'nmi': 1.0}\n",
      "LFR-lf-cons-evaluation/n1000/LFR_n1000_mu02_gamma30_beta11.mtx\n",
      "{'mu': 2, 'n': 1000, 'gamma': 30, 'beta': 11, 'cons_method': 'lf-louvain', 'ncluster': 33, 'fscore': 0.9554076435111403, 'precision': 0.9146224721790116, 'recall': 1.0, 'nmi': 0.9837550203512714}\n",
      "{'mu': 2, 'n': 1000, 'gamma': 30, 'beta': 11, 'cons_method': 'v5', 'ncluster': 37, 'fscore': 0.9910856105546371, 'precision': 0.9823287495180568, 'recall': 1.0, 'nmi': 0.9968593680562174}\n",
      "LFR-lf-cons-evaluation/n1000/LFR_n1000_mu03_gamma30_beta11.mtx\n",
      "{'mu': 3, 'n': 1000, 'gamma': 30, 'beta': 11, 'cons_method': 'lf-louvain', 'ncluster': 37, 'fscore': 0.9771501925545572, 'precision': 0.9591129591129591, 'recall': 0.9958788513115719, 'nmi': 0.993193756353928}\n",
      "{'mu': 3, 'n': 1000, 'gamma': 30, 'beta': 11, 'cons_method': 'v5', 'ncluster': 38, 'fscore': 0.9880332986472424, 'precision': 0.9823472356935015, 'recall': 0.9937855694380846, 'nmi': 0.9943675730780329}\n",
      "LFR-lf-cons-evaluation/n1000/LFR_n1000_mu04_gamma30_beta11.mtx\n",
      "{'mu': 4, 'n': 1000, 'gamma': 30, 'beta': 11, 'cons_method': 'lf-louvain', 'ncluster': 35, 'fscore': 0.912475547422225, 'precision': 0.8813311391479247, 'recall': 0.9459017465820632, 'nmi': 0.943967539326444}\n",
      "{'mu': 4, 'n': 1000, 'gamma': 30, 'beta': 11, 'cons_method': 'v5', 'ncluster': 43, 'fscore': 0.9256893397104613, 'precision': 0.9087986890205471, 'recall': 0.9432197291816576, 'nmi': 0.9502167120029529}\n",
      "LFR-lf-cons-evaluation/n5000/LFR_n5000_mu01_gamma30_beta11.mtx\n",
      "{'mu': 1, 'n': 5000, 'gamma': 30, 'beta': 11, 'cons_method': 'lf-louvain', 'ncluster': 150, 'fscore': 0.8733361339494689, 'precision': 0.7751523415860571, 'recall': 1.0, 'nmi': 0.9729867621660679}\n",
      "{'mu': 1, 'n': 5000, 'gamma': 30, 'beta': 11, 'cons_method': 'v5', 'ncluster': 181, 'fscore': 0.9489540403776932, 'precision': 0.902866360590644, 'recall': 1.0, 'nmi': 0.9899316224321142}\n",
      "LFR-lf-cons-evaluation/n5000/LFR_n5000_mu02_gamma30_beta11.mtx\n",
      "{'mu': 2, 'n': 5000, 'gamma': 30, 'beta': 11, 'cons_method': 'lf-louvain', 'ncluster': 157, 'fscore': 0.860864626961028, 'precision': 0.7557175796098959, 'recall': 1.0, 'nmi': 0.973949704756225}\n",
      "{'mu': 2, 'n': 5000, 'gamma': 30, 'beta': 11, 'cons_method': 'v5', 'ncluster': 186, 'fscore': 0.9478723612133371, 'precision': 0.9009100476691636, 'recall': 1.0, 'nmi': 0.9913961181210352}\n",
      "LFR-lf-cons-evaluation/n5000/LFR_n5000_mu03_gamma30_beta11.mtx\n",
      "{'mu': 3, 'n': 5000, 'gamma': 30, 'beta': 11, 'cons_method': 'lf-louvain', 'ncluster': 158, 'fscore': 0.8575608489953869, 'precision': 0.7512298978874695, 'recall': 0.9989554987493472, 'nmi': 0.9732485209601109}\n",
      "{'mu': 3, 'n': 5000, 'gamma': 30, 'beta': 11, 'cons_method': 'v5', 'ncluster': 187, 'fscore': 0.9497713315039854, 'precision': 0.9052031183840196, 'recall': 0.9989554987493472, 'nmi': 0.9911859698322012}\n",
      "LFR-lf-cons-evaluation/n5000/LFR_n5000_mu04_gamma30_beta11.mtx\n",
      "{'mu': 4, 'n': 5000, 'gamma': 30, 'beta': 11, 'cons_method': 'lf-louvain', 'ncluster': 157, 'fscore': 0.7702349018798667, 'precision': 0.6366606822262119, 'recall': 0.9747395618592122, 'nmi': 0.9509516237920054}\n",
      "{'mu': 4, 'n': 5000, 'gamma': 30, 'beta': 11, 'cons_method': 'v5', 'ncluster': 196, 'fscore': 0.8963376078104054, 'precision': 0.8300775302742839, 'recall': 0.9740936202963085, 'nmi': 0.9747521628328945}\n"
     ]
    }
   ],
   "source": [
    "stats = []\n",
    "\n",
    "distance_metrics = [\"split_joint_distance\", \"mirkin_distance\", \"variation_of_info_distance\"]\n",
    "consensus_methods = [\"lf-louvain\", \"v5\"]\n",
    "#consensus_methods = [\"v4\"]\n",
    "ns = [200, 1000, 5000]\n",
    "mus = [1, 2, 3, 4]\n",
    "#mus = [2]\n",
    "gammas = [30]\n",
    "betas = [11]\n",
    "for n in ns:\n",
    "    for mu in mus:\n",
    "        for gamma in gammas:\n",
    "            for beta in betas:\n",
    "                P_list = []\n",
    "                fileprefix = \"LFR-lf-cons-evaluation/\" + \"n\" + str(n) + \"/\"\n",
    "                fname = \"LFR_n\" + str(n) + \"_mu0\" + str(mu) + \"_gamma\" + str(gamma) + \"_beta\" + str(beta)\n",
    "                graph_file = fileprefix + fname + \".mtx\"\n",
    "                print(graph_file)\n",
    "\n",
    "                gt_clust_lst = read_clust_lst(fileprefix + fname + \".gt\")\n",
    "                gt_clust_asn = clust_lst_to_asn(gt_clust_lst)\n",
    "\n",
    "                common_stat = {}\n",
    "                common_stat[\"mu\"] = mu\n",
    "                common_stat[\"n\"] = n\n",
    "                common_stat[\"gamma\"] = gamma\n",
    "                common_stat[\"beta\"] = beta\n",
    "\n",
    "                for cons_method in consensus_methods:\n",
    "                    #print(cons_method)\n",
    "                    clust_file = fileprefix + fname + \".\" + cons_method\n",
    "                    if Path(clust_file).is_file():\n",
    "                        clust_lst = read_clust_lst(clust_file)\n",
    "                        clust_asn = clust_lst_to_asn(clust_lst)\n",
    "                            \n",
    "                        stat = dict(common_stat)\n",
    "                        stat[\"cons_method\"] = cons_method\n",
    "                        stat[\"ncluster\"] = len(clust_lst)\n",
    "\n",
    "                        F, precision, recall = fscore(gt_clust_lst, clust_lst)\n",
    "\n",
    "                        stat[\"fscore\"] = F\n",
    "                        stat[\"precision\"] = precision\n",
    "                        stat[\"recall\"] = recall\n",
    "\n",
    "                        #clust_lst_temp = clust_asn_to_lst(clust_asn)\n",
    "                        #modularity = nx.community.modularity(G, clust_lst_temp)\n",
    "                        #stat[\"modularity\"] = modularity\n",
    "\n",
    "                        stat[\"nmi\"] = normalized_mutual_info_score(gt_clust_asn, clust_asn)\n",
    "\n",
    "                        stats.append(stat)\n",
    "                        print(stat)\n",
    "\n",
    "df = pd.DataFrame(stats)\n",
    "filename = \"lf-cons-evaluation-quality-stats.csv\"\n",
    "df.to_csv(filename, index=False, mode='w', header=True)\n",
    "#df.to_csv(filename, index=False, mode='a', header=not os.path.exists(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0a2c55bd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import networkx.algorithms.community as nx_comm\n",
    "from networkx.generators.community import LFR_benchmark_graph\n",
    "from networkx.algorithms import bipartite\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy import sparse\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from matplotlib import rc\n",
    "import matplotlib.colors as mcolors\n",
    "matplotlib.rcParams.update(matplotlib.rcParamsDefault)\n",
    "plt.rcParams.update({\n",
    "    \"text.usetex\": True,\n",
    "    #\"font.family\": \"Helvetica\"\n",
    "    \"font.family\": \"Arial\"\n",
    "})\n",
    "import math\n",
    "\n",
    "quality_metrics = [\"precision\", \"recall\", \"fscore\", \"nmi\"]\n",
    "consensus_methods = [\"lf-louvain\", \"v5\"]\n",
    "consensus_methods_colors = [\"tab:gray\", \"tab:pink\"]\n",
    "mus = [1, 2, 3, 4]\n",
    "ns = [200, 1000, 5000]\n",
    "for n in ns:\n",
    "    df = pd.read_csv(\"lf-cons-evaluation-quality-stats.csv\")\n",
    "    df = df[df[\"n\"] == n]\n",
    "    \n",
    "    fig = plt.figure(figsize=(9, 6))\n",
    "    naxr = 2 \n",
    "    naxc = 2\n",
    "    gs = GridSpec(nrows=naxr, ncols=naxc)\n",
    "    axes = []\n",
    "    for i in range(naxr):\n",
    "        axr = []\n",
    "        for j in range(naxc):\n",
    "            axr.append(fig.add_subplot(gs[i,j]))\n",
    "        axes.append(axr)\n",
    "        \n",
    "    group_items = list(consensus_methods)\n",
    "    group_width = 0.7\n",
    "    bar_width = group_width/len(group_items)\n",
    "    middle_bar = math.floor(len(group_items) / 2.0)\n",
    "    even = len(group_items) % 2 == 0\n",
    "    for i in range(naxr):\n",
    "        for j in range(naxc):\n",
    "            idx = (i * naxr + j)\n",
    "            quality_metric = quality_metrics[idx]\n",
    "            for k in range(len(consensus_methods)):\n",
    "                df_target = df[df[\"cons_method\"] == consensus_methods[k]]\n",
    "                offset = None\n",
    "                if(even):\n",
    "                    offset = bar_width / 2.0 + (k - middle_bar) * bar_width\n",
    "                else:\n",
    "                    offset = (k - middle_bar) * bar_width\n",
    "                axes[i][j].bar(df_target[\"mu\"] + offset, df_target[quality_metric], color=consensus_methods_colors[k], width=bar_width, alpha=0.5, edgecolor='black', linewidth=bar_width/10.0, label=consensus_methods[k])\n",
    "            axes[i][j].set_xlabel(\"$\\mu$\")\n",
    "            axes[i][j].set_ylabel(quality_metric)\n",
    "            axes[i][j].set_xticks(np.array(mus))\n",
    "            axes[i][j].set_xticklabels(np.array(mus) / 10.0)\n",
    "            axes[i][j].grid(axis='y')\n",
    "            axes[i][j].legend(loc = \"lower right\")\n",
    "                \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"lf-cons-evaluation-quality-\"+ \"n\"+str(n)+\".pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6424183a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
